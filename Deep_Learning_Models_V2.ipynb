{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9OkX3kWXi3h",
        "outputId": "fd71b6d4-4eed-486c-d620-49be602e080b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/1.6 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -U -q pydrive google-colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rzJLxgsYHqJ",
        "outputId": "2738445e-fbdb-43bf-8e5e-6b2391b2f11b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Authenticate and mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u20nG2ADYVRD",
        "outputId": "b1e53ef6-c557-4694-e59b-67a425e3a32c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of DataFrame after dropping null values: (4958, 8)\n",
            "Training MLP...\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7070 - loss: 0.6495 - val_accuracy: 0.7994 - val_loss: 0.4507\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8067 - loss: 0.5036 - val_accuracy: 0.8075 - val_loss: 0.4578\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8089 - loss: 0.4938 - val_accuracy: 0.8135 - val_loss: 0.4263\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8163 - loss: 0.4820 - val_accuracy: 0.8075 - val_loss: 0.4538\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8235 - loss: 0.4737 - val_accuracy: 0.8105 - val_loss: 0.4440\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8373 - loss: 0.4499 - val_accuracy: 0.8004 - val_loss: 0.4636\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7215 - loss: 0.6177 - val_accuracy: 0.7087 - val_loss: 0.5686\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7913 - loss: 0.5369 - val_accuracy: 0.8145 - val_loss: 0.4360\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8128 - loss: 0.4834 - val_accuracy: 0.8135 - val_loss: 0.4249\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8283 - loss: 0.4652 - val_accuracy: 0.8125 - val_loss: 0.4346\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8120 - loss: 0.4849 - val_accuracy: 0.8085 - val_loss: 0.4456\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8298 - loss: 0.4341 - val_accuracy: 0.7661 - val_loss: 0.4984\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7042 - loss: 0.6384 - val_accuracy: 0.7641 - val_loss: 0.5032\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7863 - loss: 0.5304 - val_accuracy: 0.7873 - val_loss: 0.4571\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8137 - loss: 0.5086 - val_accuracy: 0.8014 - val_loss: 0.4475\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8209 - loss: 0.4698 - val_accuracy: 0.7994 - val_loss: 0.4305\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8295 - loss: 0.4692 - val_accuracy: 0.7964 - val_loss: 0.4349\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8290 - loss: 0.4655 - val_accuracy: 0.8105 - val_loss: 0.4304\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8217 - loss: 0.4568 - val_accuracy: 0.8115 - val_loss: 0.4688\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8398 - loss: 0.4264 - val_accuracy: 0.8095 - val_loss: 0.4541\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8435 - loss: 0.4247 - val_accuracy: 0.8135 - val_loss: 0.4254\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8426 - loss: 0.4292 - val_accuracy: 0.7923 - val_loss: 0.4658\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7094 - loss: 0.6358 - val_accuracy: 0.7873 - val_loss: 0.4509\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8009 - loss: 0.5118 - val_accuracy: 0.8095 - val_loss: 0.4405\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8142 - loss: 0.4936 - val_accuracy: 0.7893 - val_loss: 0.4396\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8087 - loss: 0.4890 - val_accuracy: 0.8065 - val_loss: 0.4391\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8294 - loss: 0.4525 - val_accuracy: 0.8125 - val_loss: 0.4238\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8269 - loss: 0.4652 - val_accuracy: 0.8075 - val_loss: 0.4277\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8262 - loss: 0.4646 - val_accuracy: 0.8085 - val_loss: 0.4339\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8163 - loss: 0.4511 - val_accuracy: 0.7591 - val_loss: 0.5071\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.6921 - loss: 0.6524 - val_accuracy: 0.8044 - val_loss: 0.4407\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8053 - loss: 0.5099 - val_accuracy: 0.8004 - val_loss: 0.4373\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8106 - loss: 0.4947 - val_accuracy: 0.7954 - val_loss: 0.4445\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8386 - loss: 0.4471 - val_accuracy: 0.8065 - val_loss: 0.4415\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8215 - loss: 0.4719 - val_accuracy: 0.8105 - val_loss: 0.4237\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8314 - loss: 0.4465 - val_accuracy: 0.8115 - val_loss: 0.4282\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8302 - loss: 0.4335 - val_accuracy: 0.8135 - val_loss: 0.4243\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8389 - loss: 0.4203 - val_accuracy: 0.8105 - val_loss: 0.4385\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7122 - loss: 0.6439 - val_accuracy: 0.8024 - val_loss: 0.4479\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8120 - loss: 0.4939 - val_accuracy: 0.8024 - val_loss: 0.4675\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8225 - loss: 0.4872 - val_accuracy: 0.8095 - val_loss: 0.4282\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8086 - loss: 0.4775 - val_accuracy: 0.7732 - val_loss: 0.4845\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8358 - loss: 0.4400 - val_accuracy: 0.8014 - val_loss: 0.4429\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8339 - loss: 0.4437 - val_accuracy: 0.8095 - val_loss: 0.4533\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6799 - loss: 0.6741 - val_accuracy: 0.8024 - val_loss: 0.4495\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8027 - loss: 0.5269 - val_accuracy: 0.8075 - val_loss: 0.4388\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8218 - loss: 0.4941 - val_accuracy: 0.7944 - val_loss: 0.4549\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8096 - loss: 0.4948 - val_accuracy: 0.7571 - val_loss: 0.5214\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8242 - loss: 0.4654 - val_accuracy: 0.8165 - val_loss: 0.4222\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8243 - loss: 0.4583 - val_accuracy: 0.7994 - val_loss: 0.4411\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8314 - loss: 0.4396 - val_accuracy: 0.7833 - val_loss: 0.4657\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8084 - loss: 0.4728 - val_accuracy: 0.8085 - val_loss: 0.4450\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7114 - loss: 0.6375 - val_accuracy: 0.8024 - val_loss: 0.4484\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7913 - loss: 0.5356 - val_accuracy: 0.7954 - val_loss: 0.4544\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8274 - loss: 0.4819 - val_accuracy: 0.8075 - val_loss: 0.4430\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8190 - loss: 0.4799 - val_accuracy: 0.8085 - val_loss: 0.4212\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8164 - loss: 0.4735 - val_accuracy: 0.8095 - val_loss: 0.4274\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8398 - loss: 0.4322 - val_accuracy: 0.8155 - val_loss: 0.4282\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8356 - loss: 0.4383 - val_accuracy: 0.8075 - val_loss: 0.4206\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8345 - loss: 0.4253 - val_accuracy: 0.8155 - val_loss: 0.4190\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8528 - loss: 0.4152 - val_accuracy: 0.7863 - val_loss: 0.4680\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8265 - loss: 0.4342 - val_accuracy: 0.8185 - val_loss: 0.4287\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7171 - loss: 0.6330 - val_accuracy: 0.8054 - val_loss: 0.4502\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7937 - loss: 0.5347 - val_accuracy: 0.7923 - val_loss: 0.4335\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8212 - loss: 0.4817 - val_accuracy: 0.7954 - val_loss: 0.4534\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8322 - loss: 0.4683 - val_accuracy: 0.7954 - val_loss: 0.4629\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8422 - loss: 0.4477 - val_accuracy: 0.8024 - val_loss: 0.4410\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7252 - loss: 0.6274 - val_accuracy: 0.7984 - val_loss: 0.4588\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7922 - loss: 0.5232 - val_accuracy: 0.7893 - val_loss: 0.4466\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8236 - loss: 0.4892 - val_accuracy: 0.8085 - val_loss: 0.4340\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.8081 - loss: 0.4940 - val_accuracy: 0.7903 - val_loss: 0.4699\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8236 - loss: 0.4515 - val_accuracy: 0.8145 - val_loss: 0.4302\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8306 - loss: 0.4530 - val_accuracy: 0.8125 - val_loss: 0.4305\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8468 - loss: 0.4130 - val_accuracy: 0.8115 - val_loss: 0.4180\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8333 - loss: 0.4259 - val_accuracy: 0.8085 - val_loss: 0.4379\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8475 - loss: 0.4175 - val_accuracy: 0.8226 - val_loss: 0.4330\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8486 - loss: 0.3956 - val_accuracy: 0.7893 - val_loss: 0.4978\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7033 - loss: 0.6612 - val_accuracy: 0.8034 - val_loss: 0.4682\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7820 - loss: 0.5505 - val_accuracy: 0.7974 - val_loss: 0.4510\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8030 - loss: 0.5123 - val_accuracy: 0.7994 - val_loss: 0.4459\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8144 - loss: 0.4901 - val_accuracy: 0.8014 - val_loss: 0.4415\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8137 - loss: 0.4776 - val_accuracy: 0.7792 - val_loss: 0.5002\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8319 - loss: 0.4575 - val_accuracy: 0.7954 - val_loss: 0.4689\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8227 - loss: 0.4534 - val_accuracy: 0.8145 - val_loss: 0.4277\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8362 - loss: 0.4504 - val_accuracy: 0.7651 - val_loss: 0.4847\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8304 - loss: 0.4387 - val_accuracy: 0.8125 - val_loss: 0.4233\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8358 - loss: 0.4307 - val_accuracy: 0.8165 - val_loss: 0.4367\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8512 - loss: 0.4104 - val_accuracy: 0.8135 - val_loss: 0.4302\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8515 - loss: 0.4019 - val_accuracy: 0.8105 - val_loss: 0.4613\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7082 - loss: 0.6475 - val_accuracy: 0.7802 - val_loss: 0.4688\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8022 - loss: 0.5180 - val_accuracy: 0.7933 - val_loss: 0.4490\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.8108 - loss: 0.4858 - val_accuracy: 0.8024 - val_loss: 0.4370\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8157 - loss: 0.4769 - val_accuracy: 0.8014 - val_loss: 0.4428\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8130 - loss: 0.4754 - val_accuracy: 0.8075 - val_loss: 0.4328\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8185 - loss: 0.4589 - val_accuracy: 0.8095 - val_loss: 0.4211\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8446 - loss: 0.4395 - val_accuracy: 0.8206 - val_loss: 0.4300\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8435 - loss: 0.4371 - val_accuracy: 0.8085 - val_loss: 0.4274\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8536 - loss: 0.4223 - val_accuracy: 0.8085 - val_loss: 0.4352\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7197 - loss: 0.6304 - val_accuracy: 0.7933 - val_loss: 0.4563\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8129 - loss: 0.5007 - val_accuracy: 0.7681 - val_loss: 0.4881\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8226 - loss: 0.4726 - val_accuracy: 0.7974 - val_loss: 0.4434\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8237 - loss: 0.4634 - val_accuracy: 0.8105 - val_loss: 0.4444\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8274 - loss: 0.4468 - val_accuracy: 0.7974 - val_loss: 0.4486\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8372 - loss: 0.4429 - val_accuracy: 0.7964 - val_loss: 0.4538\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7174 - loss: 0.6408 - val_accuracy: 0.7591 - val_loss: 0.4977\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8031 - loss: 0.5038 - val_accuracy: 0.8085 - val_loss: 0.4293\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8185 - loss: 0.4705 - val_accuracy: 0.8054 - val_loss: 0.4310\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8196 - loss: 0.4731 - val_accuracy: 0.7510 - val_loss: 0.5147\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8163 - loss: 0.4605 - val_accuracy: 0.8125 - val_loss: 0.4271\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8341 - loss: 0.4424 - val_accuracy: 0.8095 - val_loss: 0.4220\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8394 - loss: 0.4229 - val_accuracy: 0.8065 - val_loss: 0.4262\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8385 - loss: 0.4271 - val_accuracy: 0.8165 - val_loss: 0.4211\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8461 - loss: 0.4124 - val_accuracy: 0.8165 - val_loss: 0.4223\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8608 - loss: 0.3937 - val_accuracy: 0.8135 - val_loss: 0.4304\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8619 - loss: 0.3941 - val_accuracy: 0.8185 - val_loss: 0.4443\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6982 - loss: 0.6744 - val_accuracy: 0.7671 - val_loss: 0.4869\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7968 - loss: 0.5200 - val_accuracy: 0.8044 - val_loss: 0.4616\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8142 - loss: 0.5021 - val_accuracy: 0.7883 - val_loss: 0.4755\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8176 - loss: 0.4862 - val_accuracy: 0.8095 - val_loss: 0.4341\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8155 - loss: 0.4827 - val_accuracy: 0.7490 - val_loss: 0.5252\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8076 - loss: 0.4860 - val_accuracy: 0.7823 - val_loss: 0.4858\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8210 - loss: 0.4690 - val_accuracy: 0.8024 - val_loss: 0.4516\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7064 - loss: 0.6428 - val_accuracy: 0.8004 - val_loss: 0.4512\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8131 - loss: 0.5115 - val_accuracy: 0.7823 - val_loss: 0.5044\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8138 - loss: 0.4951 - val_accuracy: 0.8054 - val_loss: 0.4471\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8023 - loss: 0.5008 - val_accuracy: 0.8065 - val_loss: 0.4280\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8294 - loss: 0.4608 - val_accuracy: 0.8085 - val_loss: 0.4350\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8178 - loss: 0.4619 - val_accuracy: 0.7923 - val_loss: 0.4457\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8349 - loss: 0.4437 - val_accuracy: 0.7964 - val_loss: 0.4438\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Training LSTM...\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 591ms/step - accuracy: 0.5101 - loss: 0.8409 - val_accuracy: 0.5121 - val_loss: 0.7100\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 608ms/step - accuracy: 0.5737 - loss: 0.7959 - val_accuracy: 0.4778 - val_loss: 0.7085\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 617ms/step - accuracy: 0.5699 - loss: 0.7979 - val_accuracy: 0.6169 - val_loss: 0.6585\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 604ms/step - accuracy: 0.6197 - loss: 0.7797 - val_accuracy: 0.6240 - val_loss: 0.6550\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 598ms/step - accuracy: 0.6415 - loss: 0.7565 - val_accuracy: 0.6401 - val_loss: 0.6550\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 604ms/step - accuracy: 0.6624 - loss: 0.7397 - val_accuracy: 0.6774 - val_loss: 0.6033\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 605ms/step - accuracy: 0.6832 - loss: 0.7123 - val_accuracy: 0.6452 - val_loss: 0.6225\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 605ms/step - accuracy: 0.6756 - loss: 0.7042 - val_accuracy: 0.5958 - val_loss: 0.6537\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 613ms/step - accuracy: 0.7121 - loss: 0.6756 - val_accuracy: 0.7288 - val_loss: 0.5368\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 610ms/step - accuracy: 0.7100 - loss: 0.6681 - val_accuracy: 0.7046 - val_loss: 0.5635\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 138ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 934ms/step - accuracy: 0.5059 - loss: 0.8479 - val_accuracy: 0.4708 - val_loss: 0.6961\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 930ms/step - accuracy: 0.5373 - loss: 0.8127 - val_accuracy: 0.6149 - val_loss: 0.6524\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 933ms/step - accuracy: 0.5879 - loss: 0.7904 - val_accuracy: 0.6381 - val_loss: 0.6454\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 932ms/step - accuracy: 0.6167 - loss: 0.7758 - val_accuracy: 0.5968 - val_loss: 0.6678\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 923ms/step - accuracy: 0.6478 - loss: 0.7472 - val_accuracy: 0.6442 - val_loss: 0.6426\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 911ms/step - accuracy: 0.6538 - loss: 0.7404 - val_accuracy: 0.6250 - val_loss: 0.6529\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 906ms/step - accuracy: 0.6513 - loss: 0.7279 - val_accuracy: 0.6804 - val_loss: 0.6182\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 909ms/step - accuracy: 0.6950 - loss: 0.7118 - val_accuracy: 0.5474 - val_loss: 0.6987\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 913ms/step - accuracy: 0.7049 - loss: 0.6794 - val_accuracy: 0.7117 - val_loss: 0.5655\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 915ms/step - accuracy: 0.7147 - loss: 0.6626 - val_accuracy: 0.7107 - val_loss: 0.5727\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 454ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 621ms/step - accuracy: 0.4994 - loss: 0.8490 - val_accuracy: 0.4698 - val_loss: 0.7074\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 622ms/step - accuracy: 0.5203 - loss: 0.8274 - val_accuracy: 0.5867 - val_loss: 0.6817\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 627ms/step - accuracy: 0.6116 - loss: 0.7831 - val_accuracy: 0.6240 - val_loss: 0.6483\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 619ms/step - accuracy: 0.6253 - loss: 0.7690 - val_accuracy: 0.5595 - val_loss: 0.6905\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 616ms/step - accuracy: 0.6271 - loss: 0.7680 - val_accuracy: 0.5242 - val_loss: 0.7577\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 617ms/step - accuracy: 0.6300 - loss: 0.7640 - val_accuracy: 0.6341 - val_loss: 0.6514\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 202ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 898ms/step - accuracy: 0.5182 - loss: 0.8502 - val_accuracy: 0.4758 - val_loss: 0.6949\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 938ms/step - accuracy: 0.5218 - loss: 0.8260 - val_accuracy: 0.6149 - val_loss: 0.6592\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 934ms/step - accuracy: 0.6401 - loss: 0.7680 - val_accuracy: 0.6129 - val_loss: 0.6594\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 941ms/step - accuracy: 0.5854 - loss: 0.7901 - val_accuracy: 0.5403 - val_loss: 0.7176\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 942ms/step - accuracy: 0.6126 - loss: 0.7802 - val_accuracy: 0.6431 - val_loss: 0.6316\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 940ms/step - accuracy: 0.6397 - loss: 0.7560 - val_accuracy: 0.6774 - val_loss: 0.6123\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 938ms/step - accuracy: 0.6566 - loss: 0.7207 - val_accuracy: 0.6018 - val_loss: 0.6790\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 932ms/step - accuracy: 0.6769 - loss: 0.6943 - val_accuracy: 0.6815 - val_loss: 0.5962\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 933ms/step - accuracy: 0.7069 - loss: 0.6803 - val_accuracy: 0.7319 - val_loss: 0.5395\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 933ms/step - accuracy: 0.7022 - loss: 0.6702 - val_accuracy: 0.6825 - val_loss: 0.5880\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 450ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 694ms/step - accuracy: 0.5188 - loss: 0.8483 - val_accuracy: 0.4688 - val_loss: 0.7397\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 702ms/step - accuracy: 0.5658 - loss: 0.8055 - val_accuracy: 0.4929 - val_loss: 0.7313\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 719ms/step - accuracy: 0.5629 - loss: 0.7945 - val_accuracy: 0.5958 - val_loss: 0.6779\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 695ms/step - accuracy: 0.6156 - loss: 0.7689 - val_accuracy: 0.5857 - val_loss: 0.6657\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 727ms/step - accuracy: 0.6025 - loss: 0.7678 - val_accuracy: 0.6341 - val_loss: 0.6473\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 731ms/step - accuracy: 0.6145 - loss: 0.7749 - val_accuracy: 0.6149 - val_loss: 0.6598\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 704ms/step - accuracy: 0.6257 - loss: 0.7721 - val_accuracy: 0.6089 - val_loss: 0.6744\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 678ms/step - accuracy: 0.6430 - loss: 0.7523 - val_accuracy: 0.6129 - val_loss: 0.6582\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 142ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.5110 - loss: 0.8345 - val_accuracy: 0.5786 - val_loss: 0.6882\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - accuracy: 0.5618 - loss: 0.8072 - val_accuracy: 0.5665 - val_loss: 0.6756\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6104 - loss: 0.7859 - val_accuracy: 0.5887 - val_loss: 0.6752\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6028 - loss: 0.7729 - val_accuracy: 0.6270 - val_loss: 0.6512\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 2s/step - accuracy: 0.6221 - loss: 0.7666 - val_accuracy: 0.6149 - val_loss: 0.6624\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6460 - loss: 0.7550 - val_accuracy: 0.5998 - val_loss: 0.6697\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6266 - loss: 0.7571 - val_accuracy: 0.6411 - val_loss: 0.6320\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6497 - loss: 0.7490 - val_accuracy: 0.6371 - val_loss: 0.6309\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6823 - loss: 0.7182 - val_accuracy: 0.6159 - val_loss: 0.6739\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6825 - loss: 0.7080 - val_accuracy: 0.6935 - val_loss: 0.5829\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 464ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 695ms/step - accuracy: 0.4949 - loss: 0.8391 - val_accuracy: 0.5786 - val_loss: 0.6758\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 684ms/step - accuracy: 0.5482 - loss: 0.8136 - val_accuracy: 0.5877 - val_loss: 0.6697\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 723ms/step - accuracy: 0.5933 - loss: 0.7968 - val_accuracy: 0.6341 - val_loss: 0.6482\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 705ms/step - accuracy: 0.5995 - loss: 0.7815 - val_accuracy: 0.6099 - val_loss: 0.6608\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 698ms/step - accuracy: 0.6412 - loss: 0.7587 - val_accuracy: 0.6220 - val_loss: 0.6593\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 745ms/step - accuracy: 0.6091 - loss: 0.7694 - val_accuracy: 0.6190 - val_loss: 0.6550\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 182ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 2s/step - accuracy: 0.5113 - loss: 0.8427 - val_accuracy: 0.5938 - val_loss: 0.6671\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - accuracy: 0.5687 - loss: 0.8116 - val_accuracy: 0.4960 - val_loss: 0.6887\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - accuracy: 0.5829 - loss: 0.7924 - val_accuracy: 0.5877 - val_loss: 0.6939\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 2s/step - accuracy: 0.5862 - loss: 0.7895 - val_accuracy: 0.5998 - val_loss: 0.6762\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 437ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 611ms/step - accuracy: 0.5095 - loss: 0.8455 - val_accuracy: 0.5040 - val_loss: 0.6900\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 624ms/step - accuracy: 0.5593 - loss: 0.8091 - val_accuracy: 0.5948 - val_loss: 0.6633\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 610ms/step - accuracy: 0.5898 - loss: 0.7913 - val_accuracy: 0.6210 - val_loss: 0.6582\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 626ms/step - accuracy: 0.6218 - loss: 0.7797 - val_accuracy: 0.6159 - val_loss: 0.6541\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 632ms/step - accuracy: 0.6232 - loss: 0.7612 - val_accuracy: 0.6250 - val_loss: 0.6522\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 630ms/step - accuracy: 0.6304 - loss: 0.7699 - val_accuracy: 0.5242 - val_loss: 0.7274\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 623ms/step - accuracy: 0.6488 - loss: 0.7408 - val_accuracy: 0.6724 - val_loss: 0.5996\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 619ms/step - accuracy: 0.6659 - loss: 0.7207 - val_accuracy: 0.6885 - val_loss: 0.5944\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 631ms/step - accuracy: 0.6973 - loss: 0.6967 - val_accuracy: 0.6754 - val_loss: 0.5900\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 628ms/step - accuracy: 0.7090 - loss: 0.6769 - val_accuracy: 0.7228 - val_loss: 0.5487\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 619ms/step - accuracy: 0.7122 - loss: 0.6724 - val_accuracy: 0.7177 - val_loss: 0.5568\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 626ms/step - accuracy: 0.7196 - loss: 0.6624 - val_accuracy: 0.7429 - val_loss: 0.5106\n",
            "Epoch 13/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 623ms/step - accuracy: 0.7268 - loss: 0.6500 - val_accuracy: 0.7359 - val_loss: 0.5307\n",
            "Epoch 14/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 623ms/step - accuracy: 0.7458 - loss: 0.6301 - val_accuracy: 0.7339 - val_loss: 0.5431\n",
            "Epoch 15/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 627ms/step - accuracy: 0.7367 - loss: 0.6259 - val_accuracy: 0.7137 - val_loss: 0.5598\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 184ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 934ms/step - accuracy: 0.5199 - loss: 0.8378 - val_accuracy: 0.4698 - val_loss: 0.6897\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 940ms/step - accuracy: 0.5632 - loss: 0.7955 - val_accuracy: 0.5040 - val_loss: 0.7101\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 940ms/step - accuracy: 0.6124 - loss: 0.7759 - val_accuracy: 0.6079 - val_loss: 0.6639\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 941ms/step - accuracy: 0.6054 - loss: 0.7732 - val_accuracy: 0.6321 - val_loss: 0.6492\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 950ms/step - accuracy: 0.6290 - loss: 0.7680 - val_accuracy: 0.6381 - val_loss: 0.6437\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 937ms/step - accuracy: 0.6269 - loss: 0.7688 - val_accuracy: 0.5625 - val_loss: 0.7025\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 936ms/step - accuracy: 0.6343 - loss: 0.7525 - val_accuracy: 0.6008 - val_loss: 0.6500\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 935ms/step - accuracy: 0.6812 - loss: 0.7069 - val_accuracy: 0.7137 - val_loss: 0.5554\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 924ms/step - accuracy: 0.6967 - loss: 0.7041 - val_accuracy: 0.7177 - val_loss: 0.5511\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 909ms/step - accuracy: 0.7042 - loss: 0.6871 - val_accuracy: 0.7117 - val_loss: 0.5662\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 940ms/step - accuracy: 0.6981 - loss: 0.6825 - val_accuracy: 0.7198 - val_loss: 0.5695\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 936ms/step - accuracy: 0.7339 - loss: 0.6412 - val_accuracy: 0.7268 - val_loss: 0.5344\n",
            "Epoch 13/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 936ms/step - accuracy: 0.7282 - loss: 0.6500 - val_accuracy: 0.7228 - val_loss: 0.5406\n",
            "Epoch 14/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 938ms/step - accuracy: 0.7149 - loss: 0.6634 - val_accuracy: 0.7087 - val_loss: 0.5757\n",
            "Epoch 15/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 936ms/step - accuracy: 0.7333 - loss: 0.6368 - val_accuracy: 0.7298 - val_loss: 0.5176\n",
            "Epoch 16/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 936ms/step - accuracy: 0.7309 - loss: 0.6278 - val_accuracy: 0.7369 - val_loss: 0.5190\n",
            "Epoch 17/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 939ms/step - accuracy: 0.7306 - loss: 0.6257 - val_accuracy: 0.7268 - val_loss: 0.5315\n",
            "Epoch 18/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 938ms/step - accuracy: 0.7577 - loss: 0.5924 - val_accuracy: 0.7339 - val_loss: 0.5328\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 451ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 619ms/step - accuracy: 0.5014 - loss: 0.8431 - val_accuracy: 0.4718 - val_loss: 0.7001\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 632ms/step - accuracy: 0.5607 - loss: 0.8049 - val_accuracy: 0.5806 - val_loss: 0.6708\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 624ms/step - accuracy: 0.6062 - loss: 0.7749 - val_accuracy: 0.5423 - val_loss: 0.6904\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 621ms/step - accuracy: 0.6129 - loss: 0.7713 - val_accuracy: 0.6169 - val_loss: 0.6516\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 627ms/step - accuracy: 0.6410 - loss: 0.7638 - val_accuracy: 0.6179 - val_loss: 0.6552\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 666ms/step - accuracy: 0.6454 - loss: 0.7553 - val_accuracy: 0.5847 - val_loss: 0.6686\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 624ms/step - accuracy: 0.6372 - loss: 0.7596 - val_accuracy: 0.6401 - val_loss: 0.6336\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 623ms/step - accuracy: 0.6615 - loss: 0.7450 - val_accuracy: 0.6774 - val_loss: 0.6066\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 626ms/step - accuracy: 0.6555 - loss: 0.7393 - val_accuracy: 0.6603 - val_loss: 0.6233\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 632ms/step - accuracy: 0.6828 - loss: 0.7018 - val_accuracy: 0.7016 - val_loss: 0.5751\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 638ms/step - accuracy: 0.6956 - loss: 0.6940 - val_accuracy: 0.6744 - val_loss: 0.6010\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 631ms/step - accuracy: 0.7063 - loss: 0.6817 - val_accuracy: 0.7056 - val_loss: 0.5650\n",
            "Epoch 13/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 626ms/step - accuracy: 0.7145 - loss: 0.6738 - val_accuracy: 0.6825 - val_loss: 0.5875\n",
            "Epoch 14/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 617ms/step - accuracy: 0.7079 - loss: 0.6694 - val_accuracy: 0.7298 - val_loss: 0.5496\n",
            "Epoch 15/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 622ms/step - accuracy: 0.7147 - loss: 0.6732 - val_accuracy: 0.7056 - val_loss: 0.5780\n",
            "Epoch 16/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 634ms/step - accuracy: 0.7056 - loss: 0.6703 - val_accuracy: 0.7127 - val_loss: 0.5399\n",
            "Epoch 17/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 633ms/step - accuracy: 0.7182 - loss: 0.6658 - val_accuracy: 0.7359 - val_loss: 0.5394\n",
            "Epoch 18/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 632ms/step - accuracy: 0.7319 - loss: 0.6331 - val_accuracy: 0.7359 - val_loss: 0.5165\n",
            "Epoch 19/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 636ms/step - accuracy: 0.7490 - loss: 0.6316 - val_accuracy: 0.7329 - val_loss: 0.5395\n",
            "Epoch 20/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 621ms/step - accuracy: 0.7253 - loss: 0.6432 - val_accuracy: 0.7339 - val_loss: 0.5161\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 214ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 907ms/step - accuracy: 0.5062 - loss: 0.8446 - val_accuracy: 0.4698 - val_loss: 0.8003\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 947ms/step - accuracy: 0.4923 - loss: 0.8510 - val_accuracy: 0.4698 - val_loss: 0.7212\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 940ms/step - accuracy: 0.5012 - loss: 0.8440 - val_accuracy: 0.4698 - val_loss: 0.7173\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 937ms/step - accuracy: 0.5063 - loss: 0.8427 - val_accuracy: 0.4698 - val_loss: 0.7279\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 939ms/step - accuracy: 0.4919 - loss: 0.8434 - val_accuracy: 0.4698 - val_loss: 0.7405\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 941ms/step - accuracy: 0.4905 - loss: 0.8450 - val_accuracy: 0.4698 - val_loss: 0.7204\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 458ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 736ms/step - accuracy: 0.5014 - loss: 0.8373 - val_accuracy: 0.5534 - val_loss: 0.6910\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 727ms/step - accuracy: 0.5698 - loss: 0.7957 - val_accuracy: 0.6048 - val_loss: 0.6701\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 747ms/step - accuracy: 0.5917 - loss: 0.7887 - val_accuracy: 0.5696 - val_loss: 0.6722\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 688ms/step - accuracy: 0.5797 - loss: 0.8003 - val_accuracy: 0.5907 - val_loss: 0.6789\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 687ms/step - accuracy: 0.6117 - loss: 0.7743 - val_accuracy: 0.6079 - val_loss: 0.6570\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 701ms/step - accuracy: 0.6209 - loss: 0.7707 - val_accuracy: 0.6321 - val_loss: 0.6386\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 709ms/step - accuracy: 0.6551 - loss: 0.7576 - val_accuracy: 0.6512 - val_loss: 0.6369\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 724ms/step - accuracy: 0.6220 - loss: 0.7704 - val_accuracy: 0.5998 - val_loss: 0.6648\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 708ms/step - accuracy: 0.6354 - loss: 0.7571 - val_accuracy: 0.6250 - val_loss: 0.6474\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 737ms/step - accuracy: 0.6336 - loss: 0.7598 - val_accuracy: 0.5625 - val_loss: 0.7028\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.4951 - loss: 0.8433 - val_accuracy: 0.4849 - val_loss: 0.6933\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 2s/step - accuracy: 0.5364 - loss: 0.8179 - val_accuracy: 0.5827 - val_loss: 0.6814\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.5846 - loss: 0.7979 - val_accuracy: 0.6028 - val_loss: 0.6688\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.5934 - loss: 0.7884 - val_accuracy: 0.6149 - val_loss: 0.6564\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6112 - loss: 0.7780 - val_accuracy: 0.6260 - val_loss: 0.6617\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - accuracy: 0.6504 - loss: 0.7651 - val_accuracy: 0.5544 - val_loss: 0.7159\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - accuracy: 0.6175 - loss: 0.7738 - val_accuracy: 0.6361 - val_loss: 0.6368\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - accuracy: 0.6508 - loss: 0.7588 - val_accuracy: 0.4708 - val_loss: 0.7885\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.4949 - loss: 0.8531 - val_accuracy: 0.4698 - val_loss: 0.7340\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 2s/step - accuracy: 0.4931 - loss: 0.8444 - val_accuracy: 0.4698 - val_loss: 0.7240\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 455ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 735ms/step - accuracy: 0.5141 - loss: 0.8436 - val_accuracy: 0.5091 - val_loss: 0.6941\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 717ms/step - accuracy: 0.5554 - loss: 0.8094 - val_accuracy: 0.4778 - val_loss: 0.6955\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 752ms/step - accuracy: 0.5594 - loss: 0.8015 - val_accuracy: 0.5494 - val_loss: 0.7022\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 694ms/step - accuracy: 0.6140 - loss: 0.7764 - val_accuracy: 0.5988 - val_loss: 0.6628\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 729ms/step - accuracy: 0.6151 - loss: 0.7699 - val_accuracy: 0.4798 - val_loss: 0.7156\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 711ms/step - accuracy: 0.5885 - loss: 0.7846 - val_accuracy: 0.6220 - val_loss: 0.6649\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 722ms/step - accuracy: 0.6371 - loss: 0.7640 - val_accuracy: 0.6542 - val_loss: 0.6360\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 705ms/step - accuracy: 0.5937 - loss: 0.7924 - val_accuracy: 0.4698 - val_loss: 0.7277\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 719ms/step - accuracy: 0.4927 - loss: 0.8410 - val_accuracy: 0.6139 - val_loss: 0.6567\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 695ms/step - accuracy: 0.5661 - loss: 0.8052 - val_accuracy: 0.6190 - val_loss: 0.6555\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 147ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - accuracy: 0.5089 - loss: 0.8593 - val_accuracy: 0.4667 - val_loss: 0.7219\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 2s/step - accuracy: 0.4990 - loss: 0.8452 - val_accuracy: 0.4698 - val_loss: 0.7247\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 2s/step - accuracy: 0.4844 - loss: 0.8401 - val_accuracy: 0.4698 - val_loss: 0.7392\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.4934 - loss: 0.8425 - val_accuracy: 0.4698 - val_loss: 0.7286\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 452ms/step\n",
            "Training CNN...\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.4962 - loss: 0.8269 - val_accuracy: 0.6442 - val_loss: 0.6644\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.5840 - loss: 0.7802 - val_accuracy: 0.6472 - val_loss: 0.6371\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.6726 - loss: 0.7359 - val_accuracy: 0.6794 - val_loss: 0.6158\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.6727 - loss: 0.7243 - val_accuracy: 0.6966 - val_loss: 0.5884\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.6859 - loss: 0.7013 - val_accuracy: 0.6996 - val_loss: 0.5923\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.6952 - loss: 0.6736 - val_accuracy: 0.7056 - val_loss: 0.5818\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.7011 - loss: 0.6794 - val_accuracy: 0.7288 - val_loss: 0.5588\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.7159 - loss: 0.6581 - val_accuracy: 0.7248 - val_loss: 0.5548\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.7256 - loss: 0.6386 - val_accuracy: 0.7157 - val_loss: 0.5606\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7307 - loss: 0.6378 - val_accuracy: 0.7419 - val_loss: 0.5374\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.5058 - loss: 0.8205 - val_accuracy: 0.6159 - val_loss: 0.6589\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.6084 - loss: 0.7565 - val_accuracy: 0.6835 - val_loss: 0.6105\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.6684 - loss: 0.7301 - val_accuracy: 0.6976 - val_loss: 0.5933\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.6796 - loss: 0.7121 - val_accuracy: 0.7046 - val_loss: 0.5796\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - accuracy: 0.7109 - loss: 0.6788 - val_accuracy: 0.6764 - val_loss: 0.5990\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.7151 - loss: 0.6621 - val_accuracy: 0.7036 - val_loss: 0.5747\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.7154 - loss: 0.6505 - val_accuracy: 0.7278 - val_loss: 0.5465\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 34ms/step - accuracy: 0.7286 - loss: 0.6321 - val_accuracy: 0.6845 - val_loss: 0.5849\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.7405 - loss: 0.6398 - val_accuracy: 0.7349 - val_loss: 0.5307\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 0.7426 - loss: 0.6284 - val_accuracy: 0.7399 - val_loss: 0.5331\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.4954 - loss: 0.8305 - val_accuracy: 0.6371 - val_loss: 0.6628\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.5677 - loss: 0.7859 - val_accuracy: 0.6452 - val_loss: 0.6453\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.6487 - loss: 0.7436 - val_accuracy: 0.6452 - val_loss: 0.6394\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.6623 - loss: 0.7170 - val_accuracy: 0.6613 - val_loss: 0.6256\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.6952 - loss: 0.7009 - val_accuracy: 0.6976 - val_loss: 0.5822\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.7059 - loss: 0.6818 - val_accuracy: 0.6522 - val_loss: 0.6135\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.6979 - loss: 0.6872 - val_accuracy: 0.7308 - val_loss: 0.5623\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7134 - loss: 0.6545 - val_accuracy: 0.7117 - val_loss: 0.5725\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.7209 - loss: 0.6501 - val_accuracy: 0.7198 - val_loss: 0.5607\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.7250 - loss: 0.6376 - val_accuracy: 0.7218 - val_loss: 0.5597\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 0.4987 - loss: 0.8248 - val_accuracy: 0.6411 - val_loss: 0.6583\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.6134 - loss: 0.7626 - val_accuracy: 0.6663 - val_loss: 0.6242\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.6685 - loss: 0.7162 - val_accuracy: 0.7056 - val_loss: 0.5863\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 49ms/step - accuracy: 0.6987 - loss: 0.6948 - val_accuracy: 0.6905 - val_loss: 0.5925\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.7281 - loss: 0.6653 - val_accuracy: 0.7188 - val_loss: 0.5550\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.7288 - loss: 0.6469 - val_accuracy: 0.7278 - val_loss: 0.5417\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - accuracy: 0.7258 - loss: 0.6585 - val_accuracy: 0.7359 - val_loss: 0.5393\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 0.7363 - loss: 0.6326 - val_accuracy: 0.7329 - val_loss: 0.5363\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.7422 - loss: 0.6192 - val_accuracy: 0.7550 - val_loss: 0.5200\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - accuracy: 0.7405 - loss: 0.6196 - val_accuracy: 0.7288 - val_loss: 0.5366\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.4986 - loss: 0.8298 - val_accuracy: 0.5121 - val_loss: 0.6754\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.5332 - loss: 0.7865 - val_accuracy: 0.6512 - val_loss: 0.6444\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.6544 - loss: 0.7467 - val_accuracy: 0.6371 - val_loss: 0.6437\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.6505 - loss: 0.7504 - val_accuracy: 0.6593 - val_loss: 0.6268\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.6785 - loss: 0.7075 - val_accuracy: 0.6825 - val_loss: 0.6082\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.6961 - loss: 0.7003 - val_accuracy: 0.6421 - val_loss: 0.6321\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.6868 - loss: 0.6925 - val_accuracy: 0.7137 - val_loss: 0.5813\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.6978 - loss: 0.6888 - val_accuracy: 0.7198 - val_loss: 0.5749\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - accuracy: 0.7173 - loss: 0.6696 - val_accuracy: 0.6986 - val_loss: 0.5888\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.7043 - loss: 0.6639 - val_accuracy: 0.6895 - val_loss: 0.5904\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 78ms/step - accuracy: 0.5102 - loss: 0.8368 - val_accuracy: 0.4698 - val_loss: 0.6876\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 82ms/step - accuracy: 0.5180 - loss: 0.7867 - val_accuracy: 0.6704 - val_loss: 0.6357\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - accuracy: 0.6622 - loss: 0.7429 - val_accuracy: 0.6683 - val_loss: 0.6168\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 74ms/step - accuracy: 0.6838 - loss: 0.7130 - val_accuracy: 0.6996 - val_loss: 0.5973\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.6824 - loss: 0.6968 - val_accuracy: 0.7097 - val_loss: 0.5828\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 68ms/step - accuracy: 0.7011 - loss: 0.6821 - val_accuracy: 0.6512 - val_loss: 0.6173\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 75ms/step - accuracy: 0.6999 - loss: 0.6794 - val_accuracy: 0.7188 - val_loss: 0.5635\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.7238 - loss: 0.6526 - val_accuracy: 0.6915 - val_loss: 0.5811\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 68ms/step - accuracy: 0.7062 - loss: 0.6539 - val_accuracy: 0.7198 - val_loss: 0.5554\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 74ms/step - accuracy: 0.7316 - loss: 0.6376 - val_accuracy: 0.7268 - val_loss: 0.5466\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.4977 - loss: 0.8291 - val_accuracy: 0.4698 - val_loss: 0.6846\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.5277 - loss: 0.7915 - val_accuracy: 0.6048 - val_loss: 0.6628\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.6122 - loss: 0.7539 - val_accuracy: 0.6522 - val_loss: 0.6377\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.6583 - loss: 0.7337 - val_accuracy: 0.6744 - val_loss: 0.6200\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.6724 - loss: 0.7314 - val_accuracy: 0.6724 - val_loss: 0.6195\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.6850 - loss: 0.7103 - val_accuracy: 0.6976 - val_loss: 0.5942\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.6898 - loss: 0.7118 - val_accuracy: 0.6966 - val_loss: 0.5958\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.6936 - loss: 0.6955 - val_accuracy: 0.7147 - val_loss: 0.5765\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7069 - loss: 0.6877 - val_accuracy: 0.6956 - val_loss: 0.5875\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.7132 - loss: 0.6700 - val_accuracy: 0.7298 - val_loss: 0.5650\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 75ms/step - accuracy: 0.5041 - loss: 0.8308 - val_accuracy: 0.4698 - val_loss: 0.6840\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 78ms/step - accuracy: 0.5720 - loss: 0.7775 - val_accuracy: 0.6492 - val_loss: 0.6439\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 81ms/step - accuracy: 0.6591 - loss: 0.7366 - val_accuracy: 0.6784 - val_loss: 0.6146\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.6717 - loss: 0.7169 - val_accuracy: 0.6956 - val_loss: 0.5918\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.7036 - loss: 0.6961 - val_accuracy: 0.6230 - val_loss: 0.6386\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 70ms/step - accuracy: 0.6999 - loss: 0.6760 - val_accuracy: 0.7208 - val_loss: 0.5660\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 68ms/step - accuracy: 0.7082 - loss: 0.6726 - val_accuracy: 0.7188 - val_loss: 0.5741\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 85ms/step - accuracy: 0.7227 - loss: 0.6539 - val_accuracy: 0.7278 - val_loss: 0.5495\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 67ms/step - accuracy: 0.7236 - loss: 0.6542 - val_accuracy: 0.6935 - val_loss: 0.5809\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.7294 - loss: 0.6407 - val_accuracy: 0.7298 - val_loss: 0.5381\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.5003 - loss: 0.8242 - val_accuracy: 0.6482 - val_loss: 0.6587\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.5818 - loss: 0.7779 - val_accuracy: 0.6683 - val_loss: 0.6308\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.6522 - loss: 0.7491 - val_accuracy: 0.6815 - val_loss: 0.6051\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.6752 - loss: 0.7296 - val_accuracy: 0.6905 - val_loss: 0.5879\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 28ms/step - accuracy: 0.6917 - loss: 0.6989 - val_accuracy: 0.6966 - val_loss: 0.5978\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.6950 - loss: 0.6970 - val_accuracy: 0.7137 - val_loss: 0.5676\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7025 - loss: 0.6730 - val_accuracy: 0.7208 - val_loss: 0.5614\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.7312 - loss: 0.6511 - val_accuracy: 0.7208 - val_loss: 0.5617\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.7348 - loss: 0.6392 - val_accuracy: 0.7137 - val_loss: 0.5467\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.7189 - loss: 0.6686 - val_accuracy: 0.7339 - val_loss: 0.5408\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7386 - loss: 0.6321 - val_accuracy: 0.7379 - val_loss: 0.5343\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.7421 - loss: 0.6159 - val_accuracy: 0.7107 - val_loss: 0.5533\n",
            "Epoch 13/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.7444 - loss: 0.6140 - val_accuracy: 0.7379 - val_loss: 0.5305\n",
            "Epoch 14/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.7414 - loss: 0.6158 - val_accuracy: 0.7419 - val_loss: 0.5239\n",
            "Epoch 15/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.7508 - loss: 0.6042 - val_accuracy: 0.6976 - val_loss: 0.5722\n",
            "Epoch 16/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7368 - loss: 0.6210 - val_accuracy: 0.7450 - val_loss: 0.5192\n",
            "Epoch 17/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.7402 - loss: 0.6141 - val_accuracy: 0.7450 - val_loss: 0.5148\n",
            "Epoch 18/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7296 - loss: 0.6263 - val_accuracy: 0.7379 - val_loss: 0.5259\n",
            "Epoch 19/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 28ms/step - accuracy: 0.7416 - loss: 0.6001 - val_accuracy: 0.7369 - val_loss: 0.5318\n",
            "Epoch 20/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.7434 - loss: 0.6019 - val_accuracy: 0.7419 - val_loss: 0.5111\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.5217 - loss: 0.8198 - val_accuracy: 0.4738 - val_loss: 0.6954\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 35ms/step - accuracy: 0.6189 - loss: 0.7551 - val_accuracy: 0.6905 - val_loss: 0.6080\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - accuracy: 0.6810 - loss: 0.7182 - val_accuracy: 0.6431 - val_loss: 0.6335\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.6972 - loss: 0.6858 - val_accuracy: 0.7036 - val_loss: 0.5830\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.7130 - loss: 0.6705 - val_accuracy: 0.6421 - val_loss: 0.6243\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.7189 - loss: 0.6583 - val_accuracy: 0.6522 - val_loss: 0.6113\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.7123 - loss: 0.6511 - val_accuracy: 0.7238 - val_loss: 0.5536\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.7305 - loss: 0.6347 - val_accuracy: 0.7308 - val_loss: 0.5317\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 0.7351 - loss: 0.6390 - val_accuracy: 0.7429 - val_loss: 0.5284\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 33ms/step - accuracy: 0.7310 - loss: 0.6334 - val_accuracy: 0.7359 - val_loss: 0.5308\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - accuracy: 0.7389 - loss: 0.6104 - val_accuracy: 0.7550 - val_loss: 0.5185\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.7463 - loss: 0.6121 - val_accuracy: 0.7490 - val_loss: 0.5222\n",
            "Epoch 13/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 41ms/step - accuracy: 0.7481 - loss: 0.6006 - val_accuracy: 0.7530 - val_loss: 0.5094\n",
            "Epoch 14/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.7439 - loss: 0.6096 - val_accuracy: 0.7510 - val_loss: 0.5075\n",
            "Epoch 15/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.7519 - loss: 0.5949 - val_accuracy: 0.7046 - val_loss: 0.5583\n",
            "Epoch 16/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.7680 - loss: 0.5689 - val_accuracy: 0.7571 - val_loss: 0.5000\n",
            "Epoch 17/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.7616 - loss: 0.5816 - val_accuracy: 0.7591 - val_loss: 0.5021\n",
            "Epoch 18/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - accuracy: 0.7719 - loss: 0.5800 - val_accuracy: 0.7681 - val_loss: 0.4952\n",
            "Epoch 19/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 33ms/step - accuracy: 0.7693 - loss: 0.5854 - val_accuracy: 0.7409 - val_loss: 0.5265\n",
            "Epoch 20/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.7641 - loss: 0.5740 - val_accuracy: 0.7702 - val_loss: 0.4993\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.4944 - loss: 0.8276 - val_accuracy: 0.4698 - val_loss: 0.6969\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.5464 - loss: 0.7869 - val_accuracy: 0.6391 - val_loss: 0.6536\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.6216 - loss: 0.7592 - val_accuracy: 0.6391 - val_loss: 0.6517\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.6661 - loss: 0.7412 - val_accuracy: 0.6996 - val_loss: 0.6094\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.6796 - loss: 0.7095 - val_accuracy: 0.6956 - val_loss: 0.5924\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.7006 - loss: 0.6975 - val_accuracy: 0.7127 - val_loss: 0.5867\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7182 - loss: 0.6706 - val_accuracy: 0.7147 - val_loss: 0.5836\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.7166 - loss: 0.6714 - val_accuracy: 0.7319 - val_loss: 0.5627\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.7153 - loss: 0.6600 - val_accuracy: 0.7319 - val_loss: 0.5524\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.7294 - loss: 0.6405 - val_accuracy: 0.7429 - val_loss: 0.5510\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.7337 - loss: 0.6346 - val_accuracy: 0.7460 - val_loss: 0.5407\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7297 - loss: 0.6366 - val_accuracy: 0.7490 - val_loss: 0.5397\n",
            "Epoch 13/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.7389 - loss: 0.6133 - val_accuracy: 0.7268 - val_loss: 0.5482\n",
            "Epoch 14/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7249 - loss: 0.6226 - val_accuracy: 0.7520 - val_loss: 0.5308\n",
            "Epoch 15/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 28ms/step - accuracy: 0.7400 - loss: 0.6153 - val_accuracy: 0.7480 - val_loss: 0.5295\n",
            "Epoch 16/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.7414 - loss: 0.6141 - val_accuracy: 0.7480 - val_loss: 0.5316\n",
            "Epoch 17/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.7318 - loss: 0.6184 - val_accuracy: 0.7581 - val_loss: 0.5232\n",
            "Epoch 18/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.7480 - loss: 0.5999 - val_accuracy: 0.7560 - val_loss: 0.5194\n",
            "Epoch 19/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.7402 - loss: 0.6064 - val_accuracy: 0.7339 - val_loss: 0.5435\n",
            "Epoch 20/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.7529 - loss: 0.5982 - val_accuracy: 0.7571 - val_loss: 0.5138\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 0.5115 - loss: 0.8181 - val_accuracy: 0.5464 - val_loss: 0.6746\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.6254 - loss: 0.7678 - val_accuracy: 0.6804 - val_loss: 0.6130\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.6793 - loss: 0.7235 - val_accuracy: 0.6956 - val_loss: 0.5955\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.7025 - loss: 0.6889 - val_accuracy: 0.6966 - val_loss: 0.5744\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.6948 - loss: 0.6911 - val_accuracy: 0.6613 - val_loss: 0.6108\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 0.7045 - loss: 0.6859 - val_accuracy: 0.7167 - val_loss: 0.5635\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.7231 - loss: 0.6465 - val_accuracy: 0.6915 - val_loss: 0.5807\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.7204 - loss: 0.6378 - val_accuracy: 0.7329 - val_loss: 0.5425\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.7231 - loss: 0.6409 - val_accuracy: 0.7177 - val_loss: 0.5378\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.7302 - loss: 0.6435 - val_accuracy: 0.7379 - val_loss: 0.5411\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.7400 - loss: 0.6212 - val_accuracy: 0.7500 - val_loss: 0.5255\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.7504 - loss: 0.6025 - val_accuracy: 0.7349 - val_loss: 0.5345\n",
            "Epoch 13/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.7585 - loss: 0.5961 - val_accuracy: 0.7298 - val_loss: 0.5387\n",
            "Epoch 14/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - accuracy: 0.7422 - loss: 0.6190 - val_accuracy: 0.7581 - val_loss: 0.5171\n",
            "Epoch 15/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.7394 - loss: 0.6272 - val_accuracy: 0.7621 - val_loss: 0.5189\n",
            "Epoch 16/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.7311 - loss: 0.6067 - val_accuracy: 0.7560 - val_loss: 0.5184\n",
            "Epoch 17/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.7594 - loss: 0.5783 - val_accuracy: 0.7440 - val_loss: 0.5095\n",
            "Epoch 18/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 34ms/step - accuracy: 0.7443 - loss: 0.6117 - val_accuracy: 0.7460 - val_loss: 0.5298\n",
            "Epoch 19/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.7526 - loss: 0.5988 - val_accuracy: 0.7591 - val_loss: 0.5005\n",
            "Epoch 20/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 42ms/step - accuracy: 0.7684 - loss: 0.5742 - val_accuracy: 0.7389 - val_loss: 0.5026\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - accuracy: 0.5049 - loss: 0.8343 - val_accuracy: 0.4698 - val_loss: 0.7047\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 56ms/step - accuracy: 0.5092 - loss: 0.8089 - val_accuracy: 0.4788 - val_loss: 0.6810\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - accuracy: 0.5621 - loss: 0.7829 - val_accuracy: 0.6573 - val_loss: 0.6408\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - accuracy: 0.6347 - loss: 0.7522 - val_accuracy: 0.6562 - val_loss: 0.6338\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.6619 - loss: 0.7253 - val_accuracy: 0.6966 - val_loss: 0.6117\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.6897 - loss: 0.7041 - val_accuracy: 0.6220 - val_loss: 0.6377\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.6858 - loss: 0.6948 - val_accuracy: 0.6280 - val_loss: 0.6377\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.6844 - loss: 0.6929 - val_accuracy: 0.7218 - val_loss: 0.5721\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.7149 - loss: 0.6602 - val_accuracy: 0.7258 - val_loss: 0.5693\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.7062 - loss: 0.6643 - val_accuracy: 0.7278 - val_loss: 0.5631\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.7226 - loss: 0.6618 - val_accuracy: 0.7319 - val_loss: 0.5498\n",
            "Epoch 12/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.7271 - loss: 0.6448 - val_accuracy: 0.7389 - val_loss: 0.5470\n",
            "Epoch 13/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - accuracy: 0.7385 - loss: 0.6228 - val_accuracy: 0.7288 - val_loss: 0.5458\n",
            "Epoch 14/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.7220 - loss: 0.6420 - val_accuracy: 0.7238 - val_loss: 0.5534\n",
            "Epoch 15/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.7084 - loss: 0.6523 - val_accuracy: 0.7329 - val_loss: 0.5511\n",
            "Epoch 16/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.7451 - loss: 0.6063 - val_accuracy: 0.7238 - val_loss: 0.5533\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 86ms/step - accuracy: 0.5039 - loss: 0.8250 - val_accuracy: 0.4929 - val_loss: 0.6775\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 73ms/step - accuracy: 0.5752 - loss: 0.7765 - val_accuracy: 0.6704 - val_loss: 0.6301\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 72ms/step - accuracy: 0.6559 - loss: 0.7382 - val_accuracy: 0.6442 - val_loss: 0.6365\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 85ms/step - accuracy: 0.6825 - loss: 0.7118 - val_accuracy: 0.6734 - val_loss: 0.6099\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 72ms/step - accuracy: 0.6961 - loss: 0.6961 - val_accuracy: 0.6754 - val_loss: 0.6037\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 78ms/step - accuracy: 0.6923 - loss: 0.6842 - val_accuracy: 0.6946 - val_loss: 0.5902\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.7143 - loss: 0.6675 - val_accuracy: 0.6956 - val_loss: 0.5856\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.7102 - loss: 0.6641 - val_accuracy: 0.7288 - val_loss: 0.5480\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 95ms/step - accuracy: 0.7372 - loss: 0.6299 - val_accuracy: 0.7228 - val_loss: 0.5502\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 86ms/step - accuracy: 0.7344 - loss: 0.6351 - val_accuracy: 0.7177 - val_loss: 0.5413\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 72ms/step - accuracy: 0.7323 - loss: 0.6310 - val_accuracy: 0.7319 - val_loss: 0.5361\n",
            "Epoch 12/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 79ms/step - accuracy: 0.7262 - loss: 0.6402 - val_accuracy: 0.7288 - val_loss: 0.5493\n",
            "Epoch 13/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.7376 - loss: 0.6216 - val_accuracy: 0.6905 - val_loss: 0.5827\n",
            "Epoch 14/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - accuracy: 0.7477 - loss: 0.6103 - val_accuracy: 0.7056 - val_loss: 0.5714\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - accuracy: 0.4994 - loss: 0.8282 - val_accuracy: 0.4698 - val_loss: 0.6901\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - accuracy: 0.5301 - loss: 0.8016 - val_accuracy: 0.5766 - val_loss: 0.6655\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.5903 - loss: 0.7624 - val_accuracy: 0.6492 - val_loss: 0.6436\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.6553 - loss: 0.7387 - val_accuracy: 0.6885 - val_loss: 0.6110\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.6826 - loss: 0.7221 - val_accuracy: 0.6673 - val_loss: 0.6229\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.6817 - loss: 0.7040 - val_accuracy: 0.6986 - val_loss: 0.5868\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.6813 - loss: 0.7061 - val_accuracy: 0.7137 - val_loss: 0.5834\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - accuracy: 0.7018 - loss: 0.6861 - val_accuracy: 0.7167 - val_loss: 0.5775\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.7246 - loss: 0.6553 - val_accuracy: 0.7177 - val_loss: 0.5738\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.7056 - loss: 0.6777 - val_accuracy: 0.7077 - val_loss: 0.5641\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.7280 - loss: 0.6439 - val_accuracy: 0.7107 - val_loss: 0.5601\n",
            "Epoch 12/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - accuracy: 0.7174 - loss: 0.6617 - val_accuracy: 0.7248 - val_loss: 0.5574\n",
            "Epoch 13/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.7238 - loss: 0.6409 - val_accuracy: 0.7288 - val_loss: 0.5551\n",
            "Epoch 14/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.7152 - loss: 0.6592 - val_accuracy: 0.7298 - val_loss: 0.5556\n",
            "Epoch 15/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.7165 - loss: 0.6477 - val_accuracy: 0.7288 - val_loss: 0.5444\n",
            "Epoch 16/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.7321 - loss: 0.6370 - val_accuracy: 0.7319 - val_loss: 0.5538\n",
            "Epoch 17/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.7405 - loss: 0.6245 - val_accuracy: 0.7349 - val_loss: 0.5398\n",
            "Epoch 18/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.7306 - loss: 0.6270 - val_accuracy: 0.7379 - val_loss: 0.5360\n",
            "Epoch 19/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.7405 - loss: 0.6249 - val_accuracy: 0.6623 - val_loss: 0.6064\n",
            "Epoch 20/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.7365 - loss: 0.6079 - val_accuracy: 0.6915 - val_loss: 0.5768\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 79ms/step - accuracy: 0.4967 - loss: 0.8243 - val_accuracy: 0.6260 - val_loss: 0.6631\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.5969 - loss: 0.7798 - val_accuracy: 0.6633 - val_loss: 0.6362\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 69ms/step - accuracy: 0.6619 - loss: 0.7446 - val_accuracy: 0.6784 - val_loss: 0.6197\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 79ms/step - accuracy: 0.6753 - loss: 0.7295 - val_accuracy: 0.6109 - val_loss: 0.6506\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 95ms/step - accuracy: 0.6930 - loss: 0.6969 - val_accuracy: 0.7077 - val_loss: 0.5878\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.7148 - loss: 0.6650 - val_accuracy: 0.7087 - val_loss: 0.5656\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 85ms/step - accuracy: 0.7151 - loss: 0.6724 - val_accuracy: 0.6895 - val_loss: 0.5872\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 75ms/step - accuracy: 0.7139 - loss: 0.6627 - val_accuracy: 0.7006 - val_loss: 0.5798\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 79ms/step - accuracy: 0.7065 - loss: 0.6589 - val_accuracy: 0.7349 - val_loss: 0.5583\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 84ms/step - accuracy: 0.7219 - loss: 0.6446 - val_accuracy: 0.7288 - val_loss: 0.5456\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 72ms/step - accuracy: 0.7392 - loss: 0.6290 - val_accuracy: 0.7480 - val_loss: 0.5383\n",
            "Epoch 12/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 83ms/step - accuracy: 0.7442 - loss: 0.6212 - val_accuracy: 0.7349 - val_loss: 0.5397\n",
            "Epoch 13/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 70ms/step - accuracy: 0.7256 - loss: 0.6381 - val_accuracy: 0.7460 - val_loss: 0.5334\n",
            "Epoch 14/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.7353 - loss: 0.6358 - val_accuracy: 0.7379 - val_loss: 0.5212\n",
            "Epoch 15/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.7555 - loss: 0.6040 - val_accuracy: 0.7107 - val_loss: 0.5584\n",
            "Epoch 16/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.7371 - loss: 0.6241 - val_accuracy: 0.7056 - val_loss: 0.5604\n",
            "Epoch 17/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.7322 - loss: 0.6250 - val_accuracy: 0.7480 - val_loss: 0.5159\n",
            "Epoch 18/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 77ms/step - accuracy: 0.7463 - loss: 0.6185 - val_accuracy: 0.7591 - val_loss: 0.5161\n",
            "Epoch 19/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 73ms/step - accuracy: 0.7507 - loss: 0.6145 - val_accuracy: 0.7188 - val_loss: 0.5551\n",
            "Epoch 20/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 86ms/step - accuracy: 0.7639 - loss: 0.5808 - val_accuracy: 0.7490 - val_loss: 0.5197\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
            "Experiment completed. Results saved.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Conv1D, GlobalMaxPooling1D, Dropout, Input, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import joblib\n",
        "import json\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Set paths\n",
        "data_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/data.xlsx\"\n",
        "save_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/deep_learning_results2\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_excel(data_path)\n",
        "df.dropna(inplace=True)\n",
        "print(\"Size of DataFrame after dropping null values:\", df.shape)\n",
        "\n",
        "# Function to parse vector strings into numpy arrays\n",
        "def parse_vector(vector_str, expected_dim):\n",
        "    try:\n",
        "        if isinstance(vector_str, str):\n",
        "            vec = np.array([float(i) for i in vector_str.strip(\"[]\").split()], dtype=np.float32)\n",
        "            if vec.shape[0] == expected_dim:\n",
        "                return vec\n",
        "            elif vec.shape[0] > expected_dim:\n",
        "                return vec[:expected_dim]  # Truncate to expected size\n",
        "            else:\n",
        "                return np.pad(vec, (0, expected_dim - vec.shape[0]))  # Pad with zeros\n",
        "    except:\n",
        "        return np.zeros(expected_dim, dtype=np.float32)  # Default to zero vector\n",
        "    return np.zeros(expected_dim, dtype=np.float32)\n",
        "\n",
        "# Define expected dimensions\n",
        "word2vec_dim = 300\n",
        "fasttext_dim = 300\n",
        "sentence_embedding_dim = 300\n",
        "sinbert_dim = 768  # Larger than others\n",
        "\n",
        "# Apply parsing with dimension corrections\n",
        "df['word2vec_vector'] = df['word2vec_vector'].map(lambda x: parse_vector(x, word2vec_dim))\n",
        "df['fasttext_vector'] = df['fasttext_vector'].map(lambda x: parse_vector(x, fasttext_dim))\n",
        "df['sentence_embedding'] = df['sentence_embedding'].map(lambda x: parse_vector(x, sentence_embedding_dim))\n",
        "df['sinbert_vector'] = df['sinbert_vector'].map(lambda x: parse_vector(x, sinbert_dim))  # Keep 768D\n",
        "\n",
        "# Ensure all feature vectors have the same final dimension\n",
        "final_dim = 768  # Choose larger or normalize to 300\n",
        "for feature in ['word2vec_vector', 'fasttext_vector', 'sentence_embedding']:\n",
        "    df[feature] = df[feature].map(lambda x: np.pad(x, (0, final_dim - x.shape[0])) if x.shape[0] < final_dim else x[:final_dim])\n",
        "\n",
        "# Stack feature vectors correctly\n",
        "X = np.stack(df[['word2vec_vector', 'fasttext_vector', 'sentence_embedding', 'sinbert_vector']].apply(lambda row: np.column_stack(row.values), axis=1).values)\n",
        "\n",
        "# Flatten X for MLP: (samples, final_dim * 4)\n",
        "X_flattened = X.reshape(X.shape[0], -1)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'].values)\n",
        "joblib.dump(label_encoder, os.path.join(save_path, 'label_encoder.pkl'))\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train_flattened, X_test_flattened = train_test_split(X_flattened, test_size=0.2, random_state=42)\n",
        "\n",
        "# Function to implement early stopping and class weights\n",
        "def build_mlp(input_shape, dropout_rate=0.2, dense_units=128):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Dense(dense_units, activation='relu'),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(dense_units // 2, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_lstm(input_shape, dropout_rate=0.2, lstm_units=64):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        LSTM(lstm_units, return_sequences=True),\n",
        "        Dropout(dropout_rate),\n",
        "        LSTM(lstm_units // 2),\n",
        "        Flatten(),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_cnn(input_shape, dropout_rate=0.2, filters=64):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Conv1D(filters, kernel_size=3, activation='relu'),\n",
        "        Dropout(dropout_rate),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(filters // 2, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Early stopping callback to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Apply class weights (use if there is class imbalance)\n",
        "class_weights = {0: 1, 1: 1.5}  # Increase weight for the minority class\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"confusion_matrix\": conf_matrix.tolist()\n",
        "    }\n",
        "\n",
        "# Train and evaluate models with hyperparameter tuning and regularization\n",
        "results = {}\n",
        "\n",
        "# Model hyperparameters for tuning\n",
        "params = {\n",
        "    'MLP': {\n",
        "        'epochs': [10, 20],\n",
        "        'batch_size': [16, 32],\n",
        "        'dropout': [0.2, 0.3],\n",
        "        'dense_units': [64, 128]\n",
        "    },\n",
        "    'LSTM': {\n",
        "        'epochs': [10, 20],\n",
        "        'batch_size': [16, 32],\n",
        "        'dropout': [0.2, 0.3],\n",
        "        'lstm_units': [64, 128],\n",
        "    },\n",
        "    'CNN': {\n",
        "        'epochs': [10, 20],\n",
        "        'batch_size': [16, 32],\n",
        "        'dropout': [0.2, 0.3],\n",
        "        'filters': [64, 128],\n",
        "    }\n",
        "}\n",
        "\n",
        "# Train and evaluate each model\n",
        "for name in ['MLP', 'LSTM', 'CNN']:\n",
        "    print(f\"Training {name}...\")\n",
        "\n",
        "    # Hyperparameter grid search (manually tuned here)\n",
        "    for epochs in params[name]['epochs']:\n",
        "        for batch_size in params[name]['batch_size']:\n",
        "            if name == 'MLP':\n",
        "                for dropout in params[name]['dropout']:\n",
        "                    for dense_units in params[name]['dense_units']:\n",
        "                        model_instance = build_mlp((X_train_flattened.shape[1],), dropout, dense_units)\n",
        "                        model_instance.fit(X_train_flattened, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                                           validation_data=(X_test_flattened, y_test), class_weight=class_weights,\n",
        "                                           callbacks=[early_stopping], verbose=1)\n",
        "                        y_pred = (model_instance.predict(X_test_flattened) > 0.5).astype(int)\n",
        "                        results[name] = evaluate_model(y_test, y_pred)\n",
        "            elif name == 'LSTM':\n",
        "                for dropout in params[name]['dropout']:\n",
        "                    for lstm_units in params[name]['lstm_units']:\n",
        "                        model_instance = build_lstm((X_train.shape[1], X_train.shape[2]), dropout, lstm_units)\n",
        "                        model_instance.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                                           validation_data=(X_test, y_test), class_weight=class_weights,\n",
        "                                           callbacks=[early_stopping], verbose=1)\n",
        "                        y_pred = (model_instance.predict(X_test) > 0.5).astype(int)\n",
        "                        results[name] = evaluate_model(y_test, y_pred)\n",
        "            elif name == 'CNN':\n",
        "                for dropout in params[name]['dropout']:\n",
        "                    for filters in params[name]['filters']:\n",
        "                        model_instance = build_cnn((X_train.shape[1], X_train.shape[2]), dropout, filters)\n",
        "                        model_instance.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                                           validation_data=(X_test, y_test), class_weight=class_weights,\n",
        "                                           callbacks=[early_stopping], verbose=1)\n",
        "                        y_pred = (model_instance.predict(X_test) > 0.5).astype(int)\n",
        "                        results[name] = evaluate_model(y_test, y_pred)\n",
        "\n",
        "# Save results to JSON\n",
        "results_path = os.path.join(save_path, \"model_results.json\")\n",
        "with open(results_path, \"w\") as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n",
        "print(\"Experiment completed. Results saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeWTNUGhO5-4",
        "outputId": "6f65c3db-f21e-43cd-afd9-94de3e65d218"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of DataFrame after dropping null values: (4958, 8)\n",
            "Training MLP...\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7140 - loss: 0.6325 - val_accuracy: 0.8095 - val_loss: 0.4467\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8067 - loss: 0.5083 - val_accuracy: 0.7873 - val_loss: 0.4730\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8233 - loss: 0.4815 - val_accuracy: 0.7913 - val_loss: 0.4774\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8133 - loss: 0.4765 - val_accuracy: 0.7792 - val_loss: 0.4890\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7075 - loss: 0.6428 - val_accuracy: 0.7903 - val_loss: 0.4430\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8010 - loss: 0.5273 - val_accuracy: 0.8034 - val_loss: 0.4346\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8219 - loss: 0.4804 - val_accuracy: 0.7994 - val_loss: 0.4438\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8299 - loss: 0.4759 - val_accuracy: 0.8014 - val_loss: 0.4509\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8289 - loss: 0.4488 - val_accuracy: 0.8145 - val_loss: 0.4246\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8212 - loss: 0.4457 - val_accuracy: 0.8014 - val_loss: 0.4648\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8409 - loss: 0.4208 - val_accuracy: 0.8115 - val_loss: 0.4437\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8417 - loss: 0.4186 - val_accuracy: 0.8135 - val_loss: 0.4485\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7136 - loss: 0.6526 - val_accuracy: 0.7681 - val_loss: 0.4792\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7966 - loss: 0.5191 - val_accuracy: 0.7944 - val_loss: 0.4575\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8059 - loss: 0.5072 - val_accuracy: 0.8024 - val_loss: 0.4419\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8142 - loss: 0.4889 - val_accuracy: 0.8085 - val_loss: 0.4342\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8236 - loss: 0.4758 - val_accuracy: 0.8014 - val_loss: 0.4418\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8374 - loss: 0.4410 - val_accuracy: 0.7933 - val_loss: 0.4489\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8282 - loss: 0.4434 - val_accuracy: 0.8065 - val_loss: 0.4397\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7156 - loss: 0.6352 - val_accuracy: 0.8014 - val_loss: 0.4457\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8124 - loss: 0.5048 - val_accuracy: 0.7913 - val_loss: 0.4412\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8028 - loss: 0.5024 - val_accuracy: 0.7762 - val_loss: 0.4864\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8121 - loss: 0.4721 - val_accuracy: 0.7843 - val_loss: 0.4790\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8287 - loss: 0.4658 - val_accuracy: 0.8125 - val_loss: 0.4417\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.7122 - loss: 0.6368 - val_accuracy: 0.7812 - val_loss: 0.4729\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8049 - loss: 0.5020 - val_accuracy: 0.7994 - val_loss: 0.4331\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8098 - loss: 0.4998 - val_accuracy: 0.8095 - val_loss: 0.4262\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8052 - loss: 0.4848 - val_accuracy: 0.8105 - val_loss: 0.4268\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8314 - loss: 0.4573 - val_accuracy: 0.7722 - val_loss: 0.4834\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8242 - loss: 0.4565 - val_accuracy: 0.8135 - val_loss: 0.4275\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.7299 - loss: 0.6337 - val_accuracy: 0.8004 - val_loss: 0.4370\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8061 - loss: 0.5202 - val_accuracy: 0.7994 - val_loss: 0.4438\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8070 - loss: 0.4860 - val_accuracy: 0.8105 - val_loss: 0.4321\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8207 - loss: 0.4689 - val_accuracy: 0.7954 - val_loss: 0.4687\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8233 - loss: 0.4524 - val_accuracy: 0.8125 - val_loss: 0.4278\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8364 - loss: 0.4415 - val_accuracy: 0.8044 - val_loss: 0.4302\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8366 - loss: 0.4338 - val_accuracy: 0.8145 - val_loss: 0.4401\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8348 - loss: 0.4175 - val_accuracy: 0.8125 - val_loss: 0.4344\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.7039 - loss: 0.6657 - val_accuracy: 0.8044 - val_loss: 0.4434\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7894 - loss: 0.5428 - val_accuracy: 0.7823 - val_loss: 0.4706\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8185 - loss: 0.4750 - val_accuracy: 0.7671 - val_loss: 0.4906\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8112 - loss: 0.4812 - val_accuracy: 0.8085 - val_loss: 0.4390\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8173 - loss: 0.4794 - val_accuracy: 0.8044 - val_loss: 0.4407\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8362 - loss: 0.4415 - val_accuracy: 0.8105 - val_loss: 0.4218\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8250 - loss: 0.4530 - val_accuracy: 0.7974 - val_loss: 0.4500\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8208 - loss: 0.4563 - val_accuracy: 0.7641 - val_loss: 0.4926\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8241 - loss: 0.4464 - val_accuracy: 0.8135 - val_loss: 0.4379\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.7067 - loss: 0.6367 - val_accuracy: 0.7944 - val_loss: 0.4400\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8073 - loss: 0.5074 - val_accuracy: 0.7974 - val_loss: 0.4517\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8197 - loss: 0.4628 - val_accuracy: 0.8004 - val_loss: 0.4288\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8165 - loss: 0.4708 - val_accuracy: 0.8014 - val_loss: 0.4357\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8244 - loss: 0.4666 - val_accuracy: 0.7460 - val_loss: 0.5203\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8289 - loss: 0.4461 - val_accuracy: 0.8024 - val_loss: 0.4355\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.7141 - loss: 0.6282 - val_accuracy: 0.7984 - val_loss: 0.4531\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8083 - loss: 0.5060 - val_accuracy: 0.8145 - val_loss: 0.4400\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8176 - loss: 0.4887 - val_accuracy: 0.7661 - val_loss: 0.5019\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8257 - loss: 0.4688 - val_accuracy: 0.8075 - val_loss: 0.4315\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8329 - loss: 0.4542 - val_accuracy: 0.7883 - val_loss: 0.4837\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8211 - loss: 0.4684 - val_accuracy: 0.8034 - val_loss: 0.4308\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8303 - loss: 0.4519 - val_accuracy: 0.8145 - val_loss: 0.4209\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8571 - loss: 0.4084 - val_accuracy: 0.8105 - val_loss: 0.4288\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8498 - loss: 0.4144 - val_accuracy: 0.7974 - val_loss: 0.4651\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8514 - loss: 0.4020 - val_accuracy: 0.8155 - val_loss: 0.4258\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7318 - loss: 0.6182 - val_accuracy: 0.7833 - val_loss: 0.4761\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7972 - loss: 0.5324 - val_accuracy: 0.8054 - val_loss: 0.4350\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8188 - loss: 0.4864 - val_accuracy: 0.8014 - val_loss: 0.4523\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8194 - loss: 0.4741 - val_accuracy: 0.8065 - val_loss: 0.4304\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8206 - loss: 0.4799 - val_accuracy: 0.8085 - val_loss: 0.4233\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8250 - loss: 0.4462 - val_accuracy: 0.7974 - val_loss: 0.4556\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8471 - loss: 0.4352 - val_accuracy: 0.8115 - val_loss: 0.4335\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8414 - loss: 0.4180 - val_accuracy: 0.8125 - val_loss: 0.4245\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7204 - loss: 0.6309 - val_accuracy: 0.8065 - val_loss: 0.4403\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7882 - loss: 0.5312 - val_accuracy: 0.7893 - val_loss: 0.4684\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8050 - loss: 0.5083 - val_accuracy: 0.8085 - val_loss: 0.4370\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8172 - loss: 0.4903 - val_accuracy: 0.7641 - val_loss: 0.4785\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8245 - loss: 0.4704 - val_accuracy: 0.8085 - val_loss: 0.4515\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8281 - loss: 0.4622 - val_accuracy: 0.8095 - val_loss: 0.4494\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.7004 - loss: 0.6565 - val_accuracy: 0.7893 - val_loss: 0.4701\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8024 - loss: 0.5201 - val_accuracy: 0.8105 - val_loss: 0.4334\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8013 - loss: 0.5179 - val_accuracy: 0.7812 - val_loss: 0.4719\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8040 - loss: 0.5030 - val_accuracy: 0.8155 - val_loss: 0.4271\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8103 - loss: 0.4814 - val_accuracy: 0.7873 - val_loss: 0.4724\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8130 - loss: 0.4723 - val_accuracy: 0.8145 - val_loss: 0.4272\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8492 - loss: 0.4276 - val_accuracy: 0.8075 - val_loss: 0.4485\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7338 - loss: 0.6340 - val_accuracy: 0.7762 - val_loss: 0.4700\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7992 - loss: 0.5014 - val_accuracy: 0.7208 - val_loss: 0.5478\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8119 - loss: 0.4917 - val_accuracy: 0.7923 - val_loss: 0.4688\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8158 - loss: 0.4724 - val_accuracy: 0.7974 - val_loss: 0.4652\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8218 - loss: 0.4787 - val_accuracy: 0.8165 - val_loss: 0.4209\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8254 - loss: 0.4402 - val_accuracy: 0.8125 - val_loss: 0.4195\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8366 - loss: 0.4376 - val_accuracy: 0.8155 - val_loss: 0.4259\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8383 - loss: 0.4332 - val_accuracy: 0.8024 - val_loss: 0.4411\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8472 - loss: 0.4184 - val_accuracy: 0.7923 - val_loss: 0.4695\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7122 - loss: 0.6402 - val_accuracy: 0.7994 - val_loss: 0.4652\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7924 - loss: 0.5297 - val_accuracy: 0.8125 - val_loss: 0.4278\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8200 - loss: 0.4794 - val_accuracy: 0.8095 - val_loss: 0.4296\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8185 - loss: 0.4739 - val_accuracy: 0.8145 - val_loss: 0.4219\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8243 - loss: 0.4734 - val_accuracy: 0.8125 - val_loss: 0.4314\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8298 - loss: 0.4561 - val_accuracy: 0.8175 - val_loss: 0.4294\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8364 - loss: 0.4314 - val_accuracy: 0.8165 - val_loss: 0.4444\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.7025 - loss: 0.6396 - val_accuracy: 0.7732 - val_loss: 0.4802\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8019 - loss: 0.5259 - val_accuracy: 0.7873 - val_loss: 0.4697\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8167 - loss: 0.4897 - val_accuracy: 0.8125 - val_loss: 0.4299\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8178 - loss: 0.4721 - val_accuracy: 0.7954 - val_loss: 0.4736\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8178 - loss: 0.4666 - val_accuracy: 0.8004 - val_loss: 0.4404\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8336 - loss: 0.4667 - val_accuracy: 0.7762 - val_loss: 0.4793\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.6923 - loss: 0.6516 - val_accuracy: 0.7883 - val_loss: 0.4465\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8051 - loss: 0.5122 - val_accuracy: 0.7974 - val_loss: 0.4495\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8152 - loss: 0.4787 - val_accuracy: 0.8115 - val_loss: 0.4245\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8305 - loss: 0.4638 - val_accuracy: 0.8075 - val_loss: 0.4350\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8282 - loss: 0.4627 - val_accuracy: 0.7893 - val_loss: 0.4771\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8340 - loss: 0.4468 - val_accuracy: 0.8075 - val_loss: 0.4347\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Training LSTM...\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 50ms/step - accuracy: 0.5029 - loss: 0.8454 - val_accuracy: 0.4698 - val_loss: 0.7373\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 50ms/step - accuracy: 0.5482 - loss: 0.8109 - val_accuracy: 0.5565 - val_loss: 0.6963\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.5844 - loss: 0.7922 - val_accuracy: 0.6210 - val_loss: 0.6423\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.6221 - loss: 0.7614 - val_accuracy: 0.6341 - val_loss: 0.6473\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 53ms/step - accuracy: 0.6138 - loss: 0.7713 - val_accuracy: 0.6139 - val_loss: 0.6557\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 50ms/step - accuracy: 0.6226 - loss: 0.7575 - val_accuracy: 0.5897 - val_loss: 0.6682\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 54ms/step - accuracy: 0.4885 - loss: 0.8442 - val_accuracy: 0.4698 - val_loss: 0.7282\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 53ms/step - accuracy: 0.5019 - loss: 0.8456 - val_accuracy: 0.4698 - val_loss: 0.7212\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 54ms/step - accuracy: 0.4898 - loss: 0.8448 - val_accuracy: 0.4698 - val_loss: 0.7017\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 53ms/step - accuracy: 0.5140 - loss: 0.8420 - val_accuracy: 0.4698 - val_loss: 0.7300\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 54ms/step - accuracy: 0.4936 - loss: 0.8427 - val_accuracy: 0.4698 - val_loss: 0.7259\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 54ms/step - accuracy: 0.5024 - loss: 0.8392 - val_accuracy: 0.4698 - val_loss: 0.7481\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 54ms/step - accuracy: 0.5006 - loss: 0.8414 - val_accuracy: 0.6290 - val_loss: 0.6532\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 50ms/step - accuracy: 0.5644 - loss: 0.8117 - val_accuracy: 0.5927 - val_loss: 0.6712\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.6197 - loss: 0.7793 - val_accuracy: 0.6361 - val_loss: 0.6377\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 45ms/step - accuracy: 0.6439 - loss: 0.7593 - val_accuracy: 0.6462 - val_loss: 0.6371\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 49ms/step - accuracy: 0.6596 - loss: 0.7558 - val_accuracy: 0.6341 - val_loss: 0.6500\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 52ms/step - accuracy: 0.6620 - loss: 0.7261 - val_accuracy: 0.6623 - val_loss: 0.6248\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - accuracy: 0.6739 - loss: 0.7149 - val_accuracy: 0.7188 - val_loss: 0.5751\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 50ms/step - accuracy: 0.7068 - loss: 0.6945 - val_accuracy: 0.7188 - val_loss: 0.5665\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 50ms/step - accuracy: 0.7133 - loss: 0.6815 - val_accuracy: 0.7208 - val_loss: 0.5560\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 50ms/step - accuracy: 0.6996 - loss: 0.6895 - val_accuracy: 0.7117 - val_loss: 0.5605\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 55ms/step - accuracy: 0.4968 - loss: 0.8445 - val_accuracy: 0.6129 - val_loss: 0.6547\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 52ms/step - accuracy: 0.5485 - loss: 0.8262 - val_accuracy: 0.5020 - val_loss: 0.6898\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 54ms/step - accuracy: 0.6032 - loss: 0.7729 - val_accuracy: 0.5907 - val_loss: 0.6701\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 57ms/step - accuracy: 0.6135 - loss: 0.7753 - val_accuracy: 0.5988 - val_loss: 0.6725\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - accuracy: 0.4989 - loss: 0.8451 - val_accuracy: 0.4688 - val_loss: 0.8549\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.5477 - loss: 0.8125 - val_accuracy: 0.5655 - val_loss: 0.6983\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - accuracy: 0.5992 - loss: 0.7783 - val_accuracy: 0.5675 - val_loss: 0.6868\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.5832 - loss: 0.7860 - val_accuracy: 0.6149 - val_loss: 0.6638\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.6308 - loss: 0.7691 - val_accuracy: 0.5232 - val_loss: 0.6791\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - accuracy: 0.5880 - loss: 0.7847 - val_accuracy: 0.5726 - val_loss: 0.6796\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.6140 - loss: 0.7663 - val_accuracy: 0.6069 - val_loss: 0.6494\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.6154 - loss: 0.7631 - val_accuracy: 0.6401 - val_loss: 0.6429\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.6391 - loss: 0.7521 - val_accuracy: 0.6210 - val_loss: 0.6708\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.6358 - loss: 0.7494 - val_accuracy: 0.6310 - val_loss: 0.6471\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - accuracy: 0.4959 - loss: 0.8396 - val_accuracy: 0.4738 - val_loss: 0.7059\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.5185 - loss: 0.8552 - val_accuracy: 0.4698 - val_loss: 0.7159\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - accuracy: 0.4971 - loss: 0.8377 - val_accuracy: 0.4698 - val_loss: 0.6990\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.5205 - loss: 0.8152 - val_accuracy: 0.5948 - val_loss: 0.6663\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.6127 - loss: 0.7836 - val_accuracy: 0.5534 - val_loss: 0.6927\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.6186 - loss: 0.7639 - val_accuracy: 0.5655 - val_loss: 0.6946\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.6210 - loss: 0.7579 - val_accuracy: 0.6069 - val_loss: 0.6556\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.6392 - loss: 0.7609 - val_accuracy: 0.6079 - val_loss: 0.6740\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.6304 - loss: 0.7495 - val_accuracy: 0.5615 - val_loss: 0.6969\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.6335 - loss: 0.7578 - val_accuracy: 0.6149 - val_loss: 0.6708\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 60ms/step - accuracy: 0.4953 - loss: 0.8475 - val_accuracy: 0.5544 - val_loss: 0.6830\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.5922 - loss: 0.7957 - val_accuracy: 0.4819 - val_loss: 0.6895\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - accuracy: 0.5734 - loss: 0.7786 - val_accuracy: 0.6200 - val_loss: 0.6615\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.6116 - loss: 0.7755 - val_accuracy: 0.6089 - val_loss: 0.6641\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.6203 - loss: 0.7693 - val_accuracy: 0.5131 - val_loss: 0.7586\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.6146 - loss: 0.7750 - val_accuracy: 0.6169 - val_loss: 0.6628\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.4914 - loss: 0.8535 - val_accuracy: 0.4698 - val_loss: 0.7369\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.5238 - loss: 0.8249 - val_accuracy: 0.5726 - val_loss: 0.6773\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.5877 - loss: 0.7928 - val_accuracy: 0.5050 - val_loss: 0.7048\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.6053 - loss: 0.7843 - val_accuracy: 0.6109 - val_loss: 0.6726\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.6208 - loss: 0.7756 - val_accuracy: 0.5433 - val_loss: 0.6831\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - accuracy: 0.6241 - loss: 0.7640 - val_accuracy: 0.6159 - val_loss: 0.6638\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.6194 - loss: 0.7620 - val_accuracy: 0.6341 - val_loss: 0.6503\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.6476 - loss: 0.7551 - val_accuracy: 0.6371 - val_loss: 0.6311\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.6806 - loss: 0.7229 - val_accuracy: 0.6462 - val_loss: 0.6185\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.6675 - loss: 0.7212 - val_accuracy: 0.6825 - val_loss: 0.5882\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 53ms/step - accuracy: 0.5028 - loss: 0.8358 - val_accuracy: 0.5353 - val_loss: 0.6855\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.5993 - loss: 0.7821 - val_accuracy: 0.5938 - val_loss: 0.6774\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 52ms/step - accuracy: 0.5841 - loss: 0.8116 - val_accuracy: 0.4718 - val_loss: 0.8252\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 50ms/step - accuracy: 0.5850 - loss: 0.7974 - val_accuracy: 0.4960 - val_loss: 0.7376\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 51ms/step - accuracy: 0.6131 - loss: 0.7739 - val_accuracy: 0.5786 - val_loss: 0.6791\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 58ms/step - accuracy: 0.5060 - loss: 0.8369 - val_accuracy: 0.4698 - val_loss: 0.7431\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - accuracy: 0.5092 - loss: 0.8443 - val_accuracy: 0.4698 - val_loss: 0.7767\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 75ms/step - accuracy: 0.4920 - loss: 0.8540 - val_accuracy: 0.4698 - val_loss: 0.7389\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 74ms/step - accuracy: 0.5006 - loss: 0.8436 - val_accuracy: 0.4698 - val_loss: 0.7341\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - accuracy: 0.4992 - loss: 0.8447 - val_accuracy: 0.4698 - val_loss: 0.7384\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 74ms/step - accuracy: 0.5102 - loss: 0.8288 - val_accuracy: 0.5575 - val_loss: 0.6790\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 68ms/step - accuracy: 0.5894 - loss: 0.7899 - val_accuracy: 0.6139 - val_loss: 0.6606\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 55ms/step - accuracy: 0.5919 - loss: 0.7752 - val_accuracy: 0.5756 - val_loss: 0.6696\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.6060 - loss: 0.7623 - val_accuracy: 0.6744 - val_loss: 0.6287\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.6342 - loss: 0.7432 - val_accuracy: 0.6764 - val_loss: 0.6143\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 55ms/step - accuracy: 0.6749 - loss: 0.7005 - val_accuracy: 0.6663 - val_loss: 0.6179\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 57ms/step - accuracy: 0.6831 - loss: 0.7001 - val_accuracy: 0.7268 - val_loss: 0.5608\n",
            "Epoch 13/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 56ms/step - accuracy: 0.6871 - loss: 0.6930 - val_accuracy: 0.4698 - val_loss: 0.7282\n",
            "Epoch 14/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 55ms/step - accuracy: 0.5093 - loss: 0.8410 - val_accuracy: 0.4698 - val_loss: 0.7217\n",
            "Epoch 15/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 55ms/step - accuracy: 0.5135 - loss: 0.8410 - val_accuracy: 0.4698 - val_loss: 0.7108\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 52ms/step - accuracy: 0.4987 - loss: 0.8468 - val_accuracy: 0.4768 - val_loss: 0.6941\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.5680 - loss: 0.7992 - val_accuracy: 0.5766 - val_loss: 0.6739\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 53ms/step - accuracy: 0.6089 - loss: 0.7747 - val_accuracy: 0.5938 - val_loss: 0.6708\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 52ms/step - accuracy: 0.6363 - loss: 0.7675 - val_accuracy: 0.6442 - val_loss: 0.6514\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 52ms/step - accuracy: 0.6213 - loss: 0.7648 - val_accuracy: 0.6028 - val_loss: 0.6673\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 51ms/step - accuracy: 0.6207 - loss: 0.7661 - val_accuracy: 0.6331 - val_loss: 0.6498\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 51ms/step - accuracy: 0.6499 - loss: 0.7452 - val_accuracy: 0.6704 - val_loss: 0.6179\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 51ms/step - accuracy: 0.6459 - loss: 0.7414 - val_accuracy: 0.6562 - val_loss: 0.6234\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.6771 - loss: 0.7136 - val_accuracy: 0.7016 - val_loss: 0.5695\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 53ms/step - accuracy: 0.6783 - loss: 0.7042 - val_accuracy: 0.6966 - val_loss: 0.5882\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 50ms/step - accuracy: 0.7007 - loss: 0.6832 - val_accuracy: 0.6815 - val_loss: 0.5701\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 52ms/step - accuracy: 0.6964 - loss: 0.6939 - val_accuracy: 0.6986 - val_loss: 0.5722\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 57ms/step - accuracy: 0.5169 - loss: 0.8362 - val_accuracy: 0.4698 - val_loss: 0.7236\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 55ms/step - accuracy: 0.5381 - loss: 0.8080 - val_accuracy: 0.6139 - val_loss: 0.6583\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 57ms/step - accuracy: 0.5880 - loss: 0.7912 - val_accuracy: 0.6089 - val_loss: 0.6643\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.6090 - loss: 0.7769 - val_accuracy: 0.6280 - val_loss: 0.6454\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 55ms/step - accuracy: 0.6220 - loss: 0.7595 - val_accuracy: 0.6462 - val_loss: 0.6462\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 56ms/step - accuracy: 0.6375 - loss: 0.7483 - val_accuracy: 0.5907 - val_loss: 0.6871\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 56ms/step - accuracy: 0.6815 - loss: 0.7086 - val_accuracy: 0.7046 - val_loss: 0.5628\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.6870 - loss: 0.6995 - val_accuracy: 0.6734 - val_loss: 0.5905\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 55ms/step - accuracy: 0.7146 - loss: 0.6735 - val_accuracy: 0.6411 - val_loss: 0.6205\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 57ms/step - accuracy: 0.7160 - loss: 0.6552 - val_accuracy: 0.7278 - val_loss: 0.5293\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.7078 - loss: 0.6677 - val_accuracy: 0.7198 - val_loss: 0.5451\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.7264 - loss: 0.6567 - val_accuracy: 0.7258 - val_loss: 0.5429\n",
            "Epoch 13/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.7431 - loss: 0.6274 - val_accuracy: 0.7077 - val_loss: 0.5744\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - accuracy: 0.5048 - loss: 0.8476 - val_accuracy: 0.4829 - val_loss: 0.7029\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 55ms/step - accuracy: 0.5634 - loss: 0.8103 - val_accuracy: 0.5433 - val_loss: 0.6815\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.5903 - loss: 0.7829 - val_accuracy: 0.5917 - val_loss: 0.6852\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.6397 - loss: 0.7644 - val_accuracy: 0.5978 - val_loss: 0.6755\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.6378 - loss: 0.7507 - val_accuracy: 0.6371 - val_loss: 0.6583\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.6217 - loss: 0.7781 - val_accuracy: 0.6210 - val_loss: 0.6565\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 0.6150 - loss: 0.7811 - val_accuracy: 0.6200 - val_loss: 0.6676\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.6651 - loss: 0.7443 - val_accuracy: 0.6351 - val_loss: 0.6537\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.6309 - loss: 0.7539 - val_accuracy: 0.6542 - val_loss: 0.6195\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.6280 - loss: 0.7613 - val_accuracy: 0.6502 - val_loss: 0.6700\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.6695 - loss: 0.7383 - val_accuracy: 0.6986 - val_loss: 0.5845\n",
            "Epoch 12/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.6727 - loss: 0.7228 - val_accuracy: 0.6794 - val_loss: 0.6025\n",
            "Epoch 13/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.6788 - loss: 0.7100 - val_accuracy: 0.6018 - val_loss: 0.6647\n",
            "Epoch 14/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - accuracy: 0.6534 - loss: 0.7345 - val_accuracy: 0.6835 - val_loss: 0.5906\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 61ms/step - accuracy: 0.5099 - loss: 0.8387 - val_accuracy: 0.4677 - val_loss: 0.7088\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.5185 - loss: 0.8195 - val_accuracy: 0.5353 - val_loss: 0.6845\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.5689 - loss: 0.8037 - val_accuracy: 0.5373 - val_loss: 0.7065\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - accuracy: 0.6001 - loss: 0.7843 - val_accuracy: 0.5786 - val_loss: 0.6753\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.6192 - loss: 0.7774 - val_accuracy: 0.6048 - val_loss: 0.6728\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.6278 - loss: 0.7642 - val_accuracy: 0.6119 - val_loss: 0.6665\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.6385 - loss: 0.7593 - val_accuracy: 0.6119 - val_loss: 0.6749\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.6455 - loss: 0.7532 - val_accuracy: 0.6391 - val_loss: 0.6418\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - accuracy: 0.6631 - loss: 0.7450 - val_accuracy: 0.6613 - val_loss: 0.6180\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.6700 - loss: 0.7219 - val_accuracy: 0.6371 - val_loss: 0.6565\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.6779 - loss: 0.7090 - val_accuracy: 0.7046 - val_loss: 0.5852\n",
            "Epoch 12/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.6893 - loss: 0.7000 - val_accuracy: 0.6935 - val_loss: 0.5825\n",
            "Epoch 13/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.7039 - loss: 0.6704 - val_accuracy: 0.7238 - val_loss: 0.5602\n",
            "Epoch 14/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 0.7054 - loss: 0.6735 - val_accuracy: 0.7067 - val_loss: 0.5598\n",
            "Epoch 15/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - accuracy: 0.6994 - loss: 0.6746 - val_accuracy: 0.7087 - val_loss: 0.5550\n",
            "Epoch 16/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.7112 - loss: 0.6626 - val_accuracy: 0.7238 - val_loss: 0.5411\n",
            "Epoch 17/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.7243 - loss: 0.6554 - val_accuracy: 0.7258 - val_loss: 0.5521\n",
            "Epoch 18/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.7120 - loss: 0.6729 - val_accuracy: 0.7288 - val_loss: 0.5428\n",
            "Epoch 19/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.7298 - loss: 0.6560 - val_accuracy: 0.7409 - val_loss: 0.5615\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - accuracy: 0.5110 - loss: 0.8409 - val_accuracy: 0.5232 - val_loss: 0.6893\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.5714 - loss: 0.8116 - val_accuracy: 0.4698 - val_loss: 0.7415\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.5104 - loss: 0.8431 - val_accuracy: 0.4698 - val_loss: 0.7041\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.5023 - loss: 0.8462 - val_accuracy: 0.4698 - val_loss: 0.7289\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.4990 - loss: 0.8436 - val_accuracy: 0.5938 - val_loss: 0.6756\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.5496 - loss: 0.8169 - val_accuracy: 0.4980 - val_loss: 0.7000\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.6002 - loss: 0.7734 - val_accuracy: 0.5292 - val_loss: 0.6875\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 56ms/step - accuracy: 0.6055 - loss: 0.7681 - val_accuracy: 0.6129 - val_loss: 0.6618\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.6356 - loss: 0.7590 - val_accuracy: 0.6190 - val_loss: 0.6532\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.6351 - loss: 0.7631 - val_accuracy: 0.6179 - val_loss: 0.6535\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.6342 - loss: 0.7579 - val_accuracy: 0.6159 - val_loss: 0.6641\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.6440 - loss: 0.7620 - val_accuracy: 0.6169 - val_loss: 0.6452\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.6166 - loss: 0.7705 - val_accuracy: 0.6109 - val_loss: 0.6725\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.6430 - loss: 0.7571 - val_accuracy: 0.6512 - val_loss: 0.6419\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.6506 - loss: 0.7487 - val_accuracy: 0.6351 - val_loss: 0.6479\n",
            "Epoch 12/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.6446 - loss: 0.7460 - val_accuracy: 0.6532 - val_loss: 0.6343\n",
            "Epoch 13/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - accuracy: 0.6331 - loss: 0.7451 - val_accuracy: 0.6784 - val_loss: 0.5948\n",
            "Epoch 14/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.7036 - loss: 0.6924 - val_accuracy: 0.7147 - val_loss: 0.5538\n",
            "Epoch 15/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.6916 - loss: 0.6909 - val_accuracy: 0.7198 - val_loss: 0.5534\n",
            "Epoch 16/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.6873 - loss: 0.7034 - val_accuracy: 0.7319 - val_loss: 0.5561\n",
            "Epoch 17/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.7075 - loss: 0.6727 - val_accuracy: 0.7016 - val_loss: 0.5715\n",
            "Epoch 18/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - accuracy: 0.7077 - loss: 0.6779 - val_accuracy: 0.6895 - val_loss: 0.5742\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
            "Training CNN...\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.5064 - loss: 0.8187 - val_accuracy: 0.6018 - val_loss: 0.6659\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5886 - loss: 0.7773 - val_accuracy: 0.6452 - val_loss: 0.6445\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6473 - loss: 0.7468 - val_accuracy: 0.6552 - val_loss: 0.6273\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6820 - loss: 0.7212 - val_accuracy: 0.7006 - val_loss: 0.5902\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7024 - loss: 0.7001 - val_accuracy: 0.6946 - val_loss: 0.5958\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6877 - loss: 0.6886 - val_accuracy: 0.7238 - val_loss: 0.5650\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7162 - loss: 0.6693 - val_accuracy: 0.7329 - val_loss: 0.5593\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7179 - loss: 0.6588 - val_accuracy: 0.7157 - val_loss: 0.5627\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7310 - loss: 0.6406 - val_accuracy: 0.6986 - val_loss: 0.5734\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7338 - loss: 0.6375 - val_accuracy: 0.7006 - val_loss: 0.5688\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.4972 - loss: 0.8350 - val_accuracy: 0.5958 - val_loss: 0.6642\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6230 - loss: 0.7651 - val_accuracy: 0.6623 - val_loss: 0.6305\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6844 - loss: 0.7131 - val_accuracy: 0.6018 - val_loss: 0.6632\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6752 - loss: 0.7032 - val_accuracy: 0.5837 - val_loss: 0.6791\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6932 - loss: 0.6880 - val_accuracy: 0.7046 - val_loss: 0.5641\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7032 - loss: 0.6820 - val_accuracy: 0.7258 - val_loss: 0.5511\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7190 - loss: 0.6471 - val_accuracy: 0.7339 - val_loss: 0.5451\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7129 - loss: 0.6576 - val_accuracy: 0.6996 - val_loss: 0.5584\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7247 - loss: 0.6545 - val_accuracy: 0.7329 - val_loss: 0.5328\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7342 - loss: 0.6273 - val_accuracy: 0.7258 - val_loss: 0.5392\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.5070 - loss: 0.8224 - val_accuracy: 0.4698 - val_loss: 0.6877\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5669 - loss: 0.7849 - val_accuracy: 0.5948 - val_loss: 0.6628\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6328 - loss: 0.7445 - val_accuracy: 0.6774 - val_loss: 0.6192\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6836 - loss: 0.7257 - val_accuracy: 0.6855 - val_loss: 0.6107\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6841 - loss: 0.7048 - val_accuracy: 0.7056 - val_loss: 0.5878\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7082 - loss: 0.6792 - val_accuracy: 0.7208 - val_loss: 0.5742\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7045 - loss: 0.6787 - val_accuracy: 0.6996 - val_loss: 0.5835\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7194 - loss: 0.6600 - val_accuracy: 0.6008 - val_loss: 0.6523\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6963 - loss: 0.6751 - val_accuracy: 0.7329 - val_loss: 0.5481\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7429 - loss: 0.6397 - val_accuracy: 0.7369 - val_loss: 0.5467\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5068 - loss: 0.8218 - val_accuracy: 0.4758 - val_loss: 0.6842\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5979 - loss: 0.7740 - val_accuracy: 0.6300 - val_loss: 0.6502\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6624 - loss: 0.7313 - val_accuracy: 0.6663 - val_loss: 0.6037\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6877 - loss: 0.7075 - val_accuracy: 0.6613 - val_loss: 0.6111\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6921 - loss: 0.6862 - val_accuracy: 0.6482 - val_loss: 0.6083\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7338 - loss: 0.6445 - val_accuracy: 0.7349 - val_loss: 0.5589\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7280 - loss: 0.6420 - val_accuracy: 0.6542 - val_loss: 0.6058\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7187 - loss: 0.6527 - val_accuracy: 0.7198 - val_loss: 0.5585\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7268 - loss: 0.6591 - val_accuracy: 0.7228 - val_loss: 0.5528\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7423 - loss: 0.6269 - val_accuracy: 0.7288 - val_loss: 0.5491\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5046 - loss: 0.8236 - val_accuracy: 0.4698 - val_loss: 0.6946\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5542 - loss: 0.7797 - val_accuracy: 0.6341 - val_loss: 0.6535\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6097 - loss: 0.7558 - val_accuracy: 0.6734 - val_loss: 0.6219\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6772 - loss: 0.7211 - val_accuracy: 0.6573 - val_loss: 0.6397\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6636 - loss: 0.7238 - val_accuracy: 0.6744 - val_loss: 0.6181\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6891 - loss: 0.7048 - val_accuracy: 0.6562 - val_loss: 0.6255\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6902 - loss: 0.6960 - val_accuracy: 0.6482 - val_loss: 0.6293\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6802 - loss: 0.6996 - val_accuracy: 0.7026 - val_loss: 0.5841\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7142 - loss: 0.6643 - val_accuracy: 0.6633 - val_loss: 0.6101\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7090 - loss: 0.6650 - val_accuracy: 0.7046 - val_loss: 0.5777\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.5011 - loss: 0.8242 - val_accuracy: 0.6280 - val_loss: 0.6604\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6024 - loss: 0.7704 - val_accuracy: 0.6663 - val_loss: 0.6291\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6626 - loss: 0.7355 - val_accuracy: 0.6694 - val_loss: 0.6259\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6731 - loss: 0.7211 - val_accuracy: 0.6804 - val_loss: 0.6069\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6803 - loss: 0.7040 - val_accuracy: 0.6976 - val_loss: 0.5933\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7074 - loss: 0.6807 - val_accuracy: 0.7167 - val_loss: 0.5645\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7221 - loss: 0.6506 - val_accuracy: 0.6542 - val_loss: 0.6147\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6967 - loss: 0.6622 - val_accuracy: 0.7137 - val_loss: 0.5605\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7379 - loss: 0.6288 - val_accuracy: 0.6643 - val_loss: 0.6005\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7285 - loss: 0.6489 - val_accuracy: 0.6905 - val_loss: 0.5750\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.4913 - loss: 0.8689 - val_accuracy: 0.4698 - val_loss: 0.6898\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5066 - loss: 0.7968 - val_accuracy: 0.5534 - val_loss: 0.6714\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6134 - loss: 0.7723 - val_accuracy: 0.6633 - val_loss: 0.6379\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6515 - loss: 0.7509 - val_accuracy: 0.6825 - val_loss: 0.6209\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6660 - loss: 0.7323 - val_accuracy: 0.6925 - val_loss: 0.6107\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6898 - loss: 0.7216 - val_accuracy: 0.6815 - val_loss: 0.6090\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6868 - loss: 0.7069 - val_accuracy: 0.6694 - val_loss: 0.6145\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6971 - loss: 0.6929 - val_accuracy: 0.7107 - val_loss: 0.5793\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6892 - loss: 0.6941 - val_accuracy: 0.6925 - val_loss: 0.5919\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7161 - loss: 0.6759 - val_accuracy: 0.7258 - val_loss: 0.5675\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4884 - loss: 0.8376 - val_accuracy: 0.4889 - val_loss: 0.6778\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5202 - loss: 0.7869 - val_accuracy: 0.6613 - val_loss: 0.6388\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6616 - loss: 0.7398 - val_accuracy: 0.6714 - val_loss: 0.6240\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6768 - loss: 0.7313 - val_accuracy: 0.6865 - val_loss: 0.6096\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6868 - loss: 0.7176 - val_accuracy: 0.6996 - val_loss: 0.5806\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6920 - loss: 0.7008 - val_accuracy: 0.7046 - val_loss: 0.5753\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7182 - loss: 0.6763 - val_accuracy: 0.7218 - val_loss: 0.5663\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7229 - loss: 0.6540 - val_accuracy: 0.6351 - val_loss: 0.6184\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7146 - loss: 0.6592 - val_accuracy: 0.7329 - val_loss: 0.5572\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7241 - loss: 0.6479 - val_accuracy: 0.7147 - val_loss: 0.5436\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.5070 - loss: 0.8208 - val_accuracy: 0.6421 - val_loss: 0.6589\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5838 - loss: 0.7784 - val_accuracy: 0.6623 - val_loss: 0.6311\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6454 - loss: 0.7443 - val_accuracy: 0.6875 - val_loss: 0.6009\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6657 - loss: 0.7168 - val_accuracy: 0.6754 - val_loss: 0.6156\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6776 - loss: 0.7075 - val_accuracy: 0.7097 - val_loss: 0.5810\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7188 - loss: 0.6679 - val_accuracy: 0.7188 - val_loss: 0.5576\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7169 - loss: 0.6578 - val_accuracy: 0.7329 - val_loss: 0.5551\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7269 - loss: 0.6492 - val_accuracy: 0.6673 - val_loss: 0.5919\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7217 - loss: 0.6394 - val_accuracy: 0.7369 - val_loss: 0.5372\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7219 - loss: 0.6334 - val_accuracy: 0.7167 - val_loss: 0.5522\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7328 - loss: 0.6212 - val_accuracy: 0.7409 - val_loss: 0.5355\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7488 - loss: 0.6166 - val_accuracy: 0.7369 - val_loss: 0.5296\n",
            "Epoch 13/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7448 - loss: 0.6138 - val_accuracy: 0.7167 - val_loss: 0.5520\n",
            "Epoch 14/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7341 - loss: 0.6201 - val_accuracy: 0.7429 - val_loss: 0.5120\n",
            "Epoch 15/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7567 - loss: 0.6033 - val_accuracy: 0.6956 - val_loss: 0.5610\n",
            "Epoch 16/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7452 - loss: 0.6010 - val_accuracy: 0.7560 - val_loss: 0.5070\n",
            "Epoch 17/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7440 - loss: 0.6100 - val_accuracy: 0.7248 - val_loss: 0.5352\n",
            "Epoch 18/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7608 - loss: 0.5735 - val_accuracy: 0.7470 - val_loss: 0.5231\n",
            "Epoch 19/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7530 - loss: 0.5975 - val_accuracy: 0.7117 - val_loss: 0.5408\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.4971 - loss: 0.8183 - val_accuracy: 0.5121 - val_loss: 0.6749\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6284 - loss: 0.7550 - val_accuracy: 0.6683 - val_loss: 0.6252\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6733 - loss: 0.7128 - val_accuracy: 0.6935 - val_loss: 0.5842\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7036 - loss: 0.6774 - val_accuracy: 0.7147 - val_loss: 0.5702\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7079 - loss: 0.6773 - val_accuracy: 0.6825 - val_loss: 0.5938\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7217 - loss: 0.6407 - val_accuracy: 0.6734 - val_loss: 0.5943\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7196 - loss: 0.6497 - val_accuracy: 0.6976 - val_loss: 0.5724\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.4916 - loss: 0.8271 - val_accuracy: 0.4788 - val_loss: 0.6818\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5762 - loss: 0.7795 - val_accuracy: 0.6280 - val_loss: 0.6536\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6546 - loss: 0.7352 - val_accuracy: 0.6683 - val_loss: 0.6258\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6842 - loss: 0.7178 - val_accuracy: 0.6905 - val_loss: 0.6017\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6813 - loss: 0.7064 - val_accuracy: 0.7036 - val_loss: 0.5924\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6878 - loss: 0.6956 - val_accuracy: 0.7188 - val_loss: 0.5760\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7072 - loss: 0.6706 - val_accuracy: 0.7177 - val_loss: 0.5692\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7064 - loss: 0.6690 - val_accuracy: 0.7208 - val_loss: 0.5560\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7185 - loss: 0.6592 - val_accuracy: 0.6714 - val_loss: 0.5923\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7125 - loss: 0.6492 - val_accuracy: 0.7127 - val_loss: 0.5683\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7278 - loss: 0.6351 - val_accuracy: 0.6855 - val_loss: 0.5787\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5085 - loss: 0.8229 - val_accuracy: 0.5907 - val_loss: 0.6646\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6135 - loss: 0.7650 - val_accuracy: 0.6815 - val_loss: 0.6127\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6563 - loss: 0.7379 - val_accuracy: 0.6915 - val_loss: 0.5979\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6699 - loss: 0.7122 - val_accuracy: 0.7016 - val_loss: 0.5869\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7031 - loss: 0.6750 - val_accuracy: 0.7248 - val_loss: 0.5686\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7190 - loss: 0.6593 - val_accuracy: 0.7077 - val_loss: 0.5649\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7225 - loss: 0.6543 - val_accuracy: 0.7218 - val_loss: 0.5529\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7258 - loss: 0.6422 - val_accuracy: 0.7268 - val_loss: 0.5469\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7304 - loss: 0.6389 - val_accuracy: 0.6048 - val_loss: 0.6811\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7274 - loss: 0.6457 - val_accuracy: 0.7399 - val_loss: 0.5303\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7307 - loss: 0.6218 - val_accuracy: 0.7419 - val_loss: 0.5296\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7196 - loss: 0.6372 - val_accuracy: 0.7298 - val_loss: 0.5391\n",
            "Epoch 13/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7440 - loss: 0.6142 - val_accuracy: 0.7329 - val_loss: 0.5324\n",
            "Epoch 14/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7665 - loss: 0.5857 - val_accuracy: 0.7450 - val_loss: 0.5250\n",
            "Epoch 15/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7406 - loss: 0.6004 - val_accuracy: 0.7560 - val_loss: 0.5097\n",
            "Epoch 16/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7433 - loss: 0.6158 - val_accuracy: 0.7409 - val_loss: 0.5216\n",
            "Epoch 17/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7239 - loss: 0.6264 - val_accuracy: 0.7611 - val_loss: 0.5119\n",
            "Epoch 18/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7708 - loss: 0.5785 - val_accuracy: 0.7550 - val_loss: 0.4986\n",
            "Epoch 19/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7561 - loss: 0.5922 - val_accuracy: 0.7671 - val_loss: 0.5015\n",
            "Epoch 20/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7478 - loss: 0.5856 - val_accuracy: 0.7712 - val_loss: 0.4961\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.5063 - loss: 0.8215 - val_accuracy: 0.4940 - val_loss: 0.6759\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5305 - loss: 0.7875 - val_accuracy: 0.6351 - val_loss: 0.6529\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6322 - loss: 0.7580 - val_accuracy: 0.6865 - val_loss: 0.6210\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6541 - loss: 0.7391 - val_accuracy: 0.6643 - val_loss: 0.6206\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6758 - loss: 0.7238 - val_accuracy: 0.6633 - val_loss: 0.6254\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6780 - loss: 0.7087 - val_accuracy: 0.6371 - val_loss: 0.6398\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6905 - loss: 0.7015 - val_accuracy: 0.7077 - val_loss: 0.5857\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7153 - loss: 0.6832 - val_accuracy: 0.7167 - val_loss: 0.5720\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7003 - loss: 0.6807 - val_accuracy: 0.6643 - val_loss: 0.6078\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7053 - loss: 0.6655 - val_accuracy: 0.7218 - val_loss: 0.5609\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7283 - loss: 0.6489 - val_accuracy: 0.7147 - val_loss: 0.5640\n",
            "Epoch 12/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7340 - loss: 0.6277 - val_accuracy: 0.7298 - val_loss: 0.5460\n",
            "Epoch 13/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7262 - loss: 0.6360 - val_accuracy: 0.7107 - val_loss: 0.5665\n",
            "Epoch 14/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7249 - loss: 0.6286 - val_accuracy: 0.6976 - val_loss: 0.5792\n",
            "Epoch 15/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7372 - loss: 0.6276 - val_accuracy: 0.7298 - val_loss: 0.5484\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.5020 - loss: 0.8209 - val_accuracy: 0.4698 - val_loss: 0.6988\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5961 - loss: 0.7778 - val_accuracy: 0.6643 - val_loss: 0.6318\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6506 - loss: 0.7433 - val_accuracy: 0.6694 - val_loss: 0.6196\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6664 - loss: 0.7178 - val_accuracy: 0.6472 - val_loss: 0.6281\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6842 - loss: 0.6944 - val_accuracy: 0.7137 - val_loss: 0.5772\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7086 - loss: 0.6729 - val_accuracy: 0.7127 - val_loss: 0.5728\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7046 - loss: 0.6628 - val_accuracy: 0.6935 - val_loss: 0.5688\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7161 - loss: 0.6538 - val_accuracy: 0.7298 - val_loss: 0.5518\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7173 - loss: 0.6439 - val_accuracy: 0.7268 - val_loss: 0.5491\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7189 - loss: 0.6329 - val_accuracy: 0.7409 - val_loss: 0.5357\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7573 - loss: 0.6079 - val_accuracy: 0.7127 - val_loss: 0.5525\n",
            "Epoch 12/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7379 - loss: 0.6153 - val_accuracy: 0.7399 - val_loss: 0.5361\n",
            "Epoch 13/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7475 - loss: 0.6091 - val_accuracy: 0.7097 - val_loss: 0.5596\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.5028 - loss: 0.8370 - val_accuracy: 0.4698 - val_loss: 0.7078\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5124 - loss: 0.8082 - val_accuracy: 0.4698 - val_loss: 0.6850\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5368 - loss: 0.7941 - val_accuracy: 0.6290 - val_loss: 0.6578\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6085 - loss: 0.7559 - val_accuracy: 0.6220 - val_loss: 0.6538\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6338 - loss: 0.7317 - val_accuracy: 0.6925 - val_loss: 0.6141\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6748 - loss: 0.7207 - val_accuracy: 0.7006 - val_loss: 0.6009\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6974 - loss: 0.6966 - val_accuracy: 0.6804 - val_loss: 0.6067\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7110 - loss: 0.6819 - val_accuracy: 0.7167 - val_loss: 0.5805\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7003 - loss: 0.6858 - val_accuracy: 0.7046 - val_loss: 0.5867\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7105 - loss: 0.6672 - val_accuracy: 0.7349 - val_loss: 0.5607\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7167 - loss: 0.6706 - val_accuracy: 0.7188 - val_loss: 0.5740\n",
            "Epoch 12/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7147 - loss: 0.6483 - val_accuracy: 0.7238 - val_loss: 0.5660\n",
            "Epoch 13/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7278 - loss: 0.6430 - val_accuracy: 0.7298 - val_loss: 0.5427\n",
            "Epoch 14/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7281 - loss: 0.6433 - val_accuracy: 0.7440 - val_loss: 0.5438\n",
            "Epoch 15/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7299 - loss: 0.6386 - val_accuracy: 0.7319 - val_loss: 0.5499\n",
            "Epoch 16/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7318 - loss: 0.6308 - val_accuracy: 0.7490 - val_loss: 0.5322\n",
            "Epoch 17/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7423 - loss: 0.6185 - val_accuracy: 0.7440 - val_loss: 0.5322\n",
            "Epoch 18/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7395 - loss: 0.6233 - val_accuracy: 0.7399 - val_loss: 0.5373\n",
            "Epoch 19/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7378 - loss: 0.6333 - val_accuracy: 0.7450 - val_loss: 0.5263\n",
            "Epoch 20/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7388 - loss: 0.6230 - val_accuracy: 0.7520 - val_loss: 0.5217\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.5025 - loss: 0.8297 - val_accuracy: 0.4698 - val_loss: 0.6916\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5229 - loss: 0.7899 - val_accuracy: 0.6361 - val_loss: 0.6529\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6330 - loss: 0.7565 - val_accuracy: 0.6724 - val_loss: 0.6275\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6751 - loss: 0.7205 - val_accuracy: 0.6895 - val_loss: 0.5997\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6748 - loss: 0.7126 - val_accuracy: 0.6996 - val_loss: 0.5891\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6863 - loss: 0.6929 - val_accuracy: 0.7137 - val_loss: 0.5759\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7114 - loss: 0.6788 - val_accuracy: 0.7208 - val_loss: 0.5628\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7282 - loss: 0.6532 - val_accuracy: 0.7329 - val_loss: 0.5533\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6827 - loss: 0.6895 - val_accuracy: 0.6603 - val_loss: 0.6081\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7226 - loss: 0.6420 - val_accuracy: 0.7379 - val_loss: 0.5447\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7215 - loss: 0.6383 - val_accuracy: 0.7550 - val_loss: 0.5373\n",
            "Epoch 12/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7263 - loss: 0.6275 - val_accuracy: 0.7137 - val_loss: 0.5384\n",
            "Epoch 13/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7362 - loss: 0.6344 - val_accuracy: 0.6784 - val_loss: 0.5768\n",
            "Epoch 14/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7350 - loss: 0.6183 - val_accuracy: 0.7198 - val_loss: 0.5554\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Experiment completed. Results saved.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Conv1D, GlobalMaxPooling1D, Dropout, Input, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import joblib\n",
        "import json\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Set paths\n",
        "data_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/data.xlsx\"\n",
        "save_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/deep_learning_results5\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_excel(data_path)\n",
        "df.dropna(inplace=True)\n",
        "print(\"Size of DataFrame after dropping null values:\", df.shape)\n",
        "\n",
        "# Function to parse vector strings into numpy arrays\n",
        "def parse_vector(vector_str, expected_dim):\n",
        "    try:\n",
        "        if isinstance(vector_str, str):\n",
        "            vec = np.array([float(i) for i in vector_str.strip(\"[]\").split()], dtype=np.float32)\n",
        "            if vec.shape[0] == expected_dim:\n",
        "                return vec\n",
        "            elif vec.shape[0] > expected_dim:\n",
        "                return vec[:expected_dim]  # Truncate to expected size\n",
        "            else:\n",
        "                return np.pad(vec, (0, expected_dim - vec.shape[0]))  # Pad with zeros\n",
        "    except:\n",
        "        return np.zeros(expected_dim, dtype=np.float32)  # Default to zero vector\n",
        "    return np.zeros(expected_dim, dtype=np.float32)\n",
        "\n",
        "# Define expected dimensions\n",
        "word2vec_dim = 300\n",
        "fasttext_dim = 300\n",
        "sentence_embedding_dim = 300\n",
        "sinbert_dim = 768  # Larger than others\n",
        "\n",
        "# Apply parsing with dimension corrections\n",
        "df['word2vec_vector'] = df['word2vec_vector'].map(lambda x: parse_vector(x, word2vec_dim))\n",
        "df['fasttext_vector'] = df['fasttext_vector'].map(lambda x: parse_vector(x, fasttext_dim))\n",
        "df['sentence_embedding'] = df['sentence_embedding'].map(lambda x: parse_vector(x, sentence_embedding_dim))\n",
        "df['sinbert_vector'] = df['sinbert_vector'].map(lambda x: parse_vector(x, sinbert_dim))  # Keep 768D\n",
        "\n",
        "# Ensure all feature vectors have the same final dimension\n",
        "final_dim = 768  # Choose larger or normalize to 300\n",
        "for feature in ['word2vec_vector', 'fasttext_vector', 'sentence_embedding']:\n",
        "    df[feature] = df[feature].map(lambda x: np.pad(x, (0, final_dim - x.shape[0])) if x.shape[0] < final_dim else x[:final_dim])\n",
        "\n",
        "# Stack feature vectors correctly\n",
        "X = np.stack(df[['word2vec_vector', 'fasttext_vector', 'sentence_embedding', 'sinbert_vector']].apply(lambda row: np.column_stack(row.values), axis=1).values)\n",
        "\n",
        "# Flatten X for MLP: (samples, final_dim * 4)\n",
        "X_flattened = X.reshape(X.shape[0], -1)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'].values)\n",
        "joblib.dump(label_encoder, os.path.join(save_path, 'label_encoder.pkl'))\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train_flattened, X_test_flattened = train_test_split(X_flattened, test_size=0.2, random_state=42)\n",
        "\n",
        "# Function to implement early stopping and class weights\n",
        "def build_mlp(input_shape, dropout_rate, dense_units):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Dense(dense_units, activation='relu'),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(dense_units // 2, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_lstm(input_shape, dropout_rate, lstm_units):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        LSTM(lstm_units, return_sequences=True),\n",
        "        Dropout(dropout_rate),\n",
        "        LSTM(lstm_units // 2),\n",
        "        Flatten(),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_cnn(input_shape, dropout_rate, filters):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Conv1D(filters, kernel_size=3, activation='relu'),\n",
        "        Dropout(dropout_rate),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(filters // 2, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Early stopping callback to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Apply class weights (use if there is class imbalance)\n",
        "class_weights = {0: 1, 1: 1.5}  # Increase weight for the minority class\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"confusion_matrix\": conf_matrix.tolist()\n",
        "    }\n",
        "\n",
        "# Train and evaluate models with hyperparameter tuning and regularization\n",
        "results = {}\n",
        "\n",
        "# Model hyperparameters for tuning\n",
        "params = {\n",
        "    'MLP': {\n",
        "        'epochs': [10, 20],\n",
        "        'batch_size': [16, 32],\n",
        "        'dropout': [0.2, 0.3],\n",
        "        'dense_units': [64, 128]\n",
        "    },\n",
        "    'LSTM': {\n",
        "        'epochs': [10, 20],\n",
        "        'batch_size': [16, 32],\n",
        "        'dropout': [0.2, 0.3],\n",
        "        'lstm_units': [64, 128],\n",
        "    },\n",
        "    'CNN': {\n",
        "        'epochs': [10, 20],\n",
        "        'batch_size': [16, 32],\n",
        "        'dropout': [0.2, 0.3],\n",
        "        'filters': [64, 128],\n",
        "    }\n",
        "}\n",
        "\n",
        "# Train and evaluate each model\n",
        "for name in ['MLP', 'LSTM', 'CNN']:\n",
        "    print(f\"Training {name}...\")\n",
        "\n",
        "    # Hyperparameter grid search (manually tuned here)\n",
        "    for epochs in params[name]['epochs']:\n",
        "        for batch_size in params[name]['batch_size']:\n",
        "            if name == 'MLP':\n",
        "                for dropout in params[name]['dropout']:\n",
        "                    for dense_units in params[name]['dense_units']:\n",
        "                        model_instance = build_mlp((X_train_flattened.shape[1],), dropout, dense_units)\n",
        "                        model_instance.fit(X_train_flattened, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                                           validation_data=(X_test_flattened, y_test), class_weight=class_weights,\n",
        "                                           callbacks=[early_stopping], verbose=1)\n",
        "                        y_pred = (model_instance.predict(X_test_flattened) > 0.5).astype(int)\n",
        "                        results[name] = evaluate_model(y_test, y_pred)\n",
        "            elif name == 'LSTM':\n",
        "                for dropout in params[name]['dropout']:\n",
        "                    for lstm_units in params[name]['lstm_units']:\n",
        "                        model_instance = build_lstm((X_train.shape[1], X_train.shape[2]), dropout, lstm_units)\n",
        "                        model_instance.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                                           validation_data=(X_test, y_test), class_weight=class_weights,\n",
        "                                           callbacks=[early_stopping], verbose=1)\n",
        "                        y_pred = (model_instance.predict(X_test) > 0.5).astype(int)\n",
        "                        results[name] = evaluate_model(y_test, y_pred)\n",
        "            elif name == 'CNN':\n",
        "                for dropout in params[name]['dropout']:\n",
        "                    for filters in params[name]['filters']:\n",
        "                        model_instance = build_cnn((X_train.shape[1], X_train.shape[2]), dropout, filters)\n",
        "                        model_instance.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                                           validation_data=(X_test, y_test), class_weight=class_weights,\n",
        "                                           callbacks=[early_stopping], verbose=1)\n",
        "                        y_pred = (model_instance.predict(X_test) > 0.5).astype(int)\n",
        "                        results[name] = evaluate_model(y_test, y_pred)\n",
        "\n",
        "# Save results to JSON\n",
        "results_path = os.path.join(save_path, \"model_results.json\")\n",
        "with open(results_path, \"w\") as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n",
        "print(\"Experiment completed. Results saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kGLZv8EKIRfA",
        "outputId": "ca83f0d7-1c64-4abe-c896-f10c71ad2e66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of DataFrame after dropping null values: (4958, 8)\n",
            "Training MLP...\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.7410 - loss: 0.6352 - val_accuracy: 0.8034 - val_loss: 0.4331\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7975 - loss: 0.5205 - val_accuracy: 0.8054 - val_loss: 0.4397\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8096 - loss: 0.4943 - val_accuracy: 0.8044 - val_loss: 0.4558\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8306 - loss: 0.4660 - val_accuracy: 0.8054 - val_loss: 0.4368\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.7369 - loss: 0.6140 - val_accuracy: 0.7712 - val_loss: 0.4973\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7986 - loss: 0.5121 - val_accuracy: 0.7712 - val_loss: 0.4900\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8150 - loss: 0.4867 - val_accuracy: 0.8054 - val_loss: 0.4333\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8189 - loss: 0.4722 - val_accuracy: 0.8054 - val_loss: 0.4412\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8187 - loss: 0.4601 - val_accuracy: 0.7560 - val_loss: 0.5050\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8377 - loss: 0.4246 - val_accuracy: 0.8135 - val_loss: 0.4251\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8477 - loss: 0.4122 - val_accuracy: 0.8095 - val_loss: 0.4226\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8523 - loss: 0.4047 - val_accuracy: 0.8125 - val_loss: 0.4356\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8529 - loss: 0.3958 - val_accuracy: 0.7812 - val_loss: 0.4797\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8569 - loss: 0.3946 - val_accuracy: 0.8155 - val_loss: 0.4324\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6965 - loss: 0.6555 - val_accuracy: 0.7944 - val_loss: 0.4430\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7987 - loss: 0.5266 - val_accuracy: 0.7984 - val_loss: 0.4434\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7995 - loss: 0.5185 - val_accuracy: 0.8065 - val_loss: 0.4389\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8038 - loss: 0.5160 - val_accuracy: 0.8075 - val_loss: 0.4267\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8264 - loss: 0.4674 - val_accuracy: 0.8054 - val_loss: 0.4392\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8221 - loss: 0.4671 - val_accuracy: 0.8095 - val_loss: 0.4331\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8365 - loss: 0.4462 - val_accuracy: 0.7843 - val_loss: 0.4775\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.7421 - loss: 0.6158 - val_accuracy: 0.7833 - val_loss: 0.4670\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8060 - loss: 0.5110 - val_accuracy: 0.8034 - val_loss: 0.4567\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8018 - loss: 0.5084 - val_accuracy: 0.8065 - val_loss: 0.4233\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8107 - loss: 0.4858 - val_accuracy: 0.8014 - val_loss: 0.4368\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8268 - loss: 0.4681 - val_accuracy: 0.8155 - val_loss: 0.4340\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8352 - loss: 0.4566 - val_accuracy: 0.8115 - val_loss: 0.4195\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.8191 - loss: 0.4600 - val_accuracy: 0.8165 - val_loss: 0.4317\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8320 - loss: 0.4388 - val_accuracy: 0.7944 - val_loss: 0.4741\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8470 - loss: 0.4097 - val_accuracy: 0.7873 - val_loss: 0.4639\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6847 - loss: 0.6849 - val_accuracy: 0.7863 - val_loss: 0.4671\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8083 - loss: 0.5028 - val_accuracy: 0.7994 - val_loss: 0.4401\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8132 - loss: 0.5004 - val_accuracy: 0.8044 - val_loss: 0.4301\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8102 - loss: 0.4901 - val_accuracy: 0.8105 - val_loss: 0.4331\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8193 - loss: 0.4641 - val_accuracy: 0.7974 - val_loss: 0.4582\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8376 - loss: 0.4457 - val_accuracy: 0.8135 - val_loss: 0.4331\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.7352 - loss: 0.6231 - val_accuracy: 0.7913 - val_loss: 0.4629\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8108 - loss: 0.4963 - val_accuracy: 0.7802 - val_loss: 0.4722\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8242 - loss: 0.4636 - val_accuracy: 0.7833 - val_loss: 0.4754\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8176 - loss: 0.4770 - val_accuracy: 0.8034 - val_loss: 0.4253\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8210 - loss: 0.4589 - val_accuracy: 0.7974 - val_loss: 0.4603\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8333 - loss: 0.4480 - val_accuracy: 0.8014 - val_loss: 0.4405\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8464 - loss: 0.4198 - val_accuracy: 0.8115 - val_loss: 0.4285\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6990 - loss: 0.6636 - val_accuracy: 0.8004 - val_loss: 0.4537\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7988 - loss: 0.5201 - val_accuracy: 0.8034 - val_loss: 0.4409\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8147 - loss: 0.4957 - val_accuracy: 0.7883 - val_loss: 0.4602\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8032 - loss: 0.5017 - val_accuracy: 0.8155 - val_loss: 0.4299\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8234 - loss: 0.4687 - val_accuracy: 0.8155 - val_loss: 0.4213\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8353 - loss: 0.4542 - val_accuracy: 0.8085 - val_loss: 0.4395\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8245 - loss: 0.4499 - val_accuracy: 0.8024 - val_loss: 0.4514\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8339 - loss: 0.4385 - val_accuracy: 0.8075 - val_loss: 0.4417\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7225 - loss: 0.6203 - val_accuracy: 0.7984 - val_loss: 0.4391\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8100 - loss: 0.5124 - val_accuracy: 0.8125 - val_loss: 0.4320\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8046 - loss: 0.4983 - val_accuracy: 0.7944 - val_loss: 0.4522\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8121 - loss: 0.4803 - val_accuracy: 0.8105 - val_loss: 0.4284\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8136 - loss: 0.4775 - val_accuracy: 0.8115 - val_loss: 0.4220\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8357 - loss: 0.4426 - val_accuracy: 0.8125 - val_loss: 0.4283\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8528 - loss: 0.4273 - val_accuracy: 0.8135 - val_loss: 0.4177\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8316 - loss: 0.4454 - val_accuracy: 0.8155 - val_loss: 0.4250\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8439 - loss: 0.4101 - val_accuracy: 0.8054 - val_loss: 0.4447\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8422 - loss: 0.4057 - val_accuracy: 0.8125 - val_loss: 0.4307\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6897 - loss: 0.6595 - val_accuracy: 0.7944 - val_loss: 0.4512\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8065 - loss: 0.5205 - val_accuracy: 0.7903 - val_loss: 0.4479\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8116 - loss: 0.5069 - val_accuracy: 0.7843 - val_loss: 0.4622\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8160 - loss: 0.4819 - val_accuracy: 0.7843 - val_loss: 0.4741\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8204 - loss: 0.4829 - val_accuracy: 0.8085 - val_loss: 0.4328\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8232 - loss: 0.4729 - val_accuracy: 0.8115 - val_loss: 0.4315\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8277 - loss: 0.4530 - val_accuracy: 0.7944 - val_loss: 0.4674\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8413 - loss: 0.4327 - val_accuracy: 0.7974 - val_loss: 0.4589\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.8409 - loss: 0.4139 - val_accuracy: 0.8155 - val_loss: 0.4380\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.7445 - loss: 0.6233 - val_accuracy: 0.7964 - val_loss: 0.4559\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8009 - loss: 0.5195 - val_accuracy: 0.8075 - val_loss: 0.4311\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8131 - loss: 0.5068 - val_accuracy: 0.8085 - val_loss: 0.4233\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.8263 - loss: 0.4676 - val_accuracy: 0.7752 - val_loss: 0.4842\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8392 - loss: 0.4358 - val_accuracy: 0.8155 - val_loss: 0.4188\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8239 - loss: 0.4532 - val_accuracy: 0.8065 - val_loss: 0.4280\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8364 - loss: 0.4204 - val_accuracy: 0.8175 - val_loss: 0.4223\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8389 - loss: 0.4132 - val_accuracy: 0.8105 - val_loss: 0.4321\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.7327 - loss: 0.6229 - val_accuracy: 0.7681 - val_loss: 0.4777\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8000 - loss: 0.5251 - val_accuracy: 0.7964 - val_loss: 0.4583\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8017 - loss: 0.5084 - val_accuracy: 0.8075 - val_loss: 0.4280\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8138 - loss: 0.4812 - val_accuracy: 0.8085 - val_loss: 0.4319\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8124 - loss: 0.4857 - val_accuracy: 0.8145 - val_loss: 0.4281\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.8338 - loss: 0.4506 - val_accuracy: 0.8135 - val_loss: 0.4189\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8271 - loss: 0.4695 - val_accuracy: 0.7853 - val_loss: 0.4689\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8316 - loss: 0.4466 - val_accuracy: 0.8226 - val_loss: 0.4273\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8332 - loss: 0.4359 - val_accuracy: 0.7974 - val_loss: 0.4616\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.6870 - loss: 0.6573 - val_accuracy: 0.7843 - val_loss: 0.4715\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.7957 - loss: 0.5256 - val_accuracy: 0.8054 - val_loss: 0.4329\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.8328 - loss: 0.4684 - val_accuracy: 0.7944 - val_loss: 0.4390\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8070 - loss: 0.4977 - val_accuracy: 0.7702 - val_loss: 0.4923\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8121 - loss: 0.4798 - val_accuracy: 0.8075 - val_loss: 0.4245\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8250 - loss: 0.4565 - val_accuracy: 0.8095 - val_loss: 0.4567\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8102 - loss: 0.4717 - val_accuracy: 0.8075 - val_loss: 0.4638\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8299 - loss: 0.4423 - val_accuracy: 0.7903 - val_loss: 0.4724\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7014 - loss: 0.6447 - val_accuracy: 0.8085 - val_loss: 0.4472\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8172 - loss: 0.5036 - val_accuracy: 0.8065 - val_loss: 0.4390\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8129 - loss: 0.4825 - val_accuracy: 0.7621 - val_loss: 0.5091\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8261 - loss: 0.4770 - val_accuracy: 0.8135 - val_loss: 0.4318\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8343 - loss: 0.4473 - val_accuracy: 0.8054 - val_loss: 0.4251\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8243 - loss: 0.4638 - val_accuracy: 0.8085 - val_loss: 0.4347\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8380 - loss: 0.4435 - val_accuracy: 0.8105 - val_loss: 0.4244\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8515 - loss: 0.4214 - val_accuracy: 0.8034 - val_loss: 0.4429\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8605 - loss: 0.3964 - val_accuracy: 0.8175 - val_loss: 0.4260\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8436 - loss: 0.4237 - val_accuracy: 0.8095 - val_loss: 0.4295\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7383 - loss: 0.6004 - val_accuracy: 0.8014 - val_loss: 0.4448\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7982 - loss: 0.5114 - val_accuracy: 0.8034 - val_loss: 0.4352\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8146 - loss: 0.4878 - val_accuracy: 0.7974 - val_loss: 0.4535\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8222 - loss: 0.4593 - val_accuracy: 0.8105 - val_loss: 0.4224\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.8237 - loss: 0.4602 - val_accuracy: 0.7913 - val_loss: 0.4631\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8195 - loss: 0.4642 - val_accuracy: 0.8075 - val_loss: 0.4308\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8368 - loss: 0.4249 - val_accuracy: 0.8105 - val_loss: 0.4404\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6671 - loss: 0.6633 - val_accuracy: 0.7913 - val_loss: 0.4556\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7825 - loss: 0.5348 - val_accuracy: 0.7893 - val_loss: 0.4610\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8061 - loss: 0.5082 - val_accuracy: 0.7964 - val_loss: 0.4588\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8141 - loss: 0.4768 - val_accuracy: 0.8065 - val_loss: 0.4342\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8244 - loss: 0.4703 - val_accuracy: 0.7954 - val_loss: 0.4571\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8237 - loss: 0.4597 - val_accuracy: 0.7923 - val_loss: 0.4577\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.8383 - loss: 0.4407 - val_accuracy: 0.7984 - val_loss: 0.4240\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.4577 - val_accuracy: 0.8044 - val_loss: 0.4258\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8406 - loss: 0.4235 - val_accuracy: 0.8044 - val_loss: 0.4235\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8520 - loss: 0.4054 - val_accuracy: 0.8105 - val_loss: 0.4305\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8469 - loss: 0.4056 - val_accuracy: 0.8034 - val_loss: 0.4374\n",
            "Epoch 12/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8488 - loss: 0.4035 - val_accuracy: 0.8105 - val_loss: 0.4482\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7146 - loss: 0.6228 - val_accuracy: 0.8095 - val_loss: 0.4352\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8110 - loss: 0.5035 - val_accuracy: 0.7903 - val_loss: 0.4621\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8068 - loss: 0.4943 - val_accuracy: 0.8014 - val_loss: 0.4504\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8224 - loss: 0.4827 - val_accuracy: 0.8075 - val_loss: 0.4296\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8184 - loss: 0.4713 - val_accuracy: 0.8135 - val_loss: 0.4416\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8261 - loss: 0.4573 - val_accuracy: 0.8125 - val_loss: 0.4208\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8349 - loss: 0.4560 - val_accuracy: 0.8216 - val_loss: 0.4280\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8214 - loss: 0.4666 - val_accuracy: 0.8125 - val_loss: 0.4485\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8442 - loss: 0.4061 - val_accuracy: 0.8175 - val_loss: 0.4295\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Training LSTM...\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 747ms/step - accuracy: 0.4998 - loss: 0.8393 - val_accuracy: 0.4829 - val_loss: 0.7136\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 714ms/step - accuracy: 0.5683 - loss: 0.7945 - val_accuracy: 0.6069 - val_loss: 0.6655\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 712ms/step - accuracy: 0.5939 - loss: 0.7898 - val_accuracy: 0.6290 - val_loss: 0.6648\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 709ms/step - accuracy: 0.6352 - loss: 0.7655 - val_accuracy: 0.5131 - val_loss: 0.6876\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 718ms/step - accuracy: 0.6026 - loss: 0.7722 - val_accuracy: 0.6200 - val_loss: 0.6762\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 721ms/step - accuracy: 0.6344 - loss: 0.7634 - val_accuracy: 0.6079 - val_loss: 0.6659\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 157ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 1s/step - accuracy: 0.5004 - loss: 0.8457 - val_accuracy: 0.4738 - val_loss: 0.7175\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 1s/step - accuracy: 0.5734 - loss: 0.8030 - val_accuracy: 0.6069 - val_loss: 0.6630\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 1s/step - accuracy: 0.6177 - loss: 0.7775 - val_accuracy: 0.6220 - val_loss: 0.6586\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 1s/step - accuracy: 0.6298 - loss: 0.7669 - val_accuracy: 0.6331 - val_loss: 0.6416\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 1s/step - accuracy: 0.6267 - loss: 0.7559 - val_accuracy: 0.6562 - val_loss: 0.6155\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 1s/step - accuracy: 0.6627 - loss: 0.7364 - val_accuracy: 0.6492 - val_loss: 0.6322\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 1s/step - accuracy: 0.6652 - loss: 0.7212 - val_accuracy: 0.5776 - val_loss: 0.6554\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 1s/step - accuracy: 0.6960 - loss: 0.6987 - val_accuracy: 0.7268 - val_loss: 0.5689\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 1s/step - accuracy: 0.6963 - loss: 0.6816 - val_accuracy: 0.7137 - val_loss: 0.5638\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 1s/step - accuracy: 0.7370 - loss: 0.6434 - val_accuracy: 0.6935 - val_loss: 0.5852\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 555ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 741ms/step - accuracy: 0.5178 - loss: 0.8325 - val_accuracy: 0.6119 - val_loss: 0.6648\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 714ms/step - accuracy: 0.5921 - loss: 0.7993 - val_accuracy: 0.5716 - val_loss: 0.6734\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 718ms/step - accuracy: 0.6002 - loss: 0.7811 - val_accuracy: 0.6119 - val_loss: 0.6654\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 736ms/step - accuracy: 0.6182 - loss: 0.7661 - val_accuracy: 0.5242 - val_loss: 0.7055\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 1s/step - accuracy: 0.5076 - loss: 0.8537 - val_accuracy: 0.4698 - val_loss: 0.7305\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 1s/step - accuracy: 0.5137 - loss: 0.8406 - val_accuracy: 0.4698 - val_loss: 0.7132\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 1s/step - accuracy: 0.4953 - loss: 0.8419 - val_accuracy: 0.4698 - val_loss: 0.7114\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 1s/step - accuracy: 0.4924 - loss: 0.8427 - val_accuracy: 0.4698 - val_loss: 0.7276\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 1s/step - accuracy: 0.4941 - loss: 0.8416 - val_accuracy: 0.4698 - val_loss: 0.7458\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 1s/step - accuracy: 0.4924 - loss: 0.8419 - val_accuracy: 0.4698 - val_loss: 0.7457\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 524ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 860ms/step - accuracy: 0.4958 - loss: 0.8512 - val_accuracy: 0.4698 - val_loss: 0.7248\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 825ms/step - accuracy: 0.5202 - loss: 0.8213 - val_accuracy: 0.5565 - val_loss: 0.7136\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 823ms/step - accuracy: 0.5716 - loss: 0.7977 - val_accuracy: 0.5615 - val_loss: 0.7004\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 803ms/step - accuracy: 0.6011 - loss: 0.7837 - val_accuracy: 0.5605 - val_loss: 0.6840\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 799ms/step - accuracy: 0.5966 - loss: 0.7795 - val_accuracy: 0.6139 - val_loss: 0.6571\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 861ms/step - accuracy: 0.6470 - loss: 0.7571 - val_accuracy: 0.6210 - val_loss: 0.6517\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 837ms/step - accuracy: 0.6244 - loss: 0.7658 - val_accuracy: 0.6401 - val_loss: 0.6416\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 849ms/step - accuracy: 0.6639 - loss: 0.7386 - val_accuracy: 0.5585 - val_loss: 0.7074\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 872ms/step - accuracy: 0.6808 - loss: 0.7053 - val_accuracy: 0.6502 - val_loss: 0.6141\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 797ms/step - accuracy: 0.7085 - loss: 0.6823 - val_accuracy: 0.6885 - val_loss: 0.5665\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 180ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 2s/step - accuracy: 0.5095 - loss: 0.8456 - val_accuracy: 0.4940 - val_loss: 0.7082\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 2s/step - accuracy: 0.5372 - loss: 0.8119 - val_accuracy: 0.5343 - val_loss: 0.7169\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 2s/step - accuracy: 0.5991 - loss: 0.7863 - val_accuracy: 0.5625 - val_loss: 0.6858\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 2s/step - accuracy: 0.6228 - loss: 0.7644 - val_accuracy: 0.4688 - val_loss: 0.7256\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 2s/step - accuracy: 0.5816 - loss: 0.7815 - val_accuracy: 0.5333 - val_loss: 0.6982\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 2s/step - accuracy: 0.6287 - loss: 0.7639 - val_accuracy: 0.6190 - val_loss: 0.6633\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 2s/step - accuracy: 0.6256 - loss: 0.7540 - val_accuracy: 0.5897 - val_loss: 0.6738\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 2s/step - accuracy: 0.6614 - loss: 0.7316 - val_accuracy: 0.6784 - val_loss: 0.5946\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 2s/step - accuracy: 0.6748 - loss: 0.7065 - val_accuracy: 0.7369 - val_loss: 0.5597\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 2s/step - accuracy: 0.6929 - loss: 0.6899 - val_accuracy: 0.6401 - val_loss: 0.6378\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 545ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 854ms/step - accuracy: 0.5070 - loss: 0.8522 - val_accuracy: 0.4698 - val_loss: 0.7250\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 798ms/step - accuracy: 0.5012 - loss: 0.8448 - val_accuracy: 0.4698 - val_loss: 0.7612\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 872ms/step - accuracy: 0.4944 - loss: 0.8460 - val_accuracy: 0.4698 - val_loss: 0.7471\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 829ms/step - accuracy: 0.4898 - loss: 0.8475 - val_accuracy: 0.4698 - val_loss: 0.7329\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 164ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 2s/step - accuracy: 0.5215 - loss: 0.8454 - val_accuracy: 0.4738 - val_loss: 0.7117\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 2s/step - accuracy: 0.5643 - loss: 0.7964 - val_accuracy: 0.5282 - val_loss: 0.6997\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 2s/step - accuracy: 0.6009 - loss: 0.7837 - val_accuracy: 0.6139 - val_loss: 0.6528\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 2s/step - accuracy: 0.6069 - loss: 0.7834 - val_accuracy: 0.5917 - val_loss: 0.6739\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 2s/step - accuracy: 0.6201 - loss: 0.7769 - val_accuracy: 0.6190 - val_loss: 0.6451\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 2s/step - accuracy: 0.6239 - loss: 0.7684 - val_accuracy: 0.6341 - val_loss: 0.6481\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 2s/step - accuracy: 0.6224 - loss: 0.7736 - val_accuracy: 0.5927 - val_loss: 0.6783\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 2s/step - accuracy: 0.6159 - loss: 0.7900 - val_accuracy: 0.4698 - val_loss: 0.7258\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 542ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 726ms/step - accuracy: 0.5058 - loss: 0.8738 - val_accuracy: 0.4677 - val_loss: 0.7332\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 728ms/step - accuracy: 0.4924 - loss: 0.8461 - val_accuracy: 0.4698 - val_loss: 0.7138\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 729ms/step - accuracy: 0.5060 - loss: 0.8428 - val_accuracy: 0.4698 - val_loss: 0.7145\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 715ms/step - accuracy: 0.5034 - loss: 0.8414 - val_accuracy: 0.4698 - val_loss: 0.7229\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 752ms/step - accuracy: 0.4930 - loss: 0.8438 - val_accuracy: 0.4698 - val_loss: 0.7380\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 208ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 1s/step - accuracy: 0.5127 - loss: 0.8440 - val_accuracy: 0.5363 - val_loss: 0.7372\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 1s/step - accuracy: 0.5718 - loss: 0.8210 - val_accuracy: 0.5877 - val_loss: 0.6687\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 1s/step - accuracy: 0.6042 - loss: 0.7776 - val_accuracy: 0.6200 - val_loss: 0.6510\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 1s/step - accuracy: 0.6309 - loss: 0.7680 - val_accuracy: 0.6008 - val_loss: 0.6723\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 1s/step - accuracy: 0.6179 - loss: 0.7746 - val_accuracy: 0.5847 - val_loss: 0.6734\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 1s/step - accuracy: 0.6315 - loss: 0.7613 - val_accuracy: 0.5212 - val_loss: 0.7417\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 525ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 715ms/step - accuracy: 0.5121 - loss: 0.8371 - val_accuracy: 0.4698 - val_loss: 0.7547\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 719ms/step - accuracy: 0.5657 - loss: 0.8016 - val_accuracy: 0.5796 - val_loss: 0.6761\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 719ms/step - accuracy: 0.6017 - loss: 0.7858 - val_accuracy: 0.5998 - val_loss: 0.6664\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 717ms/step - accuracy: 0.6348 - loss: 0.7592 - val_accuracy: 0.6210 - val_loss: 0.6519\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 718ms/step - accuracy: 0.6227 - loss: 0.7649 - val_accuracy: 0.6169 - val_loss: 0.6654\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 701ms/step - accuracy: 0.6185 - loss: 0.7703 - val_accuracy: 0.6321 - val_loss: 0.6563\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 745ms/step - accuracy: 0.6211 - loss: 0.7668 - val_accuracy: 0.6361 - val_loss: 0.6644\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 197ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 1s/step - accuracy: 0.4972 - loss: 0.8487 - val_accuracy: 0.4698 - val_loss: 0.7371\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 1s/step - accuracy: 0.4921 - loss: 0.8465 - val_accuracy: 0.4698 - val_loss: 0.7300\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 1s/step - accuracy: 0.5036 - loss: 0.8415 - val_accuracy: 0.4698 - val_loss: 0.7408\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 1s/step - accuracy: 0.5008 - loss: 0.8410 - val_accuracy: 0.4698 - val_loss: 0.7248\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 1s/step - accuracy: 0.5051 - loss: 0.8421 - val_accuracy: 0.4698 - val_loss: 0.7391\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 1s/step - accuracy: 0.4927 - loss: 0.8439 - val_accuracy: 0.4698 - val_loss: 0.7227\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 1s/step - accuracy: 0.4919 - loss: 0.8436 - val_accuracy: 0.4698 - val_loss: 0.7264\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 1s/step - accuracy: 0.5132 - loss: 0.8359 - val_accuracy: 0.4698 - val_loss: 0.7254\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 1s/step - accuracy: 0.5032 - loss: 0.8276 - val_accuracy: 0.5615 - val_loss: 0.6727\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 1s/step - accuracy: 0.5921 - loss: 0.7872 - val_accuracy: 0.6431 - val_loss: 0.6393\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 1s/step - accuracy: 0.6289 - loss: 0.7530 - val_accuracy: 0.6704 - val_loss: 0.6335\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 1s/step - accuracy: 0.6349 - loss: 0.7418 - val_accuracy: 0.5978 - val_loss: 0.6676\n",
            "Epoch 13/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 1s/step - accuracy: 0.6302 - loss: 0.7567 - val_accuracy: 0.6089 - val_loss: 0.6590\n",
            "Epoch 14/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 1s/step - accuracy: 0.6382 - loss: 0.7482 - val_accuracy: 0.6250 - val_loss: 0.6405\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 525ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 836ms/step - accuracy: 0.4908 - loss: 0.8448 - val_accuracy: 0.4728 - val_loss: 0.7040\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 781ms/step - accuracy: 0.5427 - loss: 0.8086 - val_accuracy: 0.5040 - val_loss: 0.6854\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 806ms/step - accuracy: 0.5687 - loss: 0.7919 - val_accuracy: 0.6129 - val_loss: 0.6695\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 803ms/step - accuracy: 0.6223 - loss: 0.7823 - val_accuracy: 0.6099 - val_loss: 0.6765\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 811ms/step - accuracy: 0.5803 - loss: 0.8053 - val_accuracy: 0.5514 - val_loss: 0.6722\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 827ms/step - accuracy: 0.5976 - loss: 0.7836 - val_accuracy: 0.5988 - val_loss: 0.6645\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 778ms/step - accuracy: 0.6284 - loss: 0.7598 - val_accuracy: 0.6341 - val_loss: 0.6406\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 803ms/step - accuracy: 0.6302 - loss: 0.7795 - val_accuracy: 0.6683 - val_loss: 0.6234\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 804ms/step - accuracy: 0.6658 - loss: 0.7460 - val_accuracy: 0.6794 - val_loss: 0.6320\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 781ms/step - accuracy: 0.6517 - loss: 0.7573 - val_accuracy: 0.6714 - val_loss: 0.6222\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 839ms/step - accuracy: 0.6789 - loss: 0.7279 - val_accuracy: 0.6431 - val_loss: 0.6417\n",
            "Epoch 12/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 817ms/step - accuracy: 0.6426 - loss: 0.7600 - val_accuracy: 0.6724 - val_loss: 0.6159\n",
            "Epoch 13/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 795ms/step - accuracy: 0.6794 - loss: 0.7218 - val_accuracy: 0.6683 - val_loss: 0.6376\n",
            "Epoch 14/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 781ms/step - accuracy: 0.6884 - loss: 0.7101 - val_accuracy: 0.7026 - val_loss: 0.5928\n",
            "Epoch 15/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 800ms/step - accuracy: 0.6541 - loss: 0.7492 - val_accuracy: 0.6794 - val_loss: 0.6234\n",
            "Epoch 16/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 777ms/step - accuracy: 0.7000 - loss: 0.6963 - val_accuracy: 0.6905 - val_loss: 0.5934\n",
            "Epoch 17/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 820ms/step - accuracy: 0.7031 - loss: 0.6867 - val_accuracy: 0.6825 - val_loss: 0.5905\n",
            "Epoch 18/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 776ms/step - accuracy: 0.7052 - loss: 0.6820 - val_accuracy: 0.6956 - val_loss: 0.5867\n",
            "Epoch 19/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 813ms/step - accuracy: 0.7129 - loss: 0.6774 - val_accuracy: 0.6734 - val_loss: 0.6099\n",
            "Epoch 20/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 799ms/step - accuracy: 0.7259 - loss: 0.6659 - val_accuracy: 0.7097 - val_loss: 0.5932\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 186ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 2s/step - accuracy: 0.5193 - loss: 0.8460 - val_accuracy: 0.4698 - val_loss: 0.7288\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 2s/step - accuracy: 0.5402 - loss: 0.8222 - val_accuracy: 0.5444 - val_loss: 0.6798\n",
            "Epoch 3/20\n",
            "\u001b[1m 33/124\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:37\u001b[0m 2s/step - accuracy: 0.5919 - loss: 0.7713"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jx-CvdvVGzhD",
        "outputId": "2c13f90d-18ff-4f0b-d7e1-f534acbca980"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of DataFrame after dropping null values: (4958, 8)\n",
            "Epoch 1/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m480s\u001b[0m 4s/step - accuracy: 0.5806 - loss: 0.6640 - val_accuracy: 0.6425 - val_loss: 0.6305\n",
            "Epoch 2/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m497s\u001b[0m 4s/step - accuracy: 0.6428 - loss: 0.6383 - val_accuracy: 0.6499 - val_loss: 0.6151\n",
            "Epoch 3/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m503s\u001b[0m 4s/step - accuracy: 0.6587 - loss: 0.6138 - val_accuracy: 0.6680 - val_loss: 0.6024\n",
            "Epoch 4/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m435s\u001b[0m 4s/step - accuracy: 0.6762 - loss: 0.5992 - val_accuracy: 0.6687 - val_loss: 0.6001\n",
            "Epoch 5/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m475s\u001b[0m 4s/step - accuracy: 0.6773 - loss: 0.6029 - val_accuracy: 0.7050 - val_loss: 0.5658\n",
            "Epoch 6/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m503s\u001b[0m 4s/step - accuracy: 0.7061 - loss: 0.5531 - val_accuracy: 0.7325 - val_loss: 0.5487\n",
            "Epoch 7/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m500s\u001b[0m 4s/step - accuracy: 0.7296 - loss: 0.5288 - val_accuracy: 0.7466 - val_loss: 0.5234\n",
            "Epoch 8/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 4s/step - accuracy: 0.7415 - loss: 0.5225 - val_accuracy: 0.7648 - val_loss: 0.5002\n",
            "Epoch 9/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 4s/step - accuracy: 0.7381 - loss: 0.5245 - val_accuracy: 0.7742 - val_loss: 0.4921\n",
            "Epoch 10/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m435s\u001b[0m 4s/step - accuracy: 0.7649 - loss: 0.4972 - val_accuracy: 0.7809 - val_loss: 0.4779\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 1s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment completed. Results saved.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Dropout, Input, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import joblib\n",
        "import json\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Set paths\n",
        "data_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/data.xlsx\"\n",
        "save_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/deep_learning_results4\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_excel(data_path)\n",
        "df.dropna(inplace=True)\n",
        "print(\"Size of DataFrame after dropping null values:\", df.shape)\n",
        "\n",
        "# Function to parse vector strings into numpy arrays\n",
        "def parse_vector(vector_str, expected_dim):\n",
        "    try:\n",
        "        if isinstance(vector_str, str):\n",
        "            vec = np.array([float(i) for i in vector_str.strip(\"[]\").split()], dtype=np.float32)\n",
        "            if vec.shape[0] == expected_dim:\n",
        "                return vec\n",
        "            elif vec.shape[0] > expected_dim:\n",
        "                return vec[:expected_dim]  # Truncate to expected size\n",
        "            else:\n",
        "                return np.pad(vec, (0, expected_dim - vec.shape[0]))  # Pad with zeros\n",
        "    except:\n",
        "        return np.zeros(expected_dim, dtype=np.float32)  # Default to zero vector\n",
        "    return np.zeros(expected_dim, dtype=np.float32)\n",
        "\n",
        "# Define expected dimensions\n",
        "word2vec_dim = 300\n",
        "fasttext_dim = 300\n",
        "sentence_embedding_dim = 300\n",
        "sinbert_dim = 768  # Larger than others\n",
        "\n",
        "# Apply parsing with dimension corrections\n",
        "df['word2vec_vector'] = df['word2vec_vector'].map(lambda x: parse_vector(x, word2vec_dim))\n",
        "df['fasttext_vector'] = df['fasttext_vector'].map(lambda x: parse_vector(x, fasttext_dim))\n",
        "df['sentence_embedding'] = df['sentence_embedding'].map(lambda x: parse_vector(x, sentence_embedding_dim))\n",
        "df['sinbert_vector'] = df['sinbert_vector'].map(lambda x: parse_vector(x, sinbert_dim))  # Keep 768D\n",
        "\n",
        "# Ensure all feature vectors have the same final dimension\n",
        "final_dim = 768  # Normalize to 768\n",
        "for feature in ['word2vec_vector', 'fasttext_vector', 'sentence_embedding']:\n",
        "    df[feature] = df[feature].map(lambda x: np.pad(x, (0, final_dim - x.shape[0])) if x.shape[0] < final_dim else x[:final_dim])\n",
        "\n",
        "# Stack feature vectors correctly\n",
        "X = np.stack(df[['word2vec_vector', 'fasttext_vector', 'sentence_embedding', 'sinbert_vector']].apply(lambda row: np.column_stack(row.values), axis=1).values)\n",
        "\n",
        "# Reshape X for BiLSTM (samples, time_steps, features)\n",
        "X = X.reshape(X.shape[0], X.shape[1], X.shape[2])\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'].values)\n",
        "joblib.dump(label_encoder, os.path.join(save_path, 'label_encoder.pkl'))\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define BiLSTM Model\n",
        "def build_bilstm(input_shape, lstm_units=128, dropout_rate=0.3):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Bidirectional(LSTM(lstm_units, return_sequences=True)),\n",
        "        Dropout(dropout_rate),\n",
        "        Bidirectional(LSTM(lstm_units // 2)),\n",
        "        Flatten(),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train BiLSTM model\n",
        "bilstm_model = build_bilstm((X_train.shape[1], X_train.shape[2]))\n",
        "bilstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test),\n",
        "                 callbacks=[early_stopping], verbose=1)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = (bilstm_model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "# Define evaluation function\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"confusion_matrix\": conf_matrix.tolist()\n",
        "    }\n",
        "\n",
        "# Save results\n",
        "results = evaluate_model(y_test, y_pred)\n",
        "results_path = os.path.join(save_path, \"bilstm_results.json\")\n",
        "with open(results_path, \"w\") as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n",
        "# Save model\n",
        "bilstm_model.save(os.path.join(save_path, \"bilstm_model.h5\"))\n",
        "\n",
        "print(\"Experiment completed. Results saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krxDFix8Hnyk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Conv1D, GlobalMaxPooling1D, Dropout, Input, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import joblib\n",
        "import json\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Set paths\n",
        "data_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/data.xlsx\"\n",
        "save_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/deep_learning_results2\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_excel(data_path)\n",
        "df.dropna(inplace=True)\n",
        "print(\"Size of DataFrame after dropping null values:\", df.shape)\n",
        "\n",
        "# Function to parse vector strings into numpy arrays\n",
        "def parse_vector(vector_str, expected_dim):\n",
        "    try:\n",
        "        if isinstance(vector_str, str):\n",
        "            vec = np.array([float(i) for i in vector_str.strip(\"[]\").split()], dtype=np.float32)\n",
        "            if vec.shape[0] == expected_dim:\n",
        "                return vec\n",
        "            elif vec.shape[0] > expected_dim:\n",
        "                return vec[:expected_dim]  # Truncate to expected size\n",
        "            else:\n",
        "                return np.pad(vec, (0, expected_dim - vec.shape[0]))  # Pad with zeros\n",
        "    except:\n",
        "        return np.zeros(expected_dim, dtype=np.float32)  # Default to zero vector\n",
        "    return np.zeros(expected_dim, dtype=np.float32)\n",
        "\n",
        "# Define expected dimensions\n",
        "word2vec_dim = 300\n",
        "fasttext_dim = 300\n",
        "sentence_embedding_dim = 300\n",
        "sinbert_dim = 768  # Larger than others\n",
        "\n",
        "# Apply parsing with dimension corrections\n",
        "df['word2vec_vector'] = df['word2vec_vector'].map(lambda x: parse_vector(x, word2vec_dim))\n",
        "df['fasttext_vector'] = df['fasttext_vector'].map(lambda x: parse_vector(x, fasttext_dim))\n",
        "df['sentence_embedding'] = df['sentence_embedding'].map(lambda x: parse_vector(x, sentence_embedding_dim))\n",
        "df['sinbert_vector'] = df['sinbert_vector'].map(lambda x: parse_vector(x, sinbert_dim))  # Keep 768D\n",
        "\n",
        "# Ensure all feature vectors have the same final dimension\n",
        "final_dim = 768  # Choose larger or normalize to 300\n",
        "for feature in ['word2vec_vector', 'fasttext_vector', 'sentence_embedding']:\n",
        "    df[feature] = df[feature].map(lambda x: np.pad(x, (0, final_dim - x.shape[0])) if x.shape[0] < final_dim else x[:final_dim])\n",
        "\n",
        "# Stack feature vectors correctly\n",
        "X = np.stack(df[['word2vec_vector', 'fasttext_vector', 'sentence_embedding', 'sinbert_vector']].apply(lambda row: np.column_stack(row.values), axis=1).values)\n",
        "\n",
        "# Flatten X for MLP: (samples, final_dim * 4)\n",
        "X_flattened = X.reshape(X.shape[0], -1)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'].values)\n",
        "joblib.dump(label_encoder, os.path.join(save_path, 'label_encoder.pkl'))\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train_flattened, X_test_flattened = train_test_split(X_flattened, test_size=0.2, random_state=42)\n",
        "\n",
        "# Function to implement early stopping and class weights\n",
        "def build_mlp(input_shape, dropout_rate=0.2, dense_units=128):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Dense(dense_units, activation='relu'),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(dense_units // 2, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_lstm(input_shape, dropout_rate=0.2, lstm_units=64):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        LSTM(lstm_units, return_sequences=True),\n",
        "        Dropout(dropout_rate),\n",
        "        LSTM(lstm_units // 2),\n",
        "        Flatten(),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_cnn(input_shape, dropout_rate=0.2, filters=64):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Conv1D(filters, kernel_size=3, activation='relu'),\n",
        "        Dropout(dropout_rate),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(filters // 2, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Early stopping callback to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Apply class weights (use if there is class imbalance)\n",
        "class_weights = {0: 1, 1: 1.5}  # Increase weight for the minority class\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"confusion_matrix\": conf_matrix.tolist()\n",
        "    }\n",
        "\n",
        "# Train and evaluate models with hyperparameter tuning and regularization\n",
        "results = {}\n",
        "\n",
        "# Model hyperparameters for tuning\n",
        "params = {\n",
        "    'MLP': {\n",
        "        'epochs': [10, 20],\n",
        "        'batch_size': [16, 32],\n",
        "        'dropout': [0.2, 0.3],\n",
        "        'dense_units': [64, 128]\n",
        "    },\n",
        "    'LSTM': {\n",
        "        'epochs': [10, 20],\n",
        "        'batch_size': [16, 32],\n",
        "        'dropout': [0.2, 0.3],\n",
        "        'lstm_units': [64, 128],\n",
        "    },\n",
        "    'CNN': {\n",
        "        'epochs': [10, 20],\n",
        "        'batch_size': [16, 32],\n",
        "        'dropout': [0.2, 0.3],\n",
        "        'filters': [64, 128],\n",
        "    }\n",
        "}\n",
        "\n",
        "# Train and evaluate each model\n",
        "for name in ['MLP', 'LSTM', 'CNN']:\n",
        "    print(f\"Training {name}...\")\n",
        "\n",
        "    # Hyperparameter grid search (manually tuned here)\n",
        "    for epochs in params[name]['epochs']:\n",
        "        for batch_size in params[name]['batch_size']:\n",
        "            if name == 'MLP':\n",
        "                for dropout in params[name]['dropout']:\n",
        "                    for dense_units in params[name]['dense_units']:\n",
        "                        model_instance = build_mlp((X_train_flattened.shape[1],), dropout, dense_units)\n",
        "                        model_instance.fit(X_train_flattened, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                                           validation_data=(X_test_flattened, y_test), class_weight=class_weights,\n",
        "                                           callbacks=[early_stopping], verbose=1)\n",
        "                        y_pred = (model_instance.predict(X_test_flattened) > 0.5).astype(int)\n",
        "                        results[name] = evaluate_model(y_test, y_pred)\n",
        "            elif name == 'LSTM':\n",
        "                for dropout in params[name]['dropout']:\n",
        "                    for lstm_units in params[name]['lstm_units']:\n",
        "                        model_instance = build_lstm((X_train.shape[1], X_train.shape[2]), dropout, lstm_units)\n",
        "                        model_instance.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                                           validation_data=(X_test, y_test), class_weight=class_weights,\n",
        "                                           callbacks=[early_stopping], verbose=1)\n",
        "                        y_pred = (model_instance.predict(X_test) > 0.5).astype(int)\n",
        "                        results[name] = evaluate_model(y_test, y_pred)\n",
        "            elif name == 'CNN':\n",
        "                for dropout in params[name]['dropout']:\n",
        "                    for filters in params[name]['filters']:\n",
        "                        model_instance = build_cnn((X_train.shape[1], X_train.shape[2]), dropout, filters)\n",
        "                        model_instance.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                                           validation_data=(X_test, y_test), class_weight=class_weights,\n",
        "                                           callbacks=[early_stopping], verbose=1)\n",
        "                        y_pred = (model_instance.predict(X_test) > 0.5).astype(int)\n",
        "                        results[name] = evaluate_model(y_test, y_pred)\n",
        "\n",
        "# Save results to JSON\n",
        "results_path = os.path.join(save_path, \"model_results.json\")\n",
        "with open(results_path, \"w\") as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n",
        "print(\"Experiment completed. Results saved.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}