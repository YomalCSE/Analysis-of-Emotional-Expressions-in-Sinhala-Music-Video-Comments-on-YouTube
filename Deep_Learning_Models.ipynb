{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9OkX3kWXi3h",
        "outputId": "6905d03b-4e14-4d17-b7f4-ddb9698b4c75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m1.5/1.6 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -U -q pydrive google-colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rzJLxgsYHqJ",
        "outputId": "26a81ac5-cfe9-412b-cafc-7c0d186bea1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Authenticate and mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u20nG2ADYVRD",
        "outputId": "b1e53ef6-c557-4694-e59b-67a425e3a32c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of DataFrame after dropping null values: (4958, 8)\n",
            "Training MLP...\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7070 - loss: 0.6495 - val_accuracy: 0.7994 - val_loss: 0.4507\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8067 - loss: 0.5036 - val_accuracy: 0.8075 - val_loss: 0.4578\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8089 - loss: 0.4938 - val_accuracy: 0.8135 - val_loss: 0.4263\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8163 - loss: 0.4820 - val_accuracy: 0.8075 - val_loss: 0.4538\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8235 - loss: 0.4737 - val_accuracy: 0.8105 - val_loss: 0.4440\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8373 - loss: 0.4499 - val_accuracy: 0.8004 - val_loss: 0.4636\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7215 - loss: 0.6177 - val_accuracy: 0.7087 - val_loss: 0.5686\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7913 - loss: 0.5369 - val_accuracy: 0.8145 - val_loss: 0.4360\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8128 - loss: 0.4834 - val_accuracy: 0.8135 - val_loss: 0.4249\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8283 - loss: 0.4652 - val_accuracy: 0.8125 - val_loss: 0.4346\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8120 - loss: 0.4849 - val_accuracy: 0.8085 - val_loss: 0.4456\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8298 - loss: 0.4341 - val_accuracy: 0.7661 - val_loss: 0.4984\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7042 - loss: 0.6384 - val_accuracy: 0.7641 - val_loss: 0.5032\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7863 - loss: 0.5304 - val_accuracy: 0.7873 - val_loss: 0.4571\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8137 - loss: 0.5086 - val_accuracy: 0.8014 - val_loss: 0.4475\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8209 - loss: 0.4698 - val_accuracy: 0.7994 - val_loss: 0.4305\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8295 - loss: 0.4692 - val_accuracy: 0.7964 - val_loss: 0.4349\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8290 - loss: 0.4655 - val_accuracy: 0.8105 - val_loss: 0.4304\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8217 - loss: 0.4568 - val_accuracy: 0.8115 - val_loss: 0.4688\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8398 - loss: 0.4264 - val_accuracy: 0.8095 - val_loss: 0.4541\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8435 - loss: 0.4247 - val_accuracy: 0.8135 - val_loss: 0.4254\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8426 - loss: 0.4292 - val_accuracy: 0.7923 - val_loss: 0.4658\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7094 - loss: 0.6358 - val_accuracy: 0.7873 - val_loss: 0.4509\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8009 - loss: 0.5118 - val_accuracy: 0.8095 - val_loss: 0.4405\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8142 - loss: 0.4936 - val_accuracy: 0.7893 - val_loss: 0.4396\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8087 - loss: 0.4890 - val_accuracy: 0.8065 - val_loss: 0.4391\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8294 - loss: 0.4525 - val_accuracy: 0.8125 - val_loss: 0.4238\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8269 - loss: 0.4652 - val_accuracy: 0.8075 - val_loss: 0.4277\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8262 - loss: 0.4646 - val_accuracy: 0.8085 - val_loss: 0.4339\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8163 - loss: 0.4511 - val_accuracy: 0.7591 - val_loss: 0.5071\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.6921 - loss: 0.6524 - val_accuracy: 0.8044 - val_loss: 0.4407\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8053 - loss: 0.5099 - val_accuracy: 0.8004 - val_loss: 0.4373\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8106 - loss: 0.4947 - val_accuracy: 0.7954 - val_loss: 0.4445\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8386 - loss: 0.4471 - val_accuracy: 0.8065 - val_loss: 0.4415\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8215 - loss: 0.4719 - val_accuracy: 0.8105 - val_loss: 0.4237\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8314 - loss: 0.4465 - val_accuracy: 0.8115 - val_loss: 0.4282\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8302 - loss: 0.4335 - val_accuracy: 0.8135 - val_loss: 0.4243\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8389 - loss: 0.4203 - val_accuracy: 0.8105 - val_loss: 0.4385\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7122 - loss: 0.6439 - val_accuracy: 0.8024 - val_loss: 0.4479\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8120 - loss: 0.4939 - val_accuracy: 0.8024 - val_loss: 0.4675\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8225 - loss: 0.4872 - val_accuracy: 0.8095 - val_loss: 0.4282\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8086 - loss: 0.4775 - val_accuracy: 0.7732 - val_loss: 0.4845\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8358 - loss: 0.4400 - val_accuracy: 0.8014 - val_loss: 0.4429\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8339 - loss: 0.4437 - val_accuracy: 0.8095 - val_loss: 0.4533\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6799 - loss: 0.6741 - val_accuracy: 0.8024 - val_loss: 0.4495\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8027 - loss: 0.5269 - val_accuracy: 0.8075 - val_loss: 0.4388\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8218 - loss: 0.4941 - val_accuracy: 0.7944 - val_loss: 0.4549\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8096 - loss: 0.4948 - val_accuracy: 0.7571 - val_loss: 0.5214\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8242 - loss: 0.4654 - val_accuracy: 0.8165 - val_loss: 0.4222\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8243 - loss: 0.4583 - val_accuracy: 0.7994 - val_loss: 0.4411\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8314 - loss: 0.4396 - val_accuracy: 0.7833 - val_loss: 0.4657\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8084 - loss: 0.4728 - val_accuracy: 0.8085 - val_loss: 0.4450\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7114 - loss: 0.6375 - val_accuracy: 0.8024 - val_loss: 0.4484\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7913 - loss: 0.5356 - val_accuracy: 0.7954 - val_loss: 0.4544\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8274 - loss: 0.4819 - val_accuracy: 0.8075 - val_loss: 0.4430\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8190 - loss: 0.4799 - val_accuracy: 0.8085 - val_loss: 0.4212\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8164 - loss: 0.4735 - val_accuracy: 0.8095 - val_loss: 0.4274\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8398 - loss: 0.4322 - val_accuracy: 0.8155 - val_loss: 0.4282\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8356 - loss: 0.4383 - val_accuracy: 0.8075 - val_loss: 0.4206\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8345 - loss: 0.4253 - val_accuracy: 0.8155 - val_loss: 0.4190\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8528 - loss: 0.4152 - val_accuracy: 0.7863 - val_loss: 0.4680\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8265 - loss: 0.4342 - val_accuracy: 0.8185 - val_loss: 0.4287\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7171 - loss: 0.6330 - val_accuracy: 0.8054 - val_loss: 0.4502\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7937 - loss: 0.5347 - val_accuracy: 0.7923 - val_loss: 0.4335\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8212 - loss: 0.4817 - val_accuracy: 0.7954 - val_loss: 0.4534\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8322 - loss: 0.4683 - val_accuracy: 0.7954 - val_loss: 0.4629\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8422 - loss: 0.4477 - val_accuracy: 0.8024 - val_loss: 0.4410\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7252 - loss: 0.6274 - val_accuracy: 0.7984 - val_loss: 0.4588\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7922 - loss: 0.5232 - val_accuracy: 0.7893 - val_loss: 0.4466\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8236 - loss: 0.4892 - val_accuracy: 0.8085 - val_loss: 0.4340\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.8081 - loss: 0.4940 - val_accuracy: 0.7903 - val_loss: 0.4699\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8236 - loss: 0.4515 - val_accuracy: 0.8145 - val_loss: 0.4302\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8306 - loss: 0.4530 - val_accuracy: 0.8125 - val_loss: 0.4305\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8468 - loss: 0.4130 - val_accuracy: 0.8115 - val_loss: 0.4180\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8333 - loss: 0.4259 - val_accuracy: 0.8085 - val_loss: 0.4379\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8475 - loss: 0.4175 - val_accuracy: 0.8226 - val_loss: 0.4330\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8486 - loss: 0.3956 - val_accuracy: 0.7893 - val_loss: 0.4978\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7033 - loss: 0.6612 - val_accuracy: 0.8034 - val_loss: 0.4682\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7820 - loss: 0.5505 - val_accuracy: 0.7974 - val_loss: 0.4510\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8030 - loss: 0.5123 - val_accuracy: 0.7994 - val_loss: 0.4459\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8144 - loss: 0.4901 - val_accuracy: 0.8014 - val_loss: 0.4415\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8137 - loss: 0.4776 - val_accuracy: 0.7792 - val_loss: 0.5002\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8319 - loss: 0.4575 - val_accuracy: 0.7954 - val_loss: 0.4689\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8227 - loss: 0.4534 - val_accuracy: 0.8145 - val_loss: 0.4277\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8362 - loss: 0.4504 - val_accuracy: 0.7651 - val_loss: 0.4847\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8304 - loss: 0.4387 - val_accuracy: 0.8125 - val_loss: 0.4233\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8358 - loss: 0.4307 - val_accuracy: 0.8165 - val_loss: 0.4367\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8512 - loss: 0.4104 - val_accuracy: 0.8135 - val_loss: 0.4302\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8515 - loss: 0.4019 - val_accuracy: 0.8105 - val_loss: 0.4613\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7082 - loss: 0.6475 - val_accuracy: 0.7802 - val_loss: 0.4688\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8022 - loss: 0.5180 - val_accuracy: 0.7933 - val_loss: 0.4490\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.8108 - loss: 0.4858 - val_accuracy: 0.8024 - val_loss: 0.4370\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8157 - loss: 0.4769 - val_accuracy: 0.8014 - val_loss: 0.4428\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8130 - loss: 0.4754 - val_accuracy: 0.8075 - val_loss: 0.4328\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8185 - loss: 0.4589 - val_accuracy: 0.8095 - val_loss: 0.4211\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8446 - loss: 0.4395 - val_accuracy: 0.8206 - val_loss: 0.4300\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8435 - loss: 0.4371 - val_accuracy: 0.8085 - val_loss: 0.4274\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8536 - loss: 0.4223 - val_accuracy: 0.8085 - val_loss: 0.4352\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7197 - loss: 0.6304 - val_accuracy: 0.7933 - val_loss: 0.4563\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8129 - loss: 0.5007 - val_accuracy: 0.7681 - val_loss: 0.4881\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8226 - loss: 0.4726 - val_accuracy: 0.7974 - val_loss: 0.4434\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8237 - loss: 0.4634 - val_accuracy: 0.8105 - val_loss: 0.4444\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8274 - loss: 0.4468 - val_accuracy: 0.7974 - val_loss: 0.4486\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8372 - loss: 0.4429 - val_accuracy: 0.7964 - val_loss: 0.4538\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7174 - loss: 0.6408 - val_accuracy: 0.7591 - val_loss: 0.4977\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8031 - loss: 0.5038 - val_accuracy: 0.8085 - val_loss: 0.4293\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8185 - loss: 0.4705 - val_accuracy: 0.8054 - val_loss: 0.4310\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8196 - loss: 0.4731 - val_accuracy: 0.7510 - val_loss: 0.5147\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8163 - loss: 0.4605 - val_accuracy: 0.8125 - val_loss: 0.4271\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8341 - loss: 0.4424 - val_accuracy: 0.8095 - val_loss: 0.4220\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8394 - loss: 0.4229 - val_accuracy: 0.8065 - val_loss: 0.4262\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8385 - loss: 0.4271 - val_accuracy: 0.8165 - val_loss: 0.4211\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8461 - loss: 0.4124 - val_accuracy: 0.8165 - val_loss: 0.4223\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8608 - loss: 0.3937 - val_accuracy: 0.8135 - val_loss: 0.4304\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8619 - loss: 0.3941 - val_accuracy: 0.8185 - val_loss: 0.4443\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6982 - loss: 0.6744 - val_accuracy: 0.7671 - val_loss: 0.4869\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7968 - loss: 0.5200 - val_accuracy: 0.8044 - val_loss: 0.4616\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8142 - loss: 0.5021 - val_accuracy: 0.7883 - val_loss: 0.4755\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8176 - loss: 0.4862 - val_accuracy: 0.8095 - val_loss: 0.4341\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8155 - loss: 0.4827 - val_accuracy: 0.7490 - val_loss: 0.5252\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8076 - loss: 0.4860 - val_accuracy: 0.7823 - val_loss: 0.4858\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8210 - loss: 0.4690 - val_accuracy: 0.8024 - val_loss: 0.4516\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7064 - loss: 0.6428 - val_accuracy: 0.8004 - val_loss: 0.4512\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8131 - loss: 0.5115 - val_accuracy: 0.7823 - val_loss: 0.5044\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8138 - loss: 0.4951 - val_accuracy: 0.8054 - val_loss: 0.4471\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8023 - loss: 0.5008 - val_accuracy: 0.8065 - val_loss: 0.4280\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8294 - loss: 0.4608 - val_accuracy: 0.8085 - val_loss: 0.4350\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8178 - loss: 0.4619 - val_accuracy: 0.7923 - val_loss: 0.4457\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8349 - loss: 0.4437 - val_accuracy: 0.7964 - val_loss: 0.4438\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Training LSTM...\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 591ms/step - accuracy: 0.5101 - loss: 0.8409 - val_accuracy: 0.5121 - val_loss: 0.7100\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 608ms/step - accuracy: 0.5737 - loss: 0.7959 - val_accuracy: 0.4778 - val_loss: 0.7085\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 617ms/step - accuracy: 0.5699 - loss: 0.7979 - val_accuracy: 0.6169 - val_loss: 0.6585\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 604ms/step - accuracy: 0.6197 - loss: 0.7797 - val_accuracy: 0.6240 - val_loss: 0.6550\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 598ms/step - accuracy: 0.6415 - loss: 0.7565 - val_accuracy: 0.6401 - val_loss: 0.6550\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 604ms/step - accuracy: 0.6624 - loss: 0.7397 - val_accuracy: 0.6774 - val_loss: 0.6033\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 605ms/step - accuracy: 0.6832 - loss: 0.7123 - val_accuracy: 0.6452 - val_loss: 0.6225\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 605ms/step - accuracy: 0.6756 - loss: 0.7042 - val_accuracy: 0.5958 - val_loss: 0.6537\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 613ms/step - accuracy: 0.7121 - loss: 0.6756 - val_accuracy: 0.7288 - val_loss: 0.5368\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 610ms/step - accuracy: 0.7100 - loss: 0.6681 - val_accuracy: 0.7046 - val_loss: 0.5635\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 138ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 934ms/step - accuracy: 0.5059 - loss: 0.8479 - val_accuracy: 0.4708 - val_loss: 0.6961\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 930ms/step - accuracy: 0.5373 - loss: 0.8127 - val_accuracy: 0.6149 - val_loss: 0.6524\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 933ms/step - accuracy: 0.5879 - loss: 0.7904 - val_accuracy: 0.6381 - val_loss: 0.6454\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 932ms/step - accuracy: 0.6167 - loss: 0.7758 - val_accuracy: 0.5968 - val_loss: 0.6678\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 923ms/step - accuracy: 0.6478 - loss: 0.7472 - val_accuracy: 0.6442 - val_loss: 0.6426\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 911ms/step - accuracy: 0.6538 - loss: 0.7404 - val_accuracy: 0.6250 - val_loss: 0.6529\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 906ms/step - accuracy: 0.6513 - loss: 0.7279 - val_accuracy: 0.6804 - val_loss: 0.6182\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 909ms/step - accuracy: 0.6950 - loss: 0.7118 - val_accuracy: 0.5474 - val_loss: 0.6987\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 913ms/step - accuracy: 0.7049 - loss: 0.6794 - val_accuracy: 0.7117 - val_loss: 0.5655\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 915ms/step - accuracy: 0.7147 - loss: 0.6626 - val_accuracy: 0.7107 - val_loss: 0.5727\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 454ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 621ms/step - accuracy: 0.4994 - loss: 0.8490 - val_accuracy: 0.4698 - val_loss: 0.7074\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 622ms/step - accuracy: 0.5203 - loss: 0.8274 - val_accuracy: 0.5867 - val_loss: 0.6817\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 627ms/step - accuracy: 0.6116 - loss: 0.7831 - val_accuracy: 0.6240 - val_loss: 0.6483\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 619ms/step - accuracy: 0.6253 - loss: 0.7690 - val_accuracy: 0.5595 - val_loss: 0.6905\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 616ms/step - accuracy: 0.6271 - loss: 0.7680 - val_accuracy: 0.5242 - val_loss: 0.7577\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 617ms/step - accuracy: 0.6300 - loss: 0.7640 - val_accuracy: 0.6341 - val_loss: 0.6514\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 202ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 898ms/step - accuracy: 0.5182 - loss: 0.8502 - val_accuracy: 0.4758 - val_loss: 0.6949\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 938ms/step - accuracy: 0.5218 - loss: 0.8260 - val_accuracy: 0.6149 - val_loss: 0.6592\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 934ms/step - accuracy: 0.6401 - loss: 0.7680 - val_accuracy: 0.6129 - val_loss: 0.6594\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 941ms/step - accuracy: 0.5854 - loss: 0.7901 - val_accuracy: 0.5403 - val_loss: 0.7176\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 942ms/step - accuracy: 0.6126 - loss: 0.7802 - val_accuracy: 0.6431 - val_loss: 0.6316\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 940ms/step - accuracy: 0.6397 - loss: 0.7560 - val_accuracy: 0.6774 - val_loss: 0.6123\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 938ms/step - accuracy: 0.6566 - loss: 0.7207 - val_accuracy: 0.6018 - val_loss: 0.6790\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 932ms/step - accuracy: 0.6769 - loss: 0.6943 - val_accuracy: 0.6815 - val_loss: 0.5962\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 933ms/step - accuracy: 0.7069 - loss: 0.6803 - val_accuracy: 0.7319 - val_loss: 0.5395\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 933ms/step - accuracy: 0.7022 - loss: 0.6702 - val_accuracy: 0.6825 - val_loss: 0.5880\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 450ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 694ms/step - accuracy: 0.5188 - loss: 0.8483 - val_accuracy: 0.4688 - val_loss: 0.7397\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 702ms/step - accuracy: 0.5658 - loss: 0.8055 - val_accuracy: 0.4929 - val_loss: 0.7313\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 719ms/step - accuracy: 0.5629 - loss: 0.7945 - val_accuracy: 0.5958 - val_loss: 0.6779\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 695ms/step - accuracy: 0.6156 - loss: 0.7689 - val_accuracy: 0.5857 - val_loss: 0.6657\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 727ms/step - accuracy: 0.6025 - loss: 0.7678 - val_accuracy: 0.6341 - val_loss: 0.6473\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 731ms/step - accuracy: 0.6145 - loss: 0.7749 - val_accuracy: 0.6149 - val_loss: 0.6598\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 704ms/step - accuracy: 0.6257 - loss: 0.7721 - val_accuracy: 0.6089 - val_loss: 0.6744\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 678ms/step - accuracy: 0.6430 - loss: 0.7523 - val_accuracy: 0.6129 - val_loss: 0.6582\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 142ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.5110 - loss: 0.8345 - val_accuracy: 0.5786 - val_loss: 0.6882\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - accuracy: 0.5618 - loss: 0.8072 - val_accuracy: 0.5665 - val_loss: 0.6756\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6104 - loss: 0.7859 - val_accuracy: 0.5887 - val_loss: 0.6752\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.6028 - loss: 0.7729 - val_accuracy: 0.6270 - val_loss: 0.6512\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 2s/step - accuracy: 0.6221 - loss: 0.7666 - val_accuracy: 0.6149 - val_loss: 0.6624\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6460 - loss: 0.7550 - val_accuracy: 0.5998 - val_loss: 0.6697\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6266 - loss: 0.7571 - val_accuracy: 0.6411 - val_loss: 0.6320\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.6497 - loss: 0.7490 - val_accuracy: 0.6371 - val_loss: 0.6309\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.6823 - loss: 0.7182 - val_accuracy: 0.6159 - val_loss: 0.6739\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.6825 - loss: 0.7080 - val_accuracy: 0.6935 - val_loss: 0.5829\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 464ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 695ms/step - accuracy: 0.4949 - loss: 0.8391 - val_accuracy: 0.5786 - val_loss: 0.6758\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 684ms/step - accuracy: 0.5482 - loss: 0.8136 - val_accuracy: 0.5877 - val_loss: 0.6697\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 723ms/step - accuracy: 0.5933 - loss: 0.7968 - val_accuracy: 0.6341 - val_loss: 0.6482\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 705ms/step - accuracy: 0.5995 - loss: 0.7815 - val_accuracy: 0.6099 - val_loss: 0.6608\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 698ms/step - accuracy: 0.6412 - loss: 0.7587 - val_accuracy: 0.6220 - val_loss: 0.6593\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 745ms/step - accuracy: 0.6091 - loss: 0.7694 - val_accuracy: 0.6190 - val_loss: 0.6550\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 182ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 2s/step - accuracy: 0.5113 - loss: 0.8427 - val_accuracy: 0.5938 - val_loss: 0.6671\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - accuracy: 0.5687 - loss: 0.8116 - val_accuracy: 0.4960 - val_loss: 0.6887\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - accuracy: 0.5829 - loss: 0.7924 - val_accuracy: 0.5877 - val_loss: 0.6939\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 2s/step - accuracy: 0.5862 - loss: 0.7895 - val_accuracy: 0.5998 - val_loss: 0.6762\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 437ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 611ms/step - accuracy: 0.5095 - loss: 0.8455 - val_accuracy: 0.5040 - val_loss: 0.6900\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 624ms/step - accuracy: 0.5593 - loss: 0.8091 - val_accuracy: 0.5948 - val_loss: 0.6633\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 610ms/step - accuracy: 0.5898 - loss: 0.7913 - val_accuracy: 0.6210 - val_loss: 0.6582\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 626ms/step - accuracy: 0.6218 - loss: 0.7797 - val_accuracy: 0.6159 - val_loss: 0.6541\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 632ms/step - accuracy: 0.6232 - loss: 0.7612 - val_accuracy: 0.6250 - val_loss: 0.6522\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 630ms/step - accuracy: 0.6304 - loss: 0.7699 - val_accuracy: 0.5242 - val_loss: 0.7274\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 623ms/step - accuracy: 0.6488 - loss: 0.7408 - val_accuracy: 0.6724 - val_loss: 0.5996\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 619ms/step - accuracy: 0.6659 - loss: 0.7207 - val_accuracy: 0.6885 - val_loss: 0.5944\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 631ms/step - accuracy: 0.6973 - loss: 0.6967 - val_accuracy: 0.6754 - val_loss: 0.5900\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 628ms/step - accuracy: 0.7090 - loss: 0.6769 - val_accuracy: 0.7228 - val_loss: 0.5487\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 619ms/step - accuracy: 0.7122 - loss: 0.6724 - val_accuracy: 0.7177 - val_loss: 0.5568\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 626ms/step - accuracy: 0.7196 - loss: 0.6624 - val_accuracy: 0.7429 - val_loss: 0.5106\n",
            "Epoch 13/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 623ms/step - accuracy: 0.7268 - loss: 0.6500 - val_accuracy: 0.7359 - val_loss: 0.5307\n",
            "Epoch 14/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 623ms/step - accuracy: 0.7458 - loss: 0.6301 - val_accuracy: 0.7339 - val_loss: 0.5431\n",
            "Epoch 15/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 627ms/step - accuracy: 0.7367 - loss: 0.6259 - val_accuracy: 0.7137 - val_loss: 0.5598\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 184ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 934ms/step - accuracy: 0.5199 - loss: 0.8378 - val_accuracy: 0.4698 - val_loss: 0.6897\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 940ms/step - accuracy: 0.5632 - loss: 0.7955 - val_accuracy: 0.5040 - val_loss: 0.7101\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 940ms/step - accuracy: 0.6124 - loss: 0.7759 - val_accuracy: 0.6079 - val_loss: 0.6639\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 941ms/step - accuracy: 0.6054 - loss: 0.7732 - val_accuracy: 0.6321 - val_loss: 0.6492\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 950ms/step - accuracy: 0.6290 - loss: 0.7680 - val_accuracy: 0.6381 - val_loss: 0.6437\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 937ms/step - accuracy: 0.6269 - loss: 0.7688 - val_accuracy: 0.5625 - val_loss: 0.7025\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 936ms/step - accuracy: 0.6343 - loss: 0.7525 - val_accuracy: 0.6008 - val_loss: 0.6500\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 935ms/step - accuracy: 0.6812 - loss: 0.7069 - val_accuracy: 0.7137 - val_loss: 0.5554\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 924ms/step - accuracy: 0.6967 - loss: 0.7041 - val_accuracy: 0.7177 - val_loss: 0.5511\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 909ms/step - accuracy: 0.7042 - loss: 0.6871 - val_accuracy: 0.7117 - val_loss: 0.5662\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 940ms/step - accuracy: 0.6981 - loss: 0.6825 - val_accuracy: 0.7198 - val_loss: 0.5695\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 936ms/step - accuracy: 0.7339 - loss: 0.6412 - val_accuracy: 0.7268 - val_loss: 0.5344\n",
            "Epoch 13/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 936ms/step - accuracy: 0.7282 - loss: 0.6500 - val_accuracy: 0.7228 - val_loss: 0.5406\n",
            "Epoch 14/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 938ms/step - accuracy: 0.7149 - loss: 0.6634 - val_accuracy: 0.7087 - val_loss: 0.5757\n",
            "Epoch 15/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 936ms/step - accuracy: 0.7333 - loss: 0.6368 - val_accuracy: 0.7298 - val_loss: 0.5176\n",
            "Epoch 16/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 936ms/step - accuracy: 0.7309 - loss: 0.6278 - val_accuracy: 0.7369 - val_loss: 0.5190\n",
            "Epoch 17/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 939ms/step - accuracy: 0.7306 - loss: 0.6257 - val_accuracy: 0.7268 - val_loss: 0.5315\n",
            "Epoch 18/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 938ms/step - accuracy: 0.7577 - loss: 0.5924 - val_accuracy: 0.7339 - val_loss: 0.5328\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 451ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 619ms/step - accuracy: 0.5014 - loss: 0.8431 - val_accuracy: 0.4718 - val_loss: 0.7001\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 632ms/step - accuracy: 0.5607 - loss: 0.8049 - val_accuracy: 0.5806 - val_loss: 0.6708\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 624ms/step - accuracy: 0.6062 - loss: 0.7749 - val_accuracy: 0.5423 - val_loss: 0.6904\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 621ms/step - accuracy: 0.6129 - loss: 0.7713 - val_accuracy: 0.6169 - val_loss: 0.6516\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 627ms/step - accuracy: 0.6410 - loss: 0.7638 - val_accuracy: 0.6179 - val_loss: 0.6552\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 666ms/step - accuracy: 0.6454 - loss: 0.7553 - val_accuracy: 0.5847 - val_loss: 0.6686\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 624ms/step - accuracy: 0.6372 - loss: 0.7596 - val_accuracy: 0.6401 - val_loss: 0.6336\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 623ms/step - accuracy: 0.6615 - loss: 0.7450 - val_accuracy: 0.6774 - val_loss: 0.6066\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 626ms/step - accuracy: 0.6555 - loss: 0.7393 - val_accuracy: 0.6603 - val_loss: 0.6233\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 632ms/step - accuracy: 0.6828 - loss: 0.7018 - val_accuracy: 0.7016 - val_loss: 0.5751\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 638ms/step - accuracy: 0.6956 - loss: 0.6940 - val_accuracy: 0.6744 - val_loss: 0.6010\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 631ms/step - accuracy: 0.7063 - loss: 0.6817 - val_accuracy: 0.7056 - val_loss: 0.5650\n",
            "Epoch 13/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 626ms/step - accuracy: 0.7145 - loss: 0.6738 - val_accuracy: 0.6825 - val_loss: 0.5875\n",
            "Epoch 14/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 617ms/step - accuracy: 0.7079 - loss: 0.6694 - val_accuracy: 0.7298 - val_loss: 0.5496\n",
            "Epoch 15/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 622ms/step - accuracy: 0.7147 - loss: 0.6732 - val_accuracy: 0.7056 - val_loss: 0.5780\n",
            "Epoch 16/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 634ms/step - accuracy: 0.7056 - loss: 0.6703 - val_accuracy: 0.7127 - val_loss: 0.5399\n",
            "Epoch 17/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 633ms/step - accuracy: 0.7182 - loss: 0.6658 - val_accuracy: 0.7359 - val_loss: 0.5394\n",
            "Epoch 18/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 632ms/step - accuracy: 0.7319 - loss: 0.6331 - val_accuracy: 0.7359 - val_loss: 0.5165\n",
            "Epoch 19/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 636ms/step - accuracy: 0.7490 - loss: 0.6316 - val_accuracy: 0.7329 - val_loss: 0.5395\n",
            "Epoch 20/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 621ms/step - accuracy: 0.7253 - loss: 0.6432 - val_accuracy: 0.7339 - val_loss: 0.5161\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 214ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 907ms/step - accuracy: 0.5062 - loss: 0.8446 - val_accuracy: 0.4698 - val_loss: 0.8003\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 947ms/step - accuracy: 0.4923 - loss: 0.8510 - val_accuracy: 0.4698 - val_loss: 0.7212\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 940ms/step - accuracy: 0.5012 - loss: 0.8440 - val_accuracy: 0.4698 - val_loss: 0.7173\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 937ms/step - accuracy: 0.5063 - loss: 0.8427 - val_accuracy: 0.4698 - val_loss: 0.7279\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 939ms/step - accuracy: 0.4919 - loss: 0.8434 - val_accuracy: 0.4698 - val_loss: 0.7405\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 941ms/step - accuracy: 0.4905 - loss: 0.8450 - val_accuracy: 0.4698 - val_loss: 0.7204\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 458ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 736ms/step - accuracy: 0.5014 - loss: 0.8373 - val_accuracy: 0.5534 - val_loss: 0.6910\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 727ms/step - accuracy: 0.5698 - loss: 0.7957 - val_accuracy: 0.6048 - val_loss: 0.6701\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 747ms/step - accuracy: 0.5917 - loss: 0.7887 - val_accuracy: 0.5696 - val_loss: 0.6722\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 688ms/step - accuracy: 0.5797 - loss: 0.8003 - val_accuracy: 0.5907 - val_loss: 0.6789\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 687ms/step - accuracy: 0.6117 - loss: 0.7743 - val_accuracy: 0.6079 - val_loss: 0.6570\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 701ms/step - accuracy: 0.6209 - loss: 0.7707 - val_accuracy: 0.6321 - val_loss: 0.6386\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 709ms/step - accuracy: 0.6551 - loss: 0.7576 - val_accuracy: 0.6512 - val_loss: 0.6369\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 724ms/step - accuracy: 0.6220 - loss: 0.7704 - val_accuracy: 0.5998 - val_loss: 0.6648\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 708ms/step - accuracy: 0.6354 - loss: 0.7571 - val_accuracy: 0.6250 - val_loss: 0.6474\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 737ms/step - accuracy: 0.6336 - loss: 0.7598 - val_accuracy: 0.5625 - val_loss: 0.7028\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.4951 - loss: 0.8433 - val_accuracy: 0.4849 - val_loss: 0.6933\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 2s/step - accuracy: 0.5364 - loss: 0.8179 - val_accuracy: 0.5827 - val_loss: 0.6814\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.5846 - loss: 0.7979 - val_accuracy: 0.6028 - val_loss: 0.6688\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 2s/step - accuracy: 0.5934 - loss: 0.7884 - val_accuracy: 0.6149 - val_loss: 0.6564\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 2s/step - accuracy: 0.6112 - loss: 0.7780 - val_accuracy: 0.6260 - val_loss: 0.6617\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - accuracy: 0.6504 - loss: 0.7651 - val_accuracy: 0.5544 - val_loss: 0.7159\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - accuracy: 0.6175 - loss: 0.7738 - val_accuracy: 0.6361 - val_loss: 0.6368\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - accuracy: 0.6508 - loss: 0.7588 - val_accuracy: 0.4708 - val_loss: 0.7885\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.4949 - loss: 0.8531 - val_accuracy: 0.4698 - val_loss: 0.7340\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 2s/step - accuracy: 0.4931 - loss: 0.8444 - val_accuracy: 0.4698 - val_loss: 0.7240\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 455ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 735ms/step - accuracy: 0.5141 - loss: 0.8436 - val_accuracy: 0.5091 - val_loss: 0.6941\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 717ms/step - accuracy: 0.5554 - loss: 0.8094 - val_accuracy: 0.4778 - val_loss: 0.6955\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 752ms/step - accuracy: 0.5594 - loss: 0.8015 - val_accuracy: 0.5494 - val_loss: 0.7022\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 694ms/step - accuracy: 0.6140 - loss: 0.7764 - val_accuracy: 0.5988 - val_loss: 0.6628\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 729ms/step - accuracy: 0.6151 - loss: 0.7699 - val_accuracy: 0.4798 - val_loss: 0.7156\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 711ms/step - accuracy: 0.5885 - loss: 0.7846 - val_accuracy: 0.6220 - val_loss: 0.6649\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 722ms/step - accuracy: 0.6371 - loss: 0.7640 - val_accuracy: 0.6542 - val_loss: 0.6360\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 705ms/step - accuracy: 0.5937 - loss: 0.7924 - val_accuracy: 0.4698 - val_loss: 0.7277\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 719ms/step - accuracy: 0.4927 - loss: 0.8410 - val_accuracy: 0.6139 - val_loss: 0.6567\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 695ms/step - accuracy: 0.5661 - loss: 0.8052 - val_accuracy: 0.6190 - val_loss: 0.6555\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 147ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 2s/step - accuracy: 0.5089 - loss: 0.8593 - val_accuracy: 0.4667 - val_loss: 0.7219\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 2s/step - accuracy: 0.4990 - loss: 0.8452 - val_accuracy: 0.4698 - val_loss: 0.7247\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 2s/step - accuracy: 0.4844 - loss: 0.8401 - val_accuracy: 0.4698 - val_loss: 0.7392\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.4934 - loss: 0.8425 - val_accuracy: 0.4698 - val_loss: 0.7286\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 452ms/step\n",
            "Training CNN...\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - accuracy: 0.4962 - loss: 0.8269 - val_accuracy: 0.6442 - val_loss: 0.6644\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.5840 - loss: 0.7802 - val_accuracy: 0.6472 - val_loss: 0.6371\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - accuracy: 0.6726 - loss: 0.7359 - val_accuracy: 0.6794 - val_loss: 0.6158\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.6727 - loss: 0.7243 - val_accuracy: 0.6966 - val_loss: 0.5884\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.6859 - loss: 0.7013 - val_accuracy: 0.6996 - val_loss: 0.5923\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.6952 - loss: 0.6736 - val_accuracy: 0.7056 - val_loss: 0.5818\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.7011 - loss: 0.6794 - val_accuracy: 0.7288 - val_loss: 0.5588\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.7159 - loss: 0.6581 - val_accuracy: 0.7248 - val_loss: 0.5548\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.7256 - loss: 0.6386 - val_accuracy: 0.7157 - val_loss: 0.5606\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7307 - loss: 0.6378 - val_accuracy: 0.7419 - val_loss: 0.5374\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - accuracy: 0.5058 - loss: 0.8205 - val_accuracy: 0.6159 - val_loss: 0.6589\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 43ms/step - accuracy: 0.6084 - loss: 0.7565 - val_accuracy: 0.6835 - val_loss: 0.6105\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.6684 - loss: 0.7301 - val_accuracy: 0.6976 - val_loss: 0.5933\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.6796 - loss: 0.7121 - val_accuracy: 0.7046 - val_loss: 0.5796\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - accuracy: 0.7109 - loss: 0.6788 - val_accuracy: 0.6764 - val_loss: 0.5990\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.7151 - loss: 0.6621 - val_accuracy: 0.7036 - val_loss: 0.5747\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.7154 - loss: 0.6505 - val_accuracy: 0.7278 - val_loss: 0.5465\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 34ms/step - accuracy: 0.7286 - loss: 0.6321 - val_accuracy: 0.6845 - val_loss: 0.5849\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - accuracy: 0.7405 - loss: 0.6398 - val_accuracy: 0.7349 - val_loss: 0.5307\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 0.7426 - loss: 0.6284 - val_accuracy: 0.7399 - val_loss: 0.5331\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.4954 - loss: 0.8305 - val_accuracy: 0.6371 - val_loss: 0.6628\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.5677 - loss: 0.7859 - val_accuracy: 0.6452 - val_loss: 0.6453\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.6487 - loss: 0.7436 - val_accuracy: 0.6452 - val_loss: 0.6394\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.6623 - loss: 0.7170 - val_accuracy: 0.6613 - val_loss: 0.6256\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.6952 - loss: 0.7009 - val_accuracy: 0.6976 - val_loss: 0.5822\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.7059 - loss: 0.6818 - val_accuracy: 0.6522 - val_loss: 0.6135\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.6979 - loss: 0.6872 - val_accuracy: 0.7308 - val_loss: 0.5623\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7134 - loss: 0.6545 - val_accuracy: 0.7117 - val_loss: 0.5725\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.7209 - loss: 0.6501 - val_accuracy: 0.7198 - val_loss: 0.5607\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.7250 - loss: 0.6376 - val_accuracy: 0.7218 - val_loss: 0.5597\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 0.4987 - loss: 0.8248 - val_accuracy: 0.6411 - val_loss: 0.6583\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.6134 - loss: 0.7626 - val_accuracy: 0.6663 - val_loss: 0.6242\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.6685 - loss: 0.7162 - val_accuracy: 0.7056 - val_loss: 0.5863\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 49ms/step - accuracy: 0.6987 - loss: 0.6948 - val_accuracy: 0.6905 - val_loss: 0.5925\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.7281 - loss: 0.6653 - val_accuracy: 0.7188 - val_loss: 0.5550\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.7288 - loss: 0.6469 - val_accuracy: 0.7278 - val_loss: 0.5417\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - accuracy: 0.7258 - loss: 0.6585 - val_accuracy: 0.7359 - val_loss: 0.5393\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 0.7363 - loss: 0.6326 - val_accuracy: 0.7329 - val_loss: 0.5363\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.7422 - loss: 0.6192 - val_accuracy: 0.7550 - val_loss: 0.5200\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - accuracy: 0.7405 - loss: 0.6196 - val_accuracy: 0.7288 - val_loss: 0.5366\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - accuracy: 0.4986 - loss: 0.8298 - val_accuracy: 0.5121 - val_loss: 0.6754\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.5332 - loss: 0.7865 - val_accuracy: 0.6512 - val_loss: 0.6444\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.6544 - loss: 0.7467 - val_accuracy: 0.6371 - val_loss: 0.6437\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.6505 - loss: 0.7504 - val_accuracy: 0.6593 - val_loss: 0.6268\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.6785 - loss: 0.7075 - val_accuracy: 0.6825 - val_loss: 0.6082\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.6961 - loss: 0.7003 - val_accuracy: 0.6421 - val_loss: 0.6321\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.6868 - loss: 0.6925 - val_accuracy: 0.7137 - val_loss: 0.5813\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.6978 - loss: 0.6888 - val_accuracy: 0.7198 - val_loss: 0.5749\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - accuracy: 0.7173 - loss: 0.6696 - val_accuracy: 0.6986 - val_loss: 0.5888\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.7043 - loss: 0.6639 - val_accuracy: 0.6895 - val_loss: 0.5904\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 78ms/step - accuracy: 0.5102 - loss: 0.8368 - val_accuracy: 0.4698 - val_loss: 0.6876\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 82ms/step - accuracy: 0.5180 - loss: 0.7867 - val_accuracy: 0.6704 - val_loss: 0.6357\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 67ms/step - accuracy: 0.6622 - loss: 0.7429 - val_accuracy: 0.6683 - val_loss: 0.6168\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 74ms/step - accuracy: 0.6838 - loss: 0.7130 - val_accuracy: 0.6996 - val_loss: 0.5973\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.6824 - loss: 0.6968 - val_accuracy: 0.7097 - val_loss: 0.5828\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 68ms/step - accuracy: 0.7011 - loss: 0.6821 - val_accuracy: 0.6512 - val_loss: 0.6173\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 75ms/step - accuracy: 0.6999 - loss: 0.6794 - val_accuracy: 0.7188 - val_loss: 0.5635\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.7238 - loss: 0.6526 - val_accuracy: 0.6915 - val_loss: 0.5811\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 68ms/step - accuracy: 0.7062 - loss: 0.6539 - val_accuracy: 0.7198 - val_loss: 0.5554\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 74ms/step - accuracy: 0.7316 - loss: 0.6376 - val_accuracy: 0.7268 - val_loss: 0.5466\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.4977 - loss: 0.8291 - val_accuracy: 0.4698 - val_loss: 0.6846\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.5277 - loss: 0.7915 - val_accuracy: 0.6048 - val_loss: 0.6628\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.6122 - loss: 0.7539 - val_accuracy: 0.6522 - val_loss: 0.6377\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.6583 - loss: 0.7337 - val_accuracy: 0.6744 - val_loss: 0.6200\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.6724 - loss: 0.7314 - val_accuracy: 0.6724 - val_loss: 0.6195\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.6850 - loss: 0.7103 - val_accuracy: 0.6976 - val_loss: 0.5942\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.6898 - loss: 0.7118 - val_accuracy: 0.6966 - val_loss: 0.5958\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.6936 - loss: 0.6955 - val_accuracy: 0.7147 - val_loss: 0.5765\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7069 - loss: 0.6877 - val_accuracy: 0.6956 - val_loss: 0.5875\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.7132 - loss: 0.6700 - val_accuracy: 0.7298 - val_loss: 0.5650\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 75ms/step - accuracy: 0.5041 - loss: 0.8308 - val_accuracy: 0.4698 - val_loss: 0.6840\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 78ms/step - accuracy: 0.5720 - loss: 0.7775 - val_accuracy: 0.6492 - val_loss: 0.6439\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 81ms/step - accuracy: 0.6591 - loss: 0.7366 - val_accuracy: 0.6784 - val_loss: 0.6146\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - accuracy: 0.6717 - loss: 0.7169 - val_accuracy: 0.6956 - val_loss: 0.5918\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.7036 - loss: 0.6961 - val_accuracy: 0.6230 - val_loss: 0.6386\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 70ms/step - accuracy: 0.6999 - loss: 0.6760 - val_accuracy: 0.7208 - val_loss: 0.5660\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 68ms/step - accuracy: 0.7082 - loss: 0.6726 - val_accuracy: 0.7188 - val_loss: 0.5741\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 85ms/step - accuracy: 0.7227 - loss: 0.6539 - val_accuracy: 0.7278 - val_loss: 0.5495\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 67ms/step - accuracy: 0.7236 - loss: 0.6542 - val_accuracy: 0.6935 - val_loss: 0.5809\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.7294 - loss: 0.6407 - val_accuracy: 0.7298 - val_loss: 0.5381\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.5003 - loss: 0.8242 - val_accuracy: 0.6482 - val_loss: 0.6587\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.5818 - loss: 0.7779 - val_accuracy: 0.6683 - val_loss: 0.6308\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.6522 - loss: 0.7491 - val_accuracy: 0.6815 - val_loss: 0.6051\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.6752 - loss: 0.7296 - val_accuracy: 0.6905 - val_loss: 0.5879\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 28ms/step - accuracy: 0.6917 - loss: 0.6989 - val_accuracy: 0.6966 - val_loss: 0.5978\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.6950 - loss: 0.6970 - val_accuracy: 0.7137 - val_loss: 0.5676\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7025 - loss: 0.6730 - val_accuracy: 0.7208 - val_loss: 0.5614\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.7312 - loss: 0.6511 - val_accuracy: 0.7208 - val_loss: 0.5617\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.7348 - loss: 0.6392 - val_accuracy: 0.7137 - val_loss: 0.5467\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.7189 - loss: 0.6686 - val_accuracy: 0.7339 - val_loss: 0.5408\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7386 - loss: 0.6321 - val_accuracy: 0.7379 - val_loss: 0.5343\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.7421 - loss: 0.6159 - val_accuracy: 0.7107 - val_loss: 0.5533\n",
            "Epoch 13/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.7444 - loss: 0.6140 - val_accuracy: 0.7379 - val_loss: 0.5305\n",
            "Epoch 14/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.7414 - loss: 0.6158 - val_accuracy: 0.7419 - val_loss: 0.5239\n",
            "Epoch 15/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.7508 - loss: 0.6042 - val_accuracy: 0.6976 - val_loss: 0.5722\n",
            "Epoch 16/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7368 - loss: 0.6210 - val_accuracy: 0.7450 - val_loss: 0.5192\n",
            "Epoch 17/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.7402 - loss: 0.6141 - val_accuracy: 0.7450 - val_loss: 0.5148\n",
            "Epoch 18/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7296 - loss: 0.6263 - val_accuracy: 0.7379 - val_loss: 0.5259\n",
            "Epoch 19/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 28ms/step - accuracy: 0.7416 - loss: 0.6001 - val_accuracy: 0.7369 - val_loss: 0.5318\n",
            "Epoch 20/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.7434 - loss: 0.6019 - val_accuracy: 0.7419 - val_loss: 0.5111\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - accuracy: 0.5217 - loss: 0.8198 - val_accuracy: 0.4738 - val_loss: 0.6954\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 35ms/step - accuracy: 0.6189 - loss: 0.7551 - val_accuracy: 0.6905 - val_loss: 0.6080\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - accuracy: 0.6810 - loss: 0.7182 - val_accuracy: 0.6431 - val_loss: 0.6335\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.6972 - loss: 0.6858 - val_accuracy: 0.7036 - val_loss: 0.5830\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.7130 - loss: 0.6705 - val_accuracy: 0.6421 - val_loss: 0.6243\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.7189 - loss: 0.6583 - val_accuracy: 0.6522 - val_loss: 0.6113\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.7123 - loss: 0.6511 - val_accuracy: 0.7238 - val_loss: 0.5536\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.7305 - loss: 0.6347 - val_accuracy: 0.7308 - val_loss: 0.5317\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 0.7351 - loss: 0.6390 - val_accuracy: 0.7429 - val_loss: 0.5284\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 33ms/step - accuracy: 0.7310 - loss: 0.6334 - val_accuracy: 0.7359 - val_loss: 0.5308\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - accuracy: 0.7389 - loss: 0.6104 - val_accuracy: 0.7550 - val_loss: 0.5185\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.7463 - loss: 0.6121 - val_accuracy: 0.7490 - val_loss: 0.5222\n",
            "Epoch 13/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 41ms/step - accuracy: 0.7481 - loss: 0.6006 - val_accuracy: 0.7530 - val_loss: 0.5094\n",
            "Epoch 14/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.7439 - loss: 0.6096 - val_accuracy: 0.7510 - val_loss: 0.5075\n",
            "Epoch 15/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.7519 - loss: 0.5949 - val_accuracy: 0.7046 - val_loss: 0.5583\n",
            "Epoch 16/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.7680 - loss: 0.5689 - val_accuracy: 0.7571 - val_loss: 0.5000\n",
            "Epoch 17/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.7616 - loss: 0.5816 - val_accuracy: 0.7591 - val_loss: 0.5021\n",
            "Epoch 18/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - accuracy: 0.7719 - loss: 0.5800 - val_accuracy: 0.7681 - val_loss: 0.4952\n",
            "Epoch 19/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 33ms/step - accuracy: 0.7693 - loss: 0.5854 - val_accuracy: 0.7409 - val_loss: 0.5265\n",
            "Epoch 20/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.7641 - loss: 0.5740 - val_accuracy: 0.7702 - val_loss: 0.4993\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.4944 - loss: 0.8276 - val_accuracy: 0.4698 - val_loss: 0.6969\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.5464 - loss: 0.7869 - val_accuracy: 0.6391 - val_loss: 0.6536\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.6216 - loss: 0.7592 - val_accuracy: 0.6391 - val_loss: 0.6517\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.6661 - loss: 0.7412 - val_accuracy: 0.6996 - val_loss: 0.6094\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.6796 - loss: 0.7095 - val_accuracy: 0.6956 - val_loss: 0.5924\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.7006 - loss: 0.6975 - val_accuracy: 0.7127 - val_loss: 0.5867\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7182 - loss: 0.6706 - val_accuracy: 0.7147 - val_loss: 0.5836\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.7166 - loss: 0.6714 - val_accuracy: 0.7319 - val_loss: 0.5627\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.7153 - loss: 0.6600 - val_accuracy: 0.7319 - val_loss: 0.5524\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.7294 - loss: 0.6405 - val_accuracy: 0.7429 - val_loss: 0.5510\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.7337 - loss: 0.6346 - val_accuracy: 0.7460 - val_loss: 0.5407\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7297 - loss: 0.6366 - val_accuracy: 0.7490 - val_loss: 0.5397\n",
            "Epoch 13/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.7389 - loss: 0.6133 - val_accuracy: 0.7268 - val_loss: 0.5482\n",
            "Epoch 14/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7249 - loss: 0.6226 - val_accuracy: 0.7520 - val_loss: 0.5308\n",
            "Epoch 15/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 28ms/step - accuracy: 0.7400 - loss: 0.6153 - val_accuracy: 0.7480 - val_loss: 0.5295\n",
            "Epoch 16/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.7414 - loss: 0.6141 - val_accuracy: 0.7480 - val_loss: 0.5316\n",
            "Epoch 17/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.7318 - loss: 0.6184 - val_accuracy: 0.7581 - val_loss: 0.5232\n",
            "Epoch 18/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.7480 - loss: 0.5999 - val_accuracy: 0.7560 - val_loss: 0.5194\n",
            "Epoch 19/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.7402 - loss: 0.6064 - val_accuracy: 0.7339 - val_loss: 0.5435\n",
            "Epoch 20/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.7529 - loss: 0.5982 - val_accuracy: 0.7571 - val_loss: 0.5138\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 0.5115 - loss: 0.8181 - val_accuracy: 0.5464 - val_loss: 0.6746\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - accuracy: 0.6254 - loss: 0.7678 - val_accuracy: 0.6804 - val_loss: 0.6130\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.6793 - loss: 0.7235 - val_accuracy: 0.6956 - val_loss: 0.5955\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.7025 - loss: 0.6889 - val_accuracy: 0.6966 - val_loss: 0.5744\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.6948 - loss: 0.6911 - val_accuracy: 0.6613 - val_loss: 0.6108\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - accuracy: 0.7045 - loss: 0.6859 - val_accuracy: 0.7167 - val_loss: 0.5635\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.7231 - loss: 0.6465 - val_accuracy: 0.6915 - val_loss: 0.5807\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.7204 - loss: 0.6378 - val_accuracy: 0.7329 - val_loss: 0.5425\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 0.7231 - loss: 0.6409 - val_accuracy: 0.7177 - val_loss: 0.5378\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.7302 - loss: 0.6435 - val_accuracy: 0.7379 - val_loss: 0.5411\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.7400 - loss: 0.6212 - val_accuracy: 0.7500 - val_loss: 0.5255\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.7504 - loss: 0.6025 - val_accuracy: 0.7349 - val_loss: 0.5345\n",
            "Epoch 13/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.7585 - loss: 0.5961 - val_accuracy: 0.7298 - val_loss: 0.5387\n",
            "Epoch 14/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - accuracy: 0.7422 - loss: 0.6190 - val_accuracy: 0.7581 - val_loss: 0.5171\n",
            "Epoch 15/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.7394 - loss: 0.6272 - val_accuracy: 0.7621 - val_loss: 0.5189\n",
            "Epoch 16/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.7311 - loss: 0.6067 - val_accuracy: 0.7560 - val_loss: 0.5184\n",
            "Epoch 17/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.7594 - loss: 0.5783 - val_accuracy: 0.7440 - val_loss: 0.5095\n",
            "Epoch 18/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 34ms/step - accuracy: 0.7443 - loss: 0.6117 - val_accuracy: 0.7460 - val_loss: 0.5298\n",
            "Epoch 19/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.7526 - loss: 0.5988 - val_accuracy: 0.7591 - val_loss: 0.5005\n",
            "Epoch 20/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 42ms/step - accuracy: 0.7684 - loss: 0.5742 - val_accuracy: 0.7389 - val_loss: 0.5026\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - accuracy: 0.5049 - loss: 0.8343 - val_accuracy: 0.4698 - val_loss: 0.7047\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 56ms/step - accuracy: 0.5092 - loss: 0.8089 - val_accuracy: 0.4788 - val_loss: 0.6810\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - accuracy: 0.5621 - loss: 0.7829 - val_accuracy: 0.6573 - val_loss: 0.6408\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - accuracy: 0.6347 - loss: 0.7522 - val_accuracy: 0.6562 - val_loss: 0.6338\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.6619 - loss: 0.7253 - val_accuracy: 0.6966 - val_loss: 0.6117\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.6897 - loss: 0.7041 - val_accuracy: 0.6220 - val_loss: 0.6377\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.6858 - loss: 0.6948 - val_accuracy: 0.6280 - val_loss: 0.6377\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.6844 - loss: 0.6929 - val_accuracy: 0.7218 - val_loss: 0.5721\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.7149 - loss: 0.6602 - val_accuracy: 0.7258 - val_loss: 0.5693\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.7062 - loss: 0.6643 - val_accuracy: 0.7278 - val_loss: 0.5631\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.7226 - loss: 0.6618 - val_accuracy: 0.7319 - val_loss: 0.5498\n",
            "Epoch 12/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.7271 - loss: 0.6448 - val_accuracy: 0.7389 - val_loss: 0.5470\n",
            "Epoch 13/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - accuracy: 0.7385 - loss: 0.6228 - val_accuracy: 0.7288 - val_loss: 0.5458\n",
            "Epoch 14/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.7220 - loss: 0.6420 - val_accuracy: 0.7238 - val_loss: 0.5534\n",
            "Epoch 15/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.7084 - loss: 0.6523 - val_accuracy: 0.7329 - val_loss: 0.5511\n",
            "Epoch 16/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.7451 - loss: 0.6063 - val_accuracy: 0.7238 - val_loss: 0.5533\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 86ms/step - accuracy: 0.5039 - loss: 0.8250 - val_accuracy: 0.4929 - val_loss: 0.6775\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 73ms/step - accuracy: 0.5752 - loss: 0.7765 - val_accuracy: 0.6704 - val_loss: 0.6301\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 72ms/step - accuracy: 0.6559 - loss: 0.7382 - val_accuracy: 0.6442 - val_loss: 0.6365\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 85ms/step - accuracy: 0.6825 - loss: 0.7118 - val_accuracy: 0.6734 - val_loss: 0.6099\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 72ms/step - accuracy: 0.6961 - loss: 0.6961 - val_accuracy: 0.6754 - val_loss: 0.6037\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 78ms/step - accuracy: 0.6923 - loss: 0.6842 - val_accuracy: 0.6946 - val_loss: 0.5902\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.7143 - loss: 0.6675 - val_accuracy: 0.6956 - val_loss: 0.5856\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.7102 - loss: 0.6641 - val_accuracy: 0.7288 - val_loss: 0.5480\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 95ms/step - accuracy: 0.7372 - loss: 0.6299 - val_accuracy: 0.7228 - val_loss: 0.5502\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 86ms/step - accuracy: 0.7344 - loss: 0.6351 - val_accuracy: 0.7177 - val_loss: 0.5413\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 72ms/step - accuracy: 0.7323 - loss: 0.6310 - val_accuracy: 0.7319 - val_loss: 0.5361\n",
            "Epoch 12/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 79ms/step - accuracy: 0.7262 - loss: 0.6402 - val_accuracy: 0.7288 - val_loss: 0.5493\n",
            "Epoch 13/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.7376 - loss: 0.6216 - val_accuracy: 0.6905 - val_loss: 0.5827\n",
            "Epoch 14/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - accuracy: 0.7477 - loss: 0.6103 - val_accuracy: 0.7056 - val_loss: 0.5714\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - accuracy: 0.4994 - loss: 0.8282 - val_accuracy: 0.4698 - val_loss: 0.6901\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - accuracy: 0.5301 - loss: 0.8016 - val_accuracy: 0.5766 - val_loss: 0.6655\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.5903 - loss: 0.7624 - val_accuracy: 0.6492 - val_loss: 0.6436\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.6553 - loss: 0.7387 - val_accuracy: 0.6885 - val_loss: 0.6110\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.6826 - loss: 0.7221 - val_accuracy: 0.6673 - val_loss: 0.6229\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step - accuracy: 0.6817 - loss: 0.7040 - val_accuracy: 0.6986 - val_loss: 0.5868\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.6813 - loss: 0.7061 - val_accuracy: 0.7137 - val_loss: 0.5834\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - accuracy: 0.7018 - loss: 0.6861 - val_accuracy: 0.7167 - val_loss: 0.5775\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.7246 - loss: 0.6553 - val_accuracy: 0.7177 - val_loss: 0.5738\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.7056 - loss: 0.6777 - val_accuracy: 0.7077 - val_loss: 0.5641\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.7280 - loss: 0.6439 - val_accuracy: 0.7107 - val_loss: 0.5601\n",
            "Epoch 12/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - accuracy: 0.7174 - loss: 0.6617 - val_accuracy: 0.7248 - val_loss: 0.5574\n",
            "Epoch 13/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.7238 - loss: 0.6409 - val_accuracy: 0.7288 - val_loss: 0.5551\n",
            "Epoch 14/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.7152 - loss: 0.6592 - val_accuracy: 0.7298 - val_loss: 0.5556\n",
            "Epoch 15/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.7165 - loss: 0.6477 - val_accuracy: 0.7288 - val_loss: 0.5444\n",
            "Epoch 16/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.7321 - loss: 0.6370 - val_accuracy: 0.7319 - val_loss: 0.5538\n",
            "Epoch 17/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.7405 - loss: 0.6245 - val_accuracy: 0.7349 - val_loss: 0.5398\n",
            "Epoch 18/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.7306 - loss: 0.6270 - val_accuracy: 0.7379 - val_loss: 0.5360\n",
            "Epoch 19/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.7405 - loss: 0.6249 - val_accuracy: 0.6623 - val_loss: 0.6064\n",
            "Epoch 20/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.7365 - loss: 0.6079 - val_accuracy: 0.6915 - val_loss: 0.5768\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 79ms/step - accuracy: 0.4967 - loss: 0.8243 - val_accuracy: 0.6260 - val_loss: 0.6631\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.5969 - loss: 0.7798 - val_accuracy: 0.6633 - val_loss: 0.6362\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 69ms/step - accuracy: 0.6619 - loss: 0.7446 - val_accuracy: 0.6784 - val_loss: 0.6197\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 79ms/step - accuracy: 0.6753 - loss: 0.7295 - val_accuracy: 0.6109 - val_loss: 0.6506\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 95ms/step - accuracy: 0.6930 - loss: 0.6969 - val_accuracy: 0.7077 - val_loss: 0.5878\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 69ms/step - accuracy: 0.7148 - loss: 0.6650 - val_accuracy: 0.7087 - val_loss: 0.5656\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 85ms/step - accuracy: 0.7151 - loss: 0.6724 - val_accuracy: 0.6895 - val_loss: 0.5872\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 75ms/step - accuracy: 0.7139 - loss: 0.6627 - val_accuracy: 0.7006 - val_loss: 0.5798\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 79ms/step - accuracy: 0.7065 - loss: 0.6589 - val_accuracy: 0.7349 - val_loss: 0.5583\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 84ms/step - accuracy: 0.7219 - loss: 0.6446 - val_accuracy: 0.7288 - val_loss: 0.5456\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 72ms/step - accuracy: 0.7392 - loss: 0.6290 - val_accuracy: 0.7480 - val_loss: 0.5383\n",
            "Epoch 12/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 83ms/step - accuracy: 0.7442 - loss: 0.6212 - val_accuracy: 0.7349 - val_loss: 0.5397\n",
            "Epoch 13/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 70ms/step - accuracy: 0.7256 - loss: 0.6381 - val_accuracy: 0.7460 - val_loss: 0.5334\n",
            "Epoch 14/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.7353 - loss: 0.6358 - val_accuracy: 0.7379 - val_loss: 0.5212\n",
            "Epoch 15/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.7555 - loss: 0.6040 - val_accuracy: 0.7107 - val_loss: 0.5584\n",
            "Epoch 16/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.7371 - loss: 0.6241 - val_accuracy: 0.7056 - val_loss: 0.5604\n",
            "Epoch 17/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 82ms/step - accuracy: 0.7322 - loss: 0.6250 - val_accuracy: 0.7480 - val_loss: 0.5159\n",
            "Epoch 18/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 77ms/step - accuracy: 0.7463 - loss: 0.6185 - val_accuracy: 0.7591 - val_loss: 0.5161\n",
            "Epoch 19/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 73ms/step - accuracy: 0.7507 - loss: 0.6145 - val_accuracy: 0.7188 - val_loss: 0.5551\n",
            "Epoch 20/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 86ms/step - accuracy: 0.7639 - loss: 0.5808 - val_accuracy: 0.7490 - val_loss: 0.5197\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
            "Experiment completed. Results saved.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Conv1D, GlobalMaxPooling1D, Dropout, Input, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import joblib\n",
        "import json\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Set paths\n",
        "data_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/data.xlsx\"\n",
        "save_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/deep_learning_results2\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_excel(data_path)\n",
        "df.dropna(inplace=True)\n",
        "print(\"Size of DataFrame after dropping null values:\", df.shape)\n",
        "\n",
        "# Function to parse vector strings into numpy arrays\n",
        "def parse_vector(vector_str, expected_dim):\n",
        "    try:\n",
        "        if isinstance(vector_str, str):\n",
        "            vec = np.array([float(i) for i in vector_str.strip(\"[]\").split()], dtype=np.float32)\n",
        "            if vec.shape[0] == expected_dim:\n",
        "                return vec\n",
        "            elif vec.shape[0] > expected_dim:\n",
        "                return vec[:expected_dim]  # Truncate to expected size\n",
        "            else:\n",
        "                return np.pad(vec, (0, expected_dim - vec.shape[0]))  # Pad with zeros\n",
        "    except:\n",
        "        return np.zeros(expected_dim, dtype=np.float32)  # Default to zero vector\n",
        "    return np.zeros(expected_dim, dtype=np.float32)\n",
        "\n",
        "# Define expected dimensions\n",
        "word2vec_dim = 300\n",
        "fasttext_dim = 300\n",
        "sentence_embedding_dim = 300\n",
        "sinbert_dim = 768  # Larger than others\n",
        "\n",
        "# Apply parsing with dimension corrections\n",
        "df['word2vec_vector'] = df['word2vec_vector'].map(lambda x: parse_vector(x, word2vec_dim))\n",
        "df['fasttext_vector'] = df['fasttext_vector'].map(lambda x: parse_vector(x, fasttext_dim))\n",
        "df['sentence_embedding'] = df['sentence_embedding'].map(lambda x: parse_vector(x, sentence_embedding_dim))\n",
        "df['sinbert_vector'] = df['sinbert_vector'].map(lambda x: parse_vector(x, sinbert_dim))  # Keep 768D\n",
        "\n",
        "# Ensure all feature vectors have the same final dimension\n",
        "final_dim = 768  # Choose larger or normalize to 300\n",
        "for feature in ['word2vec_vector', 'fasttext_vector', 'sentence_embedding']:\n",
        "    df[feature] = df[feature].map(lambda x: np.pad(x, (0, final_dim - x.shape[0])) if x.shape[0] < final_dim else x[:final_dim])\n",
        "\n",
        "# Stack feature vectors correctly\n",
        "X = np.stack(df[['word2vec_vector', 'fasttext_vector', 'sentence_embedding', 'sinbert_vector']].apply(lambda row: np.column_stack(row.values), axis=1).values)\n",
        "\n",
        "# Flatten X for MLP: (samples, final_dim * 4)\n",
        "X_flattened = X.reshape(X.shape[0], -1)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'].values)\n",
        "joblib.dump(label_encoder, os.path.join(save_path, 'label_encoder.pkl'))\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train_flattened, X_test_flattened = train_test_split(X_flattened, test_size=0.2, random_state=42)\n",
        "\n",
        "# Function to implement early stopping and class weights\n",
        "def build_mlp(input_shape, dropout_rate=0.2, dense_units=128):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Dense(dense_units, activation='relu'),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(dense_units // 2, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_lstm(input_shape, dropout_rate=0.2, lstm_units=64):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        LSTM(lstm_units, return_sequences=True),\n",
        "        Dropout(dropout_rate),\n",
        "        LSTM(lstm_units // 2),\n",
        "        Flatten(),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_cnn(input_shape, dropout_rate=0.2, filters=64):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Conv1D(filters, kernel_size=3, activation='relu'),\n",
        "        Dropout(dropout_rate),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(filters // 2, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Early stopping callback to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Apply class weights (use if there is class imbalance)\n",
        "class_weights = {0: 1, 1: 1.5}  # Increase weight for the minority class\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"confusion_matrix\": conf_matrix.tolist()\n",
        "    }\n",
        "\n",
        "# Train and evaluate models with hyperparameter tuning and regularization\n",
        "results = {}\n",
        "\n",
        "# Model hyperparameters for tuning\n",
        "params = {\n",
        "    'MLP': {\n",
        "        'epochs': [10, 20],\n",
        "        'batch_size': [16, 32],\n",
        "        'dropout': [0.2, 0.3],\n",
        "        'dense_units': [64, 128]\n",
        "    },\n",
        "    'LSTM': {\n",
        "        'epochs': [10, 20],\n",
        "        'batch_size': [16, 32],\n",
        "        'dropout': [0.2, 0.3],\n",
        "        'lstm_units': [64, 128],\n",
        "    },\n",
        "    'CNN': {\n",
        "        'epochs': [10, 20],\n",
        "        'batch_size': [16, 32],\n",
        "        'dropout': [0.2, 0.3],\n",
        "        'filters': [64, 128],\n",
        "    }\n",
        "}\n",
        "\n",
        "# Train and evaluate each model\n",
        "for name in ['MLP', 'LSTM', 'CNN']:\n",
        "    print(f\"Training {name}...\")\n",
        "\n",
        "    # Hyperparameter grid search (manually tuned here)\n",
        "    for epochs in params[name]['epochs']:\n",
        "        for batch_size in params[name]['batch_size']:\n",
        "            if name == 'MLP':\n",
        "                for dropout in params[name]['dropout']:\n",
        "                    for dense_units in params[name]['dense_units']:\n",
        "                        model_instance = build_mlp((X_train_flattened.shape[1],), dropout, dense_units)\n",
        "                        model_instance.fit(X_train_flattened, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                                           validation_data=(X_test_flattened, y_test), class_weight=class_weights,\n",
        "                                           callbacks=[early_stopping], verbose=1)\n",
        "                        y_pred = (model_instance.predict(X_test_flattened) > 0.5).astype(int)\n",
        "                        results[name] = evaluate_model(y_test, y_pred)\n",
        "            elif name == 'LSTM':\n",
        "                for dropout in params[name]['dropout']:\n",
        "                    for lstm_units in params[name]['lstm_units']:\n",
        "                        model_instance = build_lstm((X_train.shape[1], X_train.shape[2]), dropout, lstm_units)\n",
        "                        model_instance.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                                           validation_data=(X_test, y_test), class_weight=class_weights,\n",
        "                                           callbacks=[early_stopping], verbose=1)\n",
        "                        y_pred = (model_instance.predict(X_test) > 0.5).astype(int)\n",
        "                        results[name] = evaluate_model(y_test, y_pred)\n",
        "            elif name == 'CNN':\n",
        "                for dropout in params[name]['dropout']:\n",
        "                    for filters in params[name]['filters']:\n",
        "                        model_instance = build_cnn((X_train.shape[1], X_train.shape[2]), dropout, filters)\n",
        "                        model_instance.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                                           validation_data=(X_test, y_test), class_weight=class_weights,\n",
        "                                           callbacks=[early_stopping], verbose=1)\n",
        "                        y_pred = (model_instance.predict(X_test) > 0.5).astype(int)\n",
        "                        results[name] = evaluate_model(y_test, y_pred)\n",
        "\n",
        "# Save results to JSON\n",
        "results_path = os.path.join(save_path, \"model_results.json\")\n",
        "with open(results_path, \"w\") as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n",
        "print(\"Experiment completed. Results saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeWTNUGhO5-4",
        "outputId": "4ec8a88c-6649-4dc3-d440-9a21ce7108ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of DataFrame after dropping null values: (4958, 8)\n",
            "Training MLP...\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7140 - loss: 0.6325 - val_accuracy: 0.8095 - val_loss: 0.4467\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8067 - loss: 0.5083 - val_accuracy: 0.7873 - val_loss: 0.4730\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8233 - loss: 0.4815 - val_accuracy: 0.7913 - val_loss: 0.4774\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8133 - loss: 0.4765 - val_accuracy: 0.7792 - val_loss: 0.4890\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7075 - loss: 0.6428 - val_accuracy: 0.7903 - val_loss: 0.4430\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8010 - loss: 0.5273 - val_accuracy: 0.8034 - val_loss: 0.4346\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8219 - loss: 0.4804 - val_accuracy: 0.7994 - val_loss: 0.4438\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8299 - loss: 0.4759 - val_accuracy: 0.8014 - val_loss: 0.4509\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8289 - loss: 0.4488 - val_accuracy: 0.8145 - val_loss: 0.4246\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8212 - loss: 0.4457 - val_accuracy: 0.8014 - val_loss: 0.4648\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8409 - loss: 0.4208 - val_accuracy: 0.8115 - val_loss: 0.4437\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8417 - loss: 0.4186 - val_accuracy: 0.8135 - val_loss: 0.4485\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7136 - loss: 0.6526 - val_accuracy: 0.7681 - val_loss: 0.4792\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7966 - loss: 0.5191 - val_accuracy: 0.7944 - val_loss: 0.4575\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8059 - loss: 0.5072 - val_accuracy: 0.8024 - val_loss: 0.4419\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8142 - loss: 0.4889 - val_accuracy: 0.8085 - val_loss: 0.4342\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8236 - loss: 0.4758 - val_accuracy: 0.8014 - val_loss: 0.4418\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8374 - loss: 0.4410 - val_accuracy: 0.7933 - val_loss: 0.4489\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8282 - loss: 0.4434 - val_accuracy: 0.8065 - val_loss: 0.4397\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7156 - loss: 0.6352 - val_accuracy: 0.8014 - val_loss: 0.4457\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8124 - loss: 0.5048 - val_accuracy: 0.7913 - val_loss: 0.4412\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8028 - loss: 0.5024 - val_accuracy: 0.7762 - val_loss: 0.4864\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8121 - loss: 0.4721 - val_accuracy: 0.7843 - val_loss: 0.4790\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8287 - loss: 0.4658 - val_accuracy: 0.8125 - val_loss: 0.4417\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.7122 - loss: 0.6368 - val_accuracy: 0.7812 - val_loss: 0.4729\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8049 - loss: 0.5020 - val_accuracy: 0.7994 - val_loss: 0.4331\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8098 - loss: 0.4998 - val_accuracy: 0.8095 - val_loss: 0.4262\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8052 - loss: 0.4848 - val_accuracy: 0.8105 - val_loss: 0.4268\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8314 - loss: 0.4573 - val_accuracy: 0.7722 - val_loss: 0.4834\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8242 - loss: 0.4565 - val_accuracy: 0.8135 - val_loss: 0.4275\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.7299 - loss: 0.6337 - val_accuracy: 0.8004 - val_loss: 0.4370\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8061 - loss: 0.5202 - val_accuracy: 0.7994 - val_loss: 0.4438\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8070 - loss: 0.4860 - val_accuracy: 0.8105 - val_loss: 0.4321\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8207 - loss: 0.4689 - val_accuracy: 0.7954 - val_loss: 0.4687\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8233 - loss: 0.4524 - val_accuracy: 0.8125 - val_loss: 0.4278\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8364 - loss: 0.4415 - val_accuracy: 0.8044 - val_loss: 0.4302\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8366 - loss: 0.4338 - val_accuracy: 0.8145 - val_loss: 0.4401\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8348 - loss: 0.4175 - val_accuracy: 0.8125 - val_loss: 0.4344\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.7039 - loss: 0.6657 - val_accuracy: 0.8044 - val_loss: 0.4434\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7894 - loss: 0.5428 - val_accuracy: 0.7823 - val_loss: 0.4706\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8185 - loss: 0.4750 - val_accuracy: 0.7671 - val_loss: 0.4906\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8112 - loss: 0.4812 - val_accuracy: 0.8085 - val_loss: 0.4390\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8173 - loss: 0.4794 - val_accuracy: 0.8044 - val_loss: 0.4407\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8362 - loss: 0.4415 - val_accuracy: 0.8105 - val_loss: 0.4218\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8250 - loss: 0.4530 - val_accuracy: 0.7974 - val_loss: 0.4500\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8208 - loss: 0.4563 - val_accuracy: 0.7641 - val_loss: 0.4926\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8241 - loss: 0.4464 - val_accuracy: 0.8135 - val_loss: 0.4379\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.7067 - loss: 0.6367 - val_accuracy: 0.7944 - val_loss: 0.4400\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8073 - loss: 0.5074 - val_accuracy: 0.7974 - val_loss: 0.4517\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8197 - loss: 0.4628 - val_accuracy: 0.8004 - val_loss: 0.4288\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8165 - loss: 0.4708 - val_accuracy: 0.8014 - val_loss: 0.4357\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8244 - loss: 0.4666 - val_accuracy: 0.7460 - val_loss: 0.5203\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8289 - loss: 0.4461 - val_accuracy: 0.8024 - val_loss: 0.4355\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.7141 - loss: 0.6282 - val_accuracy: 0.7984 - val_loss: 0.4531\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8083 - loss: 0.5060 - val_accuracy: 0.8145 - val_loss: 0.4400\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8176 - loss: 0.4887 - val_accuracy: 0.7661 - val_loss: 0.5019\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8257 - loss: 0.4688 - val_accuracy: 0.8075 - val_loss: 0.4315\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8329 - loss: 0.4542 - val_accuracy: 0.7883 - val_loss: 0.4837\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8211 - loss: 0.4684 - val_accuracy: 0.8034 - val_loss: 0.4308\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8303 - loss: 0.4519 - val_accuracy: 0.8145 - val_loss: 0.4209\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8571 - loss: 0.4084 - val_accuracy: 0.8105 - val_loss: 0.4288\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8498 - loss: 0.4144 - val_accuracy: 0.7974 - val_loss: 0.4651\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8514 - loss: 0.4020 - val_accuracy: 0.8155 - val_loss: 0.4258\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7318 - loss: 0.6182 - val_accuracy: 0.7833 - val_loss: 0.4761\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7972 - loss: 0.5324 - val_accuracy: 0.8054 - val_loss: 0.4350\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8188 - loss: 0.4864 - val_accuracy: 0.8014 - val_loss: 0.4523\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8194 - loss: 0.4741 - val_accuracy: 0.8065 - val_loss: 0.4304\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8206 - loss: 0.4799 - val_accuracy: 0.8085 - val_loss: 0.4233\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8250 - loss: 0.4462 - val_accuracy: 0.7974 - val_loss: 0.4556\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8471 - loss: 0.4352 - val_accuracy: 0.8115 - val_loss: 0.4335\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8414 - loss: 0.4180 - val_accuracy: 0.8125 - val_loss: 0.4245\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7204 - loss: 0.6309 - val_accuracy: 0.8065 - val_loss: 0.4403\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7882 - loss: 0.5312 - val_accuracy: 0.7893 - val_loss: 0.4684\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8050 - loss: 0.5083 - val_accuracy: 0.8085 - val_loss: 0.4370\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8172 - loss: 0.4903 - val_accuracy: 0.7641 - val_loss: 0.4785\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8245 - loss: 0.4704 - val_accuracy: 0.8085 - val_loss: 0.4515\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8281 - loss: 0.4622 - val_accuracy: 0.8095 - val_loss: 0.4494\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.7004 - loss: 0.6565 - val_accuracy: 0.7893 - val_loss: 0.4701\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8024 - loss: 0.5201 - val_accuracy: 0.8105 - val_loss: 0.4334\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8013 - loss: 0.5179 - val_accuracy: 0.7812 - val_loss: 0.4719\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8040 - loss: 0.5030 - val_accuracy: 0.8155 - val_loss: 0.4271\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8103 - loss: 0.4814 - val_accuracy: 0.7873 - val_loss: 0.4724\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8130 - loss: 0.4723 - val_accuracy: 0.8145 - val_loss: 0.4272\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8492 - loss: 0.4276 - val_accuracy: 0.8075 - val_loss: 0.4485\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7338 - loss: 0.6340 - val_accuracy: 0.7762 - val_loss: 0.4700\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7992 - loss: 0.5014 - val_accuracy: 0.7208 - val_loss: 0.5478\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8119 - loss: 0.4917 - val_accuracy: 0.7923 - val_loss: 0.4688\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8158 - loss: 0.4724 - val_accuracy: 0.7974 - val_loss: 0.4652\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8218 - loss: 0.4787 - val_accuracy: 0.8165 - val_loss: 0.4209\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8254 - loss: 0.4402 - val_accuracy: 0.8125 - val_loss: 0.4195\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8366 - loss: 0.4376 - val_accuracy: 0.8155 - val_loss: 0.4259\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8383 - loss: 0.4332 - val_accuracy: 0.8024 - val_loss: 0.4411\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8472 - loss: 0.4184 - val_accuracy: 0.7923 - val_loss: 0.4695\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7122 - loss: 0.6402 - val_accuracy: 0.7994 - val_loss: 0.4652\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7924 - loss: 0.5297 - val_accuracy: 0.8125 - val_loss: 0.4278\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8200 - loss: 0.4794 - val_accuracy: 0.8095 - val_loss: 0.4296\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8185 - loss: 0.4739 - val_accuracy: 0.8145 - val_loss: 0.4219\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8243 - loss: 0.4734 - val_accuracy: 0.8125 - val_loss: 0.4314\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8298 - loss: 0.4561 - val_accuracy: 0.8175 - val_loss: 0.4294\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8364 - loss: 0.4314 - val_accuracy: 0.8165 - val_loss: 0.4444\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.7025 - loss: 0.6396 - val_accuracy: 0.7732 - val_loss: 0.4802\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8019 - loss: 0.5259 - val_accuracy: 0.7873 - val_loss: 0.4697\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8167 - loss: 0.4897 - val_accuracy: 0.8125 - val_loss: 0.4299\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8178 - loss: 0.4721 - val_accuracy: 0.7954 - val_loss: 0.4736\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8178 - loss: 0.4666 - val_accuracy: 0.8004 - val_loss: 0.4404\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8336 - loss: 0.4667 - val_accuracy: 0.7762 - val_loss: 0.4793\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.6923 - loss: 0.6516 - val_accuracy: 0.7883 - val_loss: 0.4465\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8051 - loss: 0.5122 - val_accuracy: 0.7974 - val_loss: 0.4495\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8152 - loss: 0.4787 - val_accuracy: 0.8115 - val_loss: 0.4245\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8305 - loss: 0.4638 - val_accuracy: 0.8075 - val_loss: 0.4350\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8282 - loss: 0.4627 - val_accuracy: 0.7893 - val_loss: 0.4771\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8340 - loss: 0.4468 - val_accuracy: 0.8075 - val_loss: 0.4347\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Training LSTM...\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 50ms/step - accuracy: 0.5029 - loss: 0.8454 - val_accuracy: 0.4698 - val_loss: 0.7373\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 50ms/step - accuracy: 0.5482 - loss: 0.8109 - val_accuracy: 0.5565 - val_loss: 0.6963\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.5844 - loss: 0.7922 - val_accuracy: 0.6210 - val_loss: 0.6423\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.6221 - loss: 0.7614 - val_accuracy: 0.6341 - val_loss: 0.6473\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 53ms/step - accuracy: 0.6138 - loss: 0.7713 - val_accuracy: 0.6139 - val_loss: 0.6557\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 50ms/step - accuracy: 0.6226 - loss: 0.7575 - val_accuracy: 0.5897 - val_loss: 0.6682\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 54ms/step - accuracy: 0.4885 - loss: 0.8442 - val_accuracy: 0.4698 - val_loss: 0.7282\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 53ms/step - accuracy: 0.5019 - loss: 0.8456 - val_accuracy: 0.4698 - val_loss: 0.7212\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 54ms/step - accuracy: 0.4898 - loss: 0.8448 - val_accuracy: 0.4698 - val_loss: 0.7017\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 53ms/step - accuracy: 0.5140 - loss: 0.8420 - val_accuracy: 0.4698 - val_loss: 0.7300\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 54ms/step - accuracy: 0.4936 - loss: 0.8427 - val_accuracy: 0.4698 - val_loss: 0.7259\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 54ms/step - accuracy: 0.5024 - loss: 0.8392 - val_accuracy: 0.4698 - val_loss: 0.7481\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 54ms/step - accuracy: 0.5006 - loss: 0.8414 - val_accuracy: 0.6290 - val_loss: 0.6532\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 50ms/step - accuracy: 0.5644 - loss: 0.8117 - val_accuracy: 0.5927 - val_loss: 0.6712\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.6197 - loss: 0.7793 - val_accuracy: 0.6361 - val_loss: 0.6377\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 45ms/step - accuracy: 0.6439 - loss: 0.7593 - val_accuracy: 0.6462 - val_loss: 0.6371\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 49ms/step - accuracy: 0.6596 - loss: 0.7558 - val_accuracy: 0.6341 - val_loss: 0.6500\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 52ms/step - accuracy: 0.6620 - loss: 0.7261 - val_accuracy: 0.6623 - val_loss: 0.6248\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - accuracy: 0.6739 - loss: 0.7149 - val_accuracy: 0.7188 - val_loss: 0.5751\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 50ms/step - accuracy: 0.7068 - loss: 0.6945 - val_accuracy: 0.7188 - val_loss: 0.5665\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 50ms/step - accuracy: 0.7133 - loss: 0.6815 - val_accuracy: 0.7208 - val_loss: 0.5560\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 50ms/step - accuracy: 0.6996 - loss: 0.6895 - val_accuracy: 0.7117 - val_loss: 0.5605\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 55ms/step - accuracy: 0.4968 - loss: 0.8445 - val_accuracy: 0.6129 - val_loss: 0.6547\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 52ms/step - accuracy: 0.5485 - loss: 0.8262 - val_accuracy: 0.5020 - val_loss: 0.6898\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 54ms/step - accuracy: 0.6032 - loss: 0.7729 - val_accuracy: 0.5907 - val_loss: 0.6701\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 57ms/step - accuracy: 0.6135 - loss: 0.7753 - val_accuracy: 0.5988 - val_loss: 0.6725\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - accuracy: 0.4989 - loss: 0.8451 - val_accuracy: 0.4688 - val_loss: 0.8549\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.5477 - loss: 0.8125 - val_accuracy: 0.5655 - val_loss: 0.6983\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - accuracy: 0.5992 - loss: 0.7783 - val_accuracy: 0.5675 - val_loss: 0.6868\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.5832 - loss: 0.7860 - val_accuracy: 0.6149 - val_loss: 0.6638\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.6308 - loss: 0.7691 - val_accuracy: 0.5232 - val_loss: 0.6791\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - accuracy: 0.5880 - loss: 0.7847 - val_accuracy: 0.5726 - val_loss: 0.6796\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.6140 - loss: 0.7663 - val_accuracy: 0.6069 - val_loss: 0.6494\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.6154 - loss: 0.7631 - val_accuracy: 0.6401 - val_loss: 0.6429\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.6391 - loss: 0.7521 - val_accuracy: 0.6210 - val_loss: 0.6708\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.6358 - loss: 0.7494 - val_accuracy: 0.6310 - val_loss: 0.6471\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - accuracy: 0.4959 - loss: 0.8396 - val_accuracy: 0.4738 - val_loss: 0.7059\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.5185 - loss: 0.8552 - val_accuracy: 0.4698 - val_loss: 0.7159\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - accuracy: 0.4971 - loss: 0.8377 - val_accuracy: 0.4698 - val_loss: 0.6990\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.5205 - loss: 0.8152 - val_accuracy: 0.5948 - val_loss: 0.6663\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.6127 - loss: 0.7836 - val_accuracy: 0.5534 - val_loss: 0.6927\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.6186 - loss: 0.7639 - val_accuracy: 0.5655 - val_loss: 0.6946\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.6210 - loss: 0.7579 - val_accuracy: 0.6069 - val_loss: 0.6556\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.6392 - loss: 0.7609 - val_accuracy: 0.6079 - val_loss: 0.6740\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.6304 - loss: 0.7495 - val_accuracy: 0.5615 - val_loss: 0.6969\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.6335 - loss: 0.7578 - val_accuracy: 0.6149 - val_loss: 0.6708\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 60ms/step - accuracy: 0.4953 - loss: 0.8475 - val_accuracy: 0.5544 - val_loss: 0.6830\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.5922 - loss: 0.7957 - val_accuracy: 0.4819 - val_loss: 0.6895\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - accuracy: 0.5734 - loss: 0.7786 - val_accuracy: 0.6200 - val_loss: 0.6615\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.6116 - loss: 0.7755 - val_accuracy: 0.6089 - val_loss: 0.6641\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.6203 - loss: 0.7693 - val_accuracy: 0.5131 - val_loss: 0.7586\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.6146 - loss: 0.7750 - val_accuracy: 0.6169 - val_loss: 0.6628\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.4914 - loss: 0.8535 - val_accuracy: 0.4698 - val_loss: 0.7369\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.5238 - loss: 0.8249 - val_accuracy: 0.5726 - val_loss: 0.6773\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.5877 - loss: 0.7928 - val_accuracy: 0.5050 - val_loss: 0.7048\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.6053 - loss: 0.7843 - val_accuracy: 0.6109 - val_loss: 0.6726\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.6208 - loss: 0.7756 - val_accuracy: 0.5433 - val_loss: 0.6831\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - accuracy: 0.6241 - loss: 0.7640 - val_accuracy: 0.6159 - val_loss: 0.6638\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.6194 - loss: 0.7620 - val_accuracy: 0.6341 - val_loss: 0.6503\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.6476 - loss: 0.7551 - val_accuracy: 0.6371 - val_loss: 0.6311\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.6806 - loss: 0.7229 - val_accuracy: 0.6462 - val_loss: 0.6185\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.6675 - loss: 0.7212 - val_accuracy: 0.6825 - val_loss: 0.5882\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 53ms/step - accuracy: 0.5028 - loss: 0.8358 - val_accuracy: 0.5353 - val_loss: 0.6855\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.5993 - loss: 0.7821 - val_accuracy: 0.5938 - val_loss: 0.6774\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 52ms/step - accuracy: 0.5841 - loss: 0.8116 - val_accuracy: 0.4718 - val_loss: 0.8252\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 50ms/step - accuracy: 0.5850 - loss: 0.7974 - val_accuracy: 0.4960 - val_loss: 0.7376\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 51ms/step - accuracy: 0.6131 - loss: 0.7739 - val_accuracy: 0.5786 - val_loss: 0.6791\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 58ms/step - accuracy: 0.5060 - loss: 0.8369 - val_accuracy: 0.4698 - val_loss: 0.7431\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - accuracy: 0.5092 - loss: 0.8443 - val_accuracy: 0.4698 - val_loss: 0.7767\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 75ms/step - accuracy: 0.4920 - loss: 0.8540 - val_accuracy: 0.4698 - val_loss: 0.7389\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 74ms/step - accuracy: 0.5006 - loss: 0.8436 - val_accuracy: 0.4698 - val_loss: 0.7341\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - accuracy: 0.4992 - loss: 0.8447 - val_accuracy: 0.4698 - val_loss: 0.7384\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 74ms/step - accuracy: 0.5102 - loss: 0.8288 - val_accuracy: 0.5575 - val_loss: 0.6790\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 68ms/step - accuracy: 0.5894 - loss: 0.7899 - val_accuracy: 0.6139 - val_loss: 0.6606\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 55ms/step - accuracy: 0.5919 - loss: 0.7752 - val_accuracy: 0.5756 - val_loss: 0.6696\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.6060 - loss: 0.7623 - val_accuracy: 0.6744 - val_loss: 0.6287\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.6342 - loss: 0.7432 - val_accuracy: 0.6764 - val_loss: 0.6143\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 55ms/step - accuracy: 0.6749 - loss: 0.7005 - val_accuracy: 0.6663 - val_loss: 0.6179\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 57ms/step - accuracy: 0.6831 - loss: 0.7001 - val_accuracy: 0.7268 - val_loss: 0.5608\n",
            "Epoch 13/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 56ms/step - accuracy: 0.6871 - loss: 0.6930 - val_accuracy: 0.4698 - val_loss: 0.7282\n",
            "Epoch 14/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 55ms/step - accuracy: 0.5093 - loss: 0.8410 - val_accuracy: 0.4698 - val_loss: 0.7217\n",
            "Epoch 15/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 55ms/step - accuracy: 0.5135 - loss: 0.8410 - val_accuracy: 0.4698 - val_loss: 0.7108\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 52ms/step - accuracy: 0.4987 - loss: 0.8468 - val_accuracy: 0.4768 - val_loss: 0.6941\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.5680 - loss: 0.7992 - val_accuracy: 0.5766 - val_loss: 0.6739\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 53ms/step - accuracy: 0.6089 - loss: 0.7747 - val_accuracy: 0.5938 - val_loss: 0.6708\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 52ms/step - accuracy: 0.6363 - loss: 0.7675 - val_accuracy: 0.6442 - val_loss: 0.6514\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 52ms/step - accuracy: 0.6213 - loss: 0.7648 - val_accuracy: 0.6028 - val_loss: 0.6673\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 51ms/step - accuracy: 0.6207 - loss: 0.7661 - val_accuracy: 0.6331 - val_loss: 0.6498\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 51ms/step - accuracy: 0.6499 - loss: 0.7452 - val_accuracy: 0.6704 - val_loss: 0.6179\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 51ms/step - accuracy: 0.6459 - loss: 0.7414 - val_accuracy: 0.6562 - val_loss: 0.6234\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.6771 - loss: 0.7136 - val_accuracy: 0.7016 - val_loss: 0.5695\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 53ms/step - accuracy: 0.6783 - loss: 0.7042 - val_accuracy: 0.6966 - val_loss: 0.5882\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 50ms/step - accuracy: 0.7007 - loss: 0.6832 - val_accuracy: 0.6815 - val_loss: 0.5701\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 52ms/step - accuracy: 0.6964 - loss: 0.6939 - val_accuracy: 0.6986 - val_loss: 0.5722\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 57ms/step - accuracy: 0.5169 - loss: 0.8362 - val_accuracy: 0.4698 - val_loss: 0.7236\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 55ms/step - accuracy: 0.5381 - loss: 0.8080 - val_accuracy: 0.6139 - val_loss: 0.6583\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 57ms/step - accuracy: 0.5880 - loss: 0.7912 - val_accuracy: 0.6089 - val_loss: 0.6643\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.6090 - loss: 0.7769 - val_accuracy: 0.6280 - val_loss: 0.6454\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 55ms/step - accuracy: 0.6220 - loss: 0.7595 - val_accuracy: 0.6462 - val_loss: 0.6462\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 56ms/step - accuracy: 0.6375 - loss: 0.7483 - val_accuracy: 0.5907 - val_loss: 0.6871\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 56ms/step - accuracy: 0.6815 - loss: 0.7086 - val_accuracy: 0.7046 - val_loss: 0.5628\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.6870 - loss: 0.6995 - val_accuracy: 0.6734 - val_loss: 0.5905\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 55ms/step - accuracy: 0.7146 - loss: 0.6735 - val_accuracy: 0.6411 - val_loss: 0.6205\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 57ms/step - accuracy: 0.7160 - loss: 0.6552 - val_accuracy: 0.7278 - val_loss: 0.5293\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.7078 - loss: 0.6677 - val_accuracy: 0.7198 - val_loss: 0.5451\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.7264 - loss: 0.6567 - val_accuracy: 0.7258 - val_loss: 0.5429\n",
            "Epoch 13/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.7431 - loss: 0.6274 - val_accuracy: 0.7077 - val_loss: 0.5744\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - accuracy: 0.5048 - loss: 0.8476 - val_accuracy: 0.4829 - val_loss: 0.7029\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 55ms/step - accuracy: 0.5634 - loss: 0.8103 - val_accuracy: 0.5433 - val_loss: 0.6815\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.5903 - loss: 0.7829 - val_accuracy: 0.5917 - val_loss: 0.6852\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.6397 - loss: 0.7644 - val_accuracy: 0.5978 - val_loss: 0.6755\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.6378 - loss: 0.7507 - val_accuracy: 0.6371 - val_loss: 0.6583\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.6217 - loss: 0.7781 - val_accuracy: 0.6210 - val_loss: 0.6565\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 0.6150 - loss: 0.7811 - val_accuracy: 0.6200 - val_loss: 0.6676\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.6651 - loss: 0.7443 - val_accuracy: 0.6351 - val_loss: 0.6537\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.6309 - loss: 0.7539 - val_accuracy: 0.6542 - val_loss: 0.6195\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.6280 - loss: 0.7613 - val_accuracy: 0.6502 - val_loss: 0.6700\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.6695 - loss: 0.7383 - val_accuracy: 0.6986 - val_loss: 0.5845\n",
            "Epoch 12/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.6727 - loss: 0.7228 - val_accuracy: 0.6794 - val_loss: 0.6025\n",
            "Epoch 13/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.6788 - loss: 0.7100 - val_accuracy: 0.6018 - val_loss: 0.6647\n",
            "Epoch 14/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - accuracy: 0.6534 - loss: 0.7345 - val_accuracy: 0.6835 - val_loss: 0.5906\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 61ms/step - accuracy: 0.5099 - loss: 0.8387 - val_accuracy: 0.4677 - val_loss: 0.7088\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.5185 - loss: 0.8195 - val_accuracy: 0.5353 - val_loss: 0.6845\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.5689 - loss: 0.8037 - val_accuracy: 0.5373 - val_loss: 0.7065\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - accuracy: 0.6001 - loss: 0.7843 - val_accuracy: 0.5786 - val_loss: 0.6753\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.6192 - loss: 0.7774 - val_accuracy: 0.6048 - val_loss: 0.6728\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.6278 - loss: 0.7642 - val_accuracy: 0.6119 - val_loss: 0.6665\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.6385 - loss: 0.7593 - val_accuracy: 0.6119 - val_loss: 0.6749\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.6455 - loss: 0.7532 - val_accuracy: 0.6391 - val_loss: 0.6418\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - accuracy: 0.6631 - loss: 0.7450 - val_accuracy: 0.6613 - val_loss: 0.6180\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.6700 - loss: 0.7219 - val_accuracy: 0.6371 - val_loss: 0.6565\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.6779 - loss: 0.7090 - val_accuracy: 0.7046 - val_loss: 0.5852\n",
            "Epoch 12/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.6893 - loss: 0.7000 - val_accuracy: 0.6935 - val_loss: 0.5825\n",
            "Epoch 13/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.7039 - loss: 0.6704 - val_accuracy: 0.7238 - val_loss: 0.5602\n",
            "Epoch 14/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 0.7054 - loss: 0.6735 - val_accuracy: 0.7067 - val_loss: 0.5598\n",
            "Epoch 15/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - accuracy: 0.6994 - loss: 0.6746 - val_accuracy: 0.7087 - val_loss: 0.5550\n",
            "Epoch 16/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.7112 - loss: 0.6626 - val_accuracy: 0.7238 - val_loss: 0.5411\n",
            "Epoch 17/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.7243 - loss: 0.6554 - val_accuracy: 0.7258 - val_loss: 0.5521\n",
            "Epoch 18/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.7120 - loss: 0.6729 - val_accuracy: 0.7288 - val_loss: 0.5428\n",
            "Epoch 19/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.7298 - loss: 0.6560 - val_accuracy: 0.7409 - val_loss: 0.5615\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - accuracy: 0.5110 - loss: 0.8409 - val_accuracy: 0.5232 - val_loss: 0.6893\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.5714 - loss: 0.8116 - val_accuracy: 0.4698 - val_loss: 0.7415\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.5104 - loss: 0.8431 - val_accuracy: 0.4698 - val_loss: 0.7041\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.5023 - loss: 0.8462 - val_accuracy: 0.4698 - val_loss: 0.7289\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.4990 - loss: 0.8436 - val_accuracy: 0.5938 - val_loss: 0.6756\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.5496 - loss: 0.8169 - val_accuracy: 0.4980 - val_loss: 0.7000\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.6002 - loss: 0.7734 - val_accuracy: 0.5292 - val_loss: 0.6875\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 56ms/step - accuracy: 0.6055 - loss: 0.7681 - val_accuracy: 0.6129 - val_loss: 0.6618\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.6356 - loss: 0.7590 - val_accuracy: 0.6190 - val_loss: 0.6532\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.6351 - loss: 0.7631 - val_accuracy: 0.6179 - val_loss: 0.6535\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.6342 - loss: 0.7579 - val_accuracy: 0.6159 - val_loss: 0.6641\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.6440 - loss: 0.7620 - val_accuracy: 0.6169 - val_loss: 0.6452\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.6166 - loss: 0.7705 - val_accuracy: 0.6109 - val_loss: 0.6725\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.6430 - loss: 0.7571 - val_accuracy: 0.6512 - val_loss: 0.6419\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.6506 - loss: 0.7487 - val_accuracy: 0.6351 - val_loss: 0.6479\n",
            "Epoch 12/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.6446 - loss: 0.7460 - val_accuracy: 0.6532 - val_loss: 0.6343\n",
            "Epoch 13/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - accuracy: 0.6331 - loss: 0.7451 - val_accuracy: 0.6784 - val_loss: 0.5948\n",
            "Epoch 14/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.7036 - loss: 0.6924 - val_accuracy: 0.7147 - val_loss: 0.5538\n",
            "Epoch 15/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.6916 - loss: 0.6909 - val_accuracy: 0.7198 - val_loss: 0.5534\n",
            "Epoch 16/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.6873 - loss: 0.7034 - val_accuracy: 0.7319 - val_loss: 0.5561\n",
            "Epoch 17/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.7075 - loss: 0.6727 - val_accuracy: 0.7016 - val_loss: 0.5715\n",
            "Epoch 18/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - accuracy: 0.7077 - loss: 0.6779 - val_accuracy: 0.6895 - val_loss: 0.5742\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
            "Training CNN...\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.5064 - loss: 0.8187 - val_accuracy: 0.6018 - val_loss: 0.6659\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5886 - loss: 0.7773 - val_accuracy: 0.6452 - val_loss: 0.6445\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6473 - loss: 0.7468 - val_accuracy: 0.6552 - val_loss: 0.6273\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6820 - loss: 0.7212 - val_accuracy: 0.7006 - val_loss: 0.5902\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7024 - loss: 0.7001 - val_accuracy: 0.6946 - val_loss: 0.5958\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6877 - loss: 0.6886 - val_accuracy: 0.7238 - val_loss: 0.5650\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7162 - loss: 0.6693 - val_accuracy: 0.7329 - val_loss: 0.5593\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7179 - loss: 0.6588 - val_accuracy: 0.7157 - val_loss: 0.5627\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7310 - loss: 0.6406 - val_accuracy: 0.6986 - val_loss: 0.5734\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7338 - loss: 0.6375 - val_accuracy: 0.7006 - val_loss: 0.5688\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.4972 - loss: 0.8350 - val_accuracy: 0.5958 - val_loss: 0.6642\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6230 - loss: 0.7651 - val_accuracy: 0.6623 - val_loss: 0.6305\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6844 - loss: 0.7131 - val_accuracy: 0.6018 - val_loss: 0.6632\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6752 - loss: 0.7032 - val_accuracy: 0.5837 - val_loss: 0.6791\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6932 - loss: 0.6880 - val_accuracy: 0.7046 - val_loss: 0.5641\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7032 - loss: 0.6820 - val_accuracy: 0.7258 - val_loss: 0.5511\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7190 - loss: 0.6471 - val_accuracy: 0.7339 - val_loss: 0.5451\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7129 - loss: 0.6576 - val_accuracy: 0.6996 - val_loss: 0.5584\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7247 - loss: 0.6545 - val_accuracy: 0.7329 - val_loss: 0.5328\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7342 - loss: 0.6273 - val_accuracy: 0.7258 - val_loss: 0.5392\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.5070 - loss: 0.8224 - val_accuracy: 0.4698 - val_loss: 0.6877\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5669 - loss: 0.7849 - val_accuracy: 0.5948 - val_loss: 0.6628\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6328 - loss: 0.7445 - val_accuracy: 0.6774 - val_loss: 0.6192\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6836 - loss: 0.7257 - val_accuracy: 0.6855 - val_loss: 0.6107\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6841 - loss: 0.7048 - val_accuracy: 0.7056 - val_loss: 0.5878\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7082 - loss: 0.6792 - val_accuracy: 0.7208 - val_loss: 0.5742\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7045 - loss: 0.6787 - val_accuracy: 0.6996 - val_loss: 0.5835\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7194 - loss: 0.6600 - val_accuracy: 0.6008 - val_loss: 0.6523\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6963 - loss: 0.6751 - val_accuracy: 0.7329 - val_loss: 0.5481\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7429 - loss: 0.6397 - val_accuracy: 0.7369 - val_loss: 0.5467\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5068 - loss: 0.8218 - val_accuracy: 0.4758 - val_loss: 0.6842\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5979 - loss: 0.7740 - val_accuracy: 0.6300 - val_loss: 0.6502\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6624 - loss: 0.7313 - val_accuracy: 0.6663 - val_loss: 0.6037\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6877 - loss: 0.7075 - val_accuracy: 0.6613 - val_loss: 0.6111\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6921 - loss: 0.6862 - val_accuracy: 0.6482 - val_loss: 0.6083\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7338 - loss: 0.6445 - val_accuracy: 0.7349 - val_loss: 0.5589\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7280 - loss: 0.6420 - val_accuracy: 0.6542 - val_loss: 0.6058\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7187 - loss: 0.6527 - val_accuracy: 0.7198 - val_loss: 0.5585\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7268 - loss: 0.6591 - val_accuracy: 0.7228 - val_loss: 0.5528\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7423 - loss: 0.6269 - val_accuracy: 0.7288 - val_loss: 0.5491\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5046 - loss: 0.8236 - val_accuracy: 0.4698 - val_loss: 0.6946\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5542 - loss: 0.7797 - val_accuracy: 0.6341 - val_loss: 0.6535\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6097 - loss: 0.7558 - val_accuracy: 0.6734 - val_loss: 0.6219\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6772 - loss: 0.7211 - val_accuracy: 0.6573 - val_loss: 0.6397\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6636 - loss: 0.7238 - val_accuracy: 0.6744 - val_loss: 0.6181\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6891 - loss: 0.7048 - val_accuracy: 0.6562 - val_loss: 0.6255\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6902 - loss: 0.6960 - val_accuracy: 0.6482 - val_loss: 0.6293\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6802 - loss: 0.6996 - val_accuracy: 0.7026 - val_loss: 0.5841\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7142 - loss: 0.6643 - val_accuracy: 0.6633 - val_loss: 0.6101\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7090 - loss: 0.6650 - val_accuracy: 0.7046 - val_loss: 0.5777\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.5011 - loss: 0.8242 - val_accuracy: 0.6280 - val_loss: 0.6604\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6024 - loss: 0.7704 - val_accuracy: 0.6663 - val_loss: 0.6291\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6626 - loss: 0.7355 - val_accuracy: 0.6694 - val_loss: 0.6259\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6731 - loss: 0.7211 - val_accuracy: 0.6804 - val_loss: 0.6069\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6803 - loss: 0.7040 - val_accuracy: 0.6976 - val_loss: 0.5933\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7074 - loss: 0.6807 - val_accuracy: 0.7167 - val_loss: 0.5645\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7221 - loss: 0.6506 - val_accuracy: 0.6542 - val_loss: 0.6147\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6967 - loss: 0.6622 - val_accuracy: 0.7137 - val_loss: 0.5605\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7379 - loss: 0.6288 - val_accuracy: 0.6643 - val_loss: 0.6005\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7285 - loss: 0.6489 - val_accuracy: 0.6905 - val_loss: 0.5750\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.4913 - loss: 0.8689 - val_accuracy: 0.4698 - val_loss: 0.6898\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5066 - loss: 0.7968 - val_accuracy: 0.5534 - val_loss: 0.6714\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6134 - loss: 0.7723 - val_accuracy: 0.6633 - val_loss: 0.6379\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6515 - loss: 0.7509 - val_accuracy: 0.6825 - val_loss: 0.6209\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6660 - loss: 0.7323 - val_accuracy: 0.6925 - val_loss: 0.6107\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6898 - loss: 0.7216 - val_accuracy: 0.6815 - val_loss: 0.6090\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6868 - loss: 0.7069 - val_accuracy: 0.6694 - val_loss: 0.6145\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6971 - loss: 0.6929 - val_accuracy: 0.7107 - val_loss: 0.5793\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6892 - loss: 0.6941 - val_accuracy: 0.6925 - val_loss: 0.5919\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7161 - loss: 0.6759 - val_accuracy: 0.7258 - val_loss: 0.5675\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4884 - loss: 0.8376 - val_accuracy: 0.4889 - val_loss: 0.6778\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5202 - loss: 0.7869 - val_accuracy: 0.6613 - val_loss: 0.6388\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6616 - loss: 0.7398 - val_accuracy: 0.6714 - val_loss: 0.6240\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6768 - loss: 0.7313 - val_accuracy: 0.6865 - val_loss: 0.6096\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6868 - loss: 0.7176 - val_accuracy: 0.6996 - val_loss: 0.5806\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6920 - loss: 0.7008 - val_accuracy: 0.7046 - val_loss: 0.5753\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7182 - loss: 0.6763 - val_accuracy: 0.7218 - val_loss: 0.5663\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7229 - loss: 0.6540 - val_accuracy: 0.6351 - val_loss: 0.6184\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7146 - loss: 0.6592 - val_accuracy: 0.7329 - val_loss: 0.5572\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7241 - loss: 0.6479 - val_accuracy: 0.7147 - val_loss: 0.5436\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.5070 - loss: 0.8208 - val_accuracy: 0.6421 - val_loss: 0.6589\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5838 - loss: 0.7784 - val_accuracy: 0.6623 - val_loss: 0.6311\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6454 - loss: 0.7443 - val_accuracy: 0.6875 - val_loss: 0.6009\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6657 - loss: 0.7168 - val_accuracy: 0.6754 - val_loss: 0.6156\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6776 - loss: 0.7075 - val_accuracy: 0.7097 - val_loss: 0.5810\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7188 - loss: 0.6679 - val_accuracy: 0.7188 - val_loss: 0.5576\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7169 - loss: 0.6578 - val_accuracy: 0.7329 - val_loss: 0.5551\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7269 - loss: 0.6492 - val_accuracy: 0.6673 - val_loss: 0.5919\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7217 - loss: 0.6394 - val_accuracy: 0.7369 - val_loss: 0.5372\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7219 - loss: 0.6334 - val_accuracy: 0.7167 - val_loss: 0.5522\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7328 - loss: 0.6212 - val_accuracy: 0.7409 - val_loss: 0.5355\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7488 - loss: 0.6166 - val_accuracy: 0.7369 - val_loss: 0.5296\n",
            "Epoch 13/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7448 - loss: 0.6138 - val_accuracy: 0.7167 - val_loss: 0.5520\n",
            "Epoch 14/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7341 - loss: 0.6201 - val_accuracy: 0.7429 - val_loss: 0.5120\n",
            "Epoch 15/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7567 - loss: 0.6033 - val_accuracy: 0.6956 - val_loss: 0.5610\n",
            "Epoch 16/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7452 - loss: 0.6010 - val_accuracy: 0.7560 - val_loss: 0.5070\n",
            "Epoch 17/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7440 - loss: 0.6100 - val_accuracy: 0.7248 - val_loss: 0.5352\n",
            "Epoch 18/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7608 - loss: 0.5735 - val_accuracy: 0.7470 - val_loss: 0.5231\n",
            "Epoch 19/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7530 - loss: 0.5975 - val_accuracy: 0.7117 - val_loss: 0.5408\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.4971 - loss: 0.8183 - val_accuracy: 0.5121 - val_loss: 0.6749\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6284 - loss: 0.7550 - val_accuracy: 0.6683 - val_loss: 0.6252\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6733 - loss: 0.7128 - val_accuracy: 0.6935 - val_loss: 0.5842\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7036 - loss: 0.6774 - val_accuracy: 0.7147 - val_loss: 0.5702\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7079 - loss: 0.6773 - val_accuracy: 0.6825 - val_loss: 0.5938\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7217 - loss: 0.6407 - val_accuracy: 0.6734 - val_loss: 0.5943\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7196 - loss: 0.6497 - val_accuracy: 0.6976 - val_loss: 0.5724\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.4916 - loss: 0.8271 - val_accuracy: 0.4788 - val_loss: 0.6818\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5762 - loss: 0.7795 - val_accuracy: 0.6280 - val_loss: 0.6536\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6546 - loss: 0.7352 - val_accuracy: 0.6683 - val_loss: 0.6258\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6842 - loss: 0.7178 - val_accuracy: 0.6905 - val_loss: 0.6017\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6813 - loss: 0.7064 - val_accuracy: 0.7036 - val_loss: 0.5924\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6878 - loss: 0.6956 - val_accuracy: 0.7188 - val_loss: 0.5760\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7072 - loss: 0.6706 - val_accuracy: 0.7177 - val_loss: 0.5692\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7064 - loss: 0.6690 - val_accuracy: 0.7208 - val_loss: 0.5560\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7185 - loss: 0.6592 - val_accuracy: 0.6714 - val_loss: 0.5923\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7125 - loss: 0.6492 - val_accuracy: 0.7127 - val_loss: 0.5683\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7278 - loss: 0.6351 - val_accuracy: 0.6855 - val_loss: 0.5787\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5085 - loss: 0.8229 - val_accuracy: 0.5907 - val_loss: 0.6646\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6135 - loss: 0.7650 - val_accuracy: 0.6815 - val_loss: 0.6127\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6563 - loss: 0.7379 - val_accuracy: 0.6915 - val_loss: 0.5979\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6699 - loss: 0.7122 - val_accuracy: 0.7016 - val_loss: 0.5869\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7031 - loss: 0.6750 - val_accuracy: 0.7248 - val_loss: 0.5686\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7190 - loss: 0.6593 - val_accuracy: 0.7077 - val_loss: 0.5649\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7225 - loss: 0.6543 - val_accuracy: 0.7218 - val_loss: 0.5529\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7258 - loss: 0.6422 - val_accuracy: 0.7268 - val_loss: 0.5469\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7304 - loss: 0.6389 - val_accuracy: 0.6048 - val_loss: 0.6811\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7274 - loss: 0.6457 - val_accuracy: 0.7399 - val_loss: 0.5303\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7307 - loss: 0.6218 - val_accuracy: 0.7419 - val_loss: 0.5296\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7196 - loss: 0.6372 - val_accuracy: 0.7298 - val_loss: 0.5391\n",
            "Epoch 13/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7440 - loss: 0.6142 - val_accuracy: 0.7329 - val_loss: 0.5324\n",
            "Epoch 14/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7665 - loss: 0.5857 - val_accuracy: 0.7450 - val_loss: 0.5250\n",
            "Epoch 15/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7406 - loss: 0.6004 - val_accuracy: 0.7560 - val_loss: 0.5097\n",
            "Epoch 16/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7433 - loss: 0.6158 - val_accuracy: 0.7409 - val_loss: 0.5216\n",
            "Epoch 17/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7239 - loss: 0.6264 - val_accuracy: 0.7611 - val_loss: 0.5119\n",
            "Epoch 18/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7708 - loss: 0.5785 - val_accuracy: 0.7550 - val_loss: 0.4986\n",
            "Epoch 19/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7561 - loss: 0.5922 - val_accuracy: 0.7671 - val_loss: 0.5015\n",
            "Epoch 20/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7478 - loss: 0.5856 - val_accuracy: 0.7712 - val_loss: 0.4961\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.5063 - loss: 0.8215 - val_accuracy: 0.4940 - val_loss: 0.6759\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5305 - loss: 0.7875 - val_accuracy: 0.6351 - val_loss: 0.6529\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6322 - loss: 0.7580 - val_accuracy: 0.6865 - val_loss: 0.6210\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6541 - loss: 0.7391 - val_accuracy: 0.6643 - val_loss: 0.6206\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6758 - loss: 0.7238 - val_accuracy: 0.6633 - val_loss: 0.6254\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6780 - loss: 0.7087 - val_accuracy: 0.6371 - val_loss: 0.6398\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6905 - loss: 0.7015 - val_accuracy: 0.7077 - val_loss: 0.5857\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7153 - loss: 0.6832 - val_accuracy: 0.7167 - val_loss: 0.5720\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7003 - loss: 0.6807 - val_accuracy: 0.6643 - val_loss: 0.6078\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7053 - loss: 0.6655 - val_accuracy: 0.7218 - val_loss: 0.5609\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7283 - loss: 0.6489 - val_accuracy: 0.7147 - val_loss: 0.5640\n",
            "Epoch 12/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7340 - loss: 0.6277 - val_accuracy: 0.7298 - val_loss: 0.5460\n",
            "Epoch 13/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7262 - loss: 0.6360 - val_accuracy: 0.7107 - val_loss: 0.5665\n",
            "Epoch 14/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7249 - loss: 0.6286 - val_accuracy: 0.6976 - val_loss: 0.5792\n",
            "Epoch 15/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7372 - loss: 0.6276 - val_accuracy: 0.7298 - val_loss: 0.5484\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.5020 - loss: 0.8209 - val_accuracy: 0.4698 - val_loss: 0.6988\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5961 - loss: 0.7778 - val_accuracy: 0.6643 - val_loss: 0.6318\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6506 - loss: 0.7433 - val_accuracy: 0.6694 - val_loss: 0.6196\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6664 - loss: 0.7178 - val_accuracy: 0.6472 - val_loss: 0.6281\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6842 - loss: 0.6944 - val_accuracy: 0.7137 - val_loss: 0.5772\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7086 - loss: 0.6729 - val_accuracy: 0.7127 - val_loss: 0.5728\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7046 - loss: 0.6628 - val_accuracy: 0.6935 - val_loss: 0.5688\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7161 - loss: 0.6538 - val_accuracy: 0.7298 - val_loss: 0.5518\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7173 - loss: 0.6439 - val_accuracy: 0.7268 - val_loss: 0.5491\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7189 - loss: 0.6329 - val_accuracy: 0.7409 - val_loss: 0.5357\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7573 - loss: 0.6079 - val_accuracy: 0.7127 - val_loss: 0.5525\n",
            "Epoch 12/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7379 - loss: 0.6153 - val_accuracy: 0.7399 - val_loss: 0.5361\n",
            "Epoch 13/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7475 - loss: 0.6091 - val_accuracy: 0.7097 - val_loss: 0.5596\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.5028 - loss: 0.8370 - val_accuracy: 0.4698 - val_loss: 0.7078\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5124 - loss: 0.8082 - val_accuracy: 0.4698 - val_loss: 0.6850\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5368 - loss: 0.7941 - val_accuracy: 0.6290 - val_loss: 0.6578\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6085 - loss: 0.7559 - val_accuracy: 0.6220 - val_loss: 0.6538\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6338 - loss: 0.7317 - val_accuracy: 0.6925 - val_loss: 0.6141\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6748 - loss: 0.7207 - val_accuracy: 0.7006 - val_loss: 0.6009\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6974 - loss: 0.6966 - val_accuracy: 0.6804 - val_loss: 0.6067\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7110 - loss: 0.6819 - val_accuracy: 0.7167 - val_loss: 0.5805\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7003 - loss: 0.6858 - val_accuracy: 0.7046 - val_loss: 0.5867\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7105 - loss: 0.6672 - val_accuracy: 0.7349 - val_loss: 0.5607\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7167 - loss: 0.6706 - val_accuracy: 0.7188 - val_loss: 0.5740\n",
            "Epoch 12/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7147 - loss: 0.6483 - val_accuracy: 0.7238 - val_loss: 0.5660\n",
            "Epoch 13/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7278 - loss: 0.6430 - val_accuracy: 0.7298 - val_loss: 0.5427\n",
            "Epoch 14/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7281 - loss: 0.6433 - val_accuracy: 0.7440 - val_loss: 0.5438\n",
            "Epoch 15/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7299 - loss: 0.6386 - val_accuracy: 0.7319 - val_loss: 0.5499\n",
            "Epoch 16/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7318 - loss: 0.6308 - val_accuracy: 0.7490 - val_loss: 0.5322\n",
            "Epoch 17/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7423 - loss: 0.6185 - val_accuracy: 0.7440 - val_loss: 0.5322\n",
            "Epoch 18/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7395 - loss: 0.6233 - val_accuracy: 0.7399 - val_loss: 0.5373\n",
            "Epoch 19/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7378 - loss: 0.6333 - val_accuracy: 0.7450 - val_loss: 0.5263\n",
            "Epoch 20/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7388 - loss: 0.6230 - val_accuracy: 0.7520 - val_loss: 0.5217\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.5025 - loss: 0.8297 - val_accuracy: 0.4698 - val_loss: 0.6916\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5229 - loss: 0.7899 - val_accuracy: 0.6361 - val_loss: 0.6529\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6330 - loss: 0.7565 - val_accuracy: 0.6724 - val_loss: 0.6275\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6751 - loss: 0.7205 - val_accuracy: 0.6895 - val_loss: 0.5997\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6748 - loss: 0.7126 - val_accuracy: 0.6996 - val_loss: 0.5891\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6863 - loss: 0.6929 - val_accuracy: 0.7137 - val_loss: 0.5759\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7114 - loss: 0.6788 - val_accuracy: 0.7208 - val_loss: 0.5628\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7282 - loss: 0.6532 - val_accuracy: 0.7329 - val_loss: 0.5533\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6827 - loss: 0.6895 - val_accuracy: 0.6603 - val_loss: 0.6081\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7226 - loss: 0.6420 - val_accuracy: 0.7379 - val_loss: 0.5447\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7215 - loss: 0.6383 - val_accuracy: 0.7550 - val_loss: 0.5373\n",
            "Epoch 12/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7263 - loss: 0.6275 - val_accuracy: 0.7137 - val_loss: 0.5384\n",
            "Epoch 13/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7362 - loss: 0.6344 - val_accuracy: 0.6784 - val_loss: 0.5768\n",
            "Epoch 14/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7350 - loss: 0.6183 - val_accuracy: 0.7198 - val_loss: 0.5554\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Experiment completed. Results saved.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Conv1D, GlobalMaxPooling1D, Dropout, Input, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import joblib\n",
        "import json\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Set paths\n",
        "data_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/data.xlsx\"\n",
        "save_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/deep_learning_results5\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_excel(data_path)\n",
        "df.dropna(inplace=True)\n",
        "print(\"Size of DataFrame after dropping null values:\", df.shape)\n",
        "\n",
        "# Function to parse vector strings into numpy arrays\n",
        "def parse_vector(vector_str, expected_dim):\n",
        "    try:\n",
        "        if isinstance(vector_str, str):\n",
        "            vec = np.array([float(i) for i in vector_str.strip(\"[]\").split()], dtype=np.float32)\n",
        "            if vec.shape[0] == expected_dim:\n",
        "                return vec\n",
        "            elif vec.shape[0] > expected_dim:\n",
        "                return vec[:expected_dim]  # Truncate to expected size\n",
        "            else:\n",
        "                return np.pad(vec, (0, expected_dim - vec.shape[0]))  # Pad with zeros\n",
        "    except:\n",
        "        return np.zeros(expected_dim, dtype=np.float32)  # Default to zero vector\n",
        "    return np.zeros(expected_dim, dtype=np.float32)\n",
        "\n",
        "# Define expected dimensions\n",
        "word2vec_dim = 300\n",
        "fasttext_dim = 300\n",
        "sentence_embedding_dim = 300\n",
        "sinbert_dim = 768  # Larger than others\n",
        "\n",
        "# Apply parsing with dimension corrections\n",
        "df['word2vec_vector'] = df['word2vec_vector'].map(lambda x: parse_vector(x, word2vec_dim))\n",
        "df['fasttext_vector'] = df['fasttext_vector'].map(lambda x: parse_vector(x, fasttext_dim))\n",
        "df['sentence_embedding'] = df['sentence_embedding'].map(lambda x: parse_vector(x, sentence_embedding_dim))\n",
        "df['sinbert_vector'] = df['sinbert_vector'].map(lambda x: parse_vector(x, sinbert_dim))  # Keep 768D\n",
        "\n",
        "# Ensure all feature vectors have the same final dimension\n",
        "final_dim = 768  # Choose larger or normalize to 300\n",
        "for feature in ['word2vec_vector', 'fasttext_vector', 'sentence_embedding']:\n",
        "    df[feature] = df[feature].map(lambda x: np.pad(x, (0, final_dim - x.shape[0])) if x.shape[0] < final_dim else x[:final_dim])\n",
        "\n",
        "# Stack feature vectors correctly\n",
        "X = np.stack(df[['word2vec_vector', 'fasttext_vector', 'sentence_embedding', 'sinbert_vector']].apply(lambda row: np.column_stack(row.values), axis=1).values)\n",
        "\n",
        "# Flatten X for MLP: (samples, final_dim * 4)\n",
        "X_flattened = X.reshape(X.shape[0], -1)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'].values)\n",
        "joblib.dump(label_encoder, os.path.join(save_path, 'label_encoder.pkl'))\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train_flattened, X_test_flattened = train_test_split(X_flattened, test_size=0.2, random_state=42)\n",
        "\n",
        "# Function to implement early stopping and class weights\n",
        "def build_mlp(input_shape, dropout_rate, dense_units):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Dense(dense_units, activation='relu'),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(dense_units // 2, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_lstm(input_shape, dropout_rate, lstm_units):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        LSTM(lstm_units, return_sequences=True),\n",
        "        Dropout(dropout_rate),\n",
        "        LSTM(lstm_units // 2),\n",
        "        Flatten(),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_cnn(input_shape, dropout_rate, filters):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Conv1D(filters, kernel_size=3, activation='relu'),\n",
        "        Dropout(dropout_rate),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(filters // 2, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Early stopping callback to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Apply class weights (use if there is class imbalance)\n",
        "class_weights = {0: 1, 1: 1.5}  # Increase weight for the minority class\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"confusion_matrix\": conf_matrix.tolist()\n",
        "    }\n",
        "\n",
        "# Train and evaluate models with hyperparameter tuning and regularization\n",
        "results = {}\n",
        "\n",
        "# Model hyperparameters for tuning\n",
        "params = {\n",
        "    'MLP': {\n",
        "        'epochs': [10, 20],\n",
        "        'batch_size': [16, 32],\n",
        "        'dropout': [0.2, 0.3],\n",
        "        'dense_units': [64, 128]\n",
        "    },\n",
        "    'LSTM': {\n",
        "        'epochs': [10, 20],\n",
        "        'batch_size': [16, 32],\n",
        "        'dropout': [0.2, 0.3],\n",
        "        'lstm_units': [64, 128],\n",
        "    },\n",
        "    'CNN': {\n",
        "        'epochs': [10, 20],\n",
        "        'batch_size': [16, 32],\n",
        "        'dropout': [0.2, 0.3],\n",
        "        'filters': [64, 128],\n",
        "    }\n",
        "}\n",
        "\n",
        "# Train and evaluate each model\n",
        "for name in ['MLP', 'LSTM', 'CNN']:\n",
        "    print(f\"Training {name}...\")\n",
        "\n",
        "    # Hyperparameter grid search (manually tuned here)\n",
        "    for epochs in params[name]['epochs']:\n",
        "        for batch_size in params[name]['batch_size']:\n",
        "            if name == 'MLP':\n",
        "                for dropout in params[name]['dropout']:\n",
        "                    for dense_units in params[name]['dense_units']:\n",
        "                        model_instance = build_mlp((X_train_flattened.shape[1],), dropout, dense_units)\n",
        "                        model_instance.fit(X_train_flattened, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                                           validation_data=(X_test_flattened, y_test), class_weight=class_weights,\n",
        "                                           callbacks=[early_stopping], verbose=1)\n",
        "                        y_pred = (model_instance.predict(X_test_flattened) > 0.5).astype(int)\n",
        "                        results[name] = evaluate_model(y_test, y_pred)\n",
        "            elif name == 'LSTM':\n",
        "                for dropout in params[name]['dropout']:\n",
        "                    for lstm_units in params[name]['lstm_units']:\n",
        "                        model_instance = build_lstm((X_train.shape[1], X_train.shape[2]), dropout, lstm_units)\n",
        "                        model_instance.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                                           validation_data=(X_test, y_test), class_weight=class_weights,\n",
        "                                           callbacks=[early_stopping], verbose=1)\n",
        "                        y_pred = (model_instance.predict(X_test) > 0.5).astype(int)\n",
        "                        results[name] = evaluate_model(y_test, y_pred)\n",
        "            elif name == 'CNN':\n",
        "                for dropout in params[name]['dropout']:\n",
        "                    for filters in params[name]['filters']:\n",
        "                        model_instance = build_cnn((X_train.shape[1], X_train.shape[2]), dropout, filters)\n",
        "                        model_instance.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                                           validation_data=(X_test, y_test), class_weight=class_weights,\n",
        "                                           callbacks=[early_stopping], verbose=1)\n",
        "                        y_pred = (model_instance.predict(X_test) > 0.5).astype(int)\n",
        "                        results[name] = evaluate_model(y_test, y_pred)\n",
        "\n",
        "# Save results to JSON\n",
        "results_path = os.path.join(save_path, \"model_results.json\")\n",
        "with open(results_path, \"w\") as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n",
        "print(\"Experiment completed. Results saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGLZv8EKIRfA",
        "outputId": "89cfc273-a2b5-4241-cd28-d26244165009"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of DataFrame after dropping null values: (4958, 8)\n",
            "Training MLP...\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.7410 - loss: 0.6352 - val_accuracy: 0.8034 - val_loss: 0.4331\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7975 - loss: 0.5205 - val_accuracy: 0.8054 - val_loss: 0.4397\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8096 - loss: 0.4943 - val_accuracy: 0.8044 - val_loss: 0.4558\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8306 - loss: 0.4660 - val_accuracy: 0.8054 - val_loss: 0.4368\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.7369 - loss: 0.6140 - val_accuracy: 0.7712 - val_loss: 0.4973\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7986 - loss: 0.5121 - val_accuracy: 0.7712 - val_loss: 0.4900\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8150 - loss: 0.4867 - val_accuracy: 0.8054 - val_loss: 0.4333\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8189 - loss: 0.4722 - val_accuracy: 0.8054 - val_loss: 0.4412\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8187 - loss: 0.4601 - val_accuracy: 0.7560 - val_loss: 0.5050\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8377 - loss: 0.4246 - val_accuracy: 0.8135 - val_loss: 0.4251\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8477 - loss: 0.4122 - val_accuracy: 0.8095 - val_loss: 0.4226\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8523 - loss: 0.4047 - val_accuracy: 0.8125 - val_loss: 0.4356\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8529 - loss: 0.3958 - val_accuracy: 0.7812 - val_loss: 0.4797\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8569 - loss: 0.3946 - val_accuracy: 0.8155 - val_loss: 0.4324\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6965 - loss: 0.6555 - val_accuracy: 0.7944 - val_loss: 0.4430\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.7987 - loss: 0.5266 - val_accuracy: 0.7984 - val_loss: 0.4434\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7995 - loss: 0.5185 - val_accuracy: 0.8065 - val_loss: 0.4389\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8038 - loss: 0.5160 - val_accuracy: 0.8075 - val_loss: 0.4267\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8264 - loss: 0.4674 - val_accuracy: 0.8054 - val_loss: 0.4392\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8221 - loss: 0.4671 - val_accuracy: 0.8095 - val_loss: 0.4331\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8365 - loss: 0.4462 - val_accuracy: 0.7843 - val_loss: 0.4775\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.7421 - loss: 0.6158 - val_accuracy: 0.7833 - val_loss: 0.4670\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8060 - loss: 0.5110 - val_accuracy: 0.8034 - val_loss: 0.4567\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8018 - loss: 0.5084 - val_accuracy: 0.8065 - val_loss: 0.4233\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8107 - loss: 0.4858 - val_accuracy: 0.8014 - val_loss: 0.4368\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8268 - loss: 0.4681 - val_accuracy: 0.8155 - val_loss: 0.4340\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8352 - loss: 0.4566 - val_accuracy: 0.8115 - val_loss: 0.4195\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.8191 - loss: 0.4600 - val_accuracy: 0.8165 - val_loss: 0.4317\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8320 - loss: 0.4388 - val_accuracy: 0.7944 - val_loss: 0.4741\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8470 - loss: 0.4097 - val_accuracy: 0.7873 - val_loss: 0.4639\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6847 - loss: 0.6849 - val_accuracy: 0.7863 - val_loss: 0.4671\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8083 - loss: 0.5028 - val_accuracy: 0.7994 - val_loss: 0.4401\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8132 - loss: 0.5004 - val_accuracy: 0.8044 - val_loss: 0.4301\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8102 - loss: 0.4901 - val_accuracy: 0.8105 - val_loss: 0.4331\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8193 - loss: 0.4641 - val_accuracy: 0.7974 - val_loss: 0.4582\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8376 - loss: 0.4457 - val_accuracy: 0.8135 - val_loss: 0.4331\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.7352 - loss: 0.6231 - val_accuracy: 0.7913 - val_loss: 0.4629\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8108 - loss: 0.4963 - val_accuracy: 0.7802 - val_loss: 0.4722\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8242 - loss: 0.4636 - val_accuracy: 0.7833 - val_loss: 0.4754\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8176 - loss: 0.4770 - val_accuracy: 0.8034 - val_loss: 0.4253\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8210 - loss: 0.4589 - val_accuracy: 0.7974 - val_loss: 0.4603\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8333 - loss: 0.4480 - val_accuracy: 0.8014 - val_loss: 0.4405\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8464 - loss: 0.4198 - val_accuracy: 0.8115 - val_loss: 0.4285\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6990 - loss: 0.6636 - val_accuracy: 0.8004 - val_loss: 0.4537\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7988 - loss: 0.5201 - val_accuracy: 0.8034 - val_loss: 0.4409\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8147 - loss: 0.4957 - val_accuracy: 0.7883 - val_loss: 0.4602\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8032 - loss: 0.5017 - val_accuracy: 0.8155 - val_loss: 0.4299\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8234 - loss: 0.4687 - val_accuracy: 0.8155 - val_loss: 0.4213\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8353 - loss: 0.4542 - val_accuracy: 0.8085 - val_loss: 0.4395\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8245 - loss: 0.4499 - val_accuracy: 0.8024 - val_loss: 0.4514\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8339 - loss: 0.4385 - val_accuracy: 0.8075 - val_loss: 0.4417\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7225 - loss: 0.6203 - val_accuracy: 0.7984 - val_loss: 0.4391\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8100 - loss: 0.5124 - val_accuracy: 0.8125 - val_loss: 0.4320\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8046 - loss: 0.4983 - val_accuracy: 0.7944 - val_loss: 0.4522\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8121 - loss: 0.4803 - val_accuracy: 0.8105 - val_loss: 0.4284\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8136 - loss: 0.4775 - val_accuracy: 0.8115 - val_loss: 0.4220\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8357 - loss: 0.4426 - val_accuracy: 0.8125 - val_loss: 0.4283\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8528 - loss: 0.4273 - val_accuracy: 0.8135 - val_loss: 0.4177\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8316 - loss: 0.4454 - val_accuracy: 0.8155 - val_loss: 0.4250\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8439 - loss: 0.4101 - val_accuracy: 0.8054 - val_loss: 0.4447\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8422 - loss: 0.4057 - val_accuracy: 0.8125 - val_loss: 0.4307\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6897 - loss: 0.6595 - val_accuracy: 0.7944 - val_loss: 0.4512\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8065 - loss: 0.5205 - val_accuracy: 0.7903 - val_loss: 0.4479\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8116 - loss: 0.5069 - val_accuracy: 0.7843 - val_loss: 0.4622\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8160 - loss: 0.4819 - val_accuracy: 0.7843 - val_loss: 0.4741\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8204 - loss: 0.4829 - val_accuracy: 0.8085 - val_loss: 0.4328\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8232 - loss: 0.4729 - val_accuracy: 0.8115 - val_loss: 0.4315\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8277 - loss: 0.4530 - val_accuracy: 0.7944 - val_loss: 0.4674\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8413 - loss: 0.4327 - val_accuracy: 0.7974 - val_loss: 0.4589\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.8409 - loss: 0.4139 - val_accuracy: 0.8155 - val_loss: 0.4380\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.7445 - loss: 0.6233 - val_accuracy: 0.7964 - val_loss: 0.4559\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8009 - loss: 0.5195 - val_accuracy: 0.8075 - val_loss: 0.4311\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8131 - loss: 0.5068 - val_accuracy: 0.8085 - val_loss: 0.4233\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.8263 - loss: 0.4676 - val_accuracy: 0.7752 - val_loss: 0.4842\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8392 - loss: 0.4358 - val_accuracy: 0.8155 - val_loss: 0.4188\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8239 - loss: 0.4532 - val_accuracy: 0.8065 - val_loss: 0.4280\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8364 - loss: 0.4204 - val_accuracy: 0.8175 - val_loss: 0.4223\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8389 - loss: 0.4132 - val_accuracy: 0.8105 - val_loss: 0.4321\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.7327 - loss: 0.6229 - val_accuracy: 0.7681 - val_loss: 0.4777\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8000 - loss: 0.5251 - val_accuracy: 0.7964 - val_loss: 0.4583\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8017 - loss: 0.5084 - val_accuracy: 0.8075 - val_loss: 0.4280\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8138 - loss: 0.4812 - val_accuracy: 0.8085 - val_loss: 0.4319\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8124 - loss: 0.4857 - val_accuracy: 0.8145 - val_loss: 0.4281\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.8338 - loss: 0.4506 - val_accuracy: 0.8135 - val_loss: 0.4189\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8271 - loss: 0.4695 - val_accuracy: 0.7853 - val_loss: 0.4689\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8316 - loss: 0.4466 - val_accuracy: 0.8226 - val_loss: 0.4273\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8332 - loss: 0.4359 - val_accuracy: 0.7974 - val_loss: 0.4616\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.6870 - loss: 0.6573 - val_accuracy: 0.7843 - val_loss: 0.4715\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.7957 - loss: 0.5256 - val_accuracy: 0.8054 - val_loss: 0.4329\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.8328 - loss: 0.4684 - val_accuracy: 0.7944 - val_loss: 0.4390\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8070 - loss: 0.4977 - val_accuracy: 0.7702 - val_loss: 0.4923\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8121 - loss: 0.4798 - val_accuracy: 0.8075 - val_loss: 0.4245\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8250 - loss: 0.4565 - val_accuracy: 0.8095 - val_loss: 0.4567\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8102 - loss: 0.4717 - val_accuracy: 0.8075 - val_loss: 0.4638\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8299 - loss: 0.4423 - val_accuracy: 0.7903 - val_loss: 0.4724\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7014 - loss: 0.6447 - val_accuracy: 0.8085 - val_loss: 0.4472\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8172 - loss: 0.5036 - val_accuracy: 0.8065 - val_loss: 0.4390\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8129 - loss: 0.4825 - val_accuracy: 0.7621 - val_loss: 0.5091\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8261 - loss: 0.4770 - val_accuracy: 0.8135 - val_loss: 0.4318\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8343 - loss: 0.4473 - val_accuracy: 0.8054 - val_loss: 0.4251\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8243 - loss: 0.4638 - val_accuracy: 0.8085 - val_loss: 0.4347\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8380 - loss: 0.4435 - val_accuracy: 0.8105 - val_loss: 0.4244\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8515 - loss: 0.4214 - val_accuracy: 0.8034 - val_loss: 0.4429\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8605 - loss: 0.3964 - val_accuracy: 0.8175 - val_loss: 0.4260\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8436 - loss: 0.4237 - val_accuracy: 0.8095 - val_loss: 0.4295\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7383 - loss: 0.6004 - val_accuracy: 0.8014 - val_loss: 0.4448\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7982 - loss: 0.5114 - val_accuracy: 0.8034 - val_loss: 0.4352\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8146 - loss: 0.4878 - val_accuracy: 0.7974 - val_loss: 0.4535\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8222 - loss: 0.4593 - val_accuracy: 0.8105 - val_loss: 0.4224\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.8237 - loss: 0.4602 - val_accuracy: 0.7913 - val_loss: 0.4631\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8195 - loss: 0.4642 - val_accuracy: 0.8075 - val_loss: 0.4308\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8368 - loss: 0.4249 - val_accuracy: 0.8105 - val_loss: 0.4404\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6671 - loss: 0.6633 - val_accuracy: 0.7913 - val_loss: 0.4556\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7825 - loss: 0.5348 - val_accuracy: 0.7893 - val_loss: 0.4610\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8061 - loss: 0.5082 - val_accuracy: 0.7964 - val_loss: 0.4588\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8141 - loss: 0.4768 - val_accuracy: 0.8065 - val_loss: 0.4342\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8244 - loss: 0.4703 - val_accuracy: 0.7954 - val_loss: 0.4571\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8237 - loss: 0.4597 - val_accuracy: 0.7923 - val_loss: 0.4577\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.8383 - loss: 0.4407 - val_accuracy: 0.7984 - val_loss: 0.4240\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.4577 - val_accuracy: 0.8044 - val_loss: 0.4258\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8406 - loss: 0.4235 - val_accuracy: 0.8044 - val_loss: 0.4235\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8520 - loss: 0.4054 - val_accuracy: 0.8105 - val_loss: 0.4305\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8469 - loss: 0.4056 - val_accuracy: 0.8034 - val_loss: 0.4374\n",
            "Epoch 12/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8488 - loss: 0.4035 - val_accuracy: 0.8105 - val_loss: 0.4482\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7146 - loss: 0.6228 - val_accuracy: 0.8095 - val_loss: 0.4352\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8110 - loss: 0.5035 - val_accuracy: 0.7903 - val_loss: 0.4621\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8068 - loss: 0.4943 - val_accuracy: 0.8014 - val_loss: 0.4504\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8224 - loss: 0.4827 - val_accuracy: 0.8075 - val_loss: 0.4296\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8184 - loss: 0.4713 - val_accuracy: 0.8135 - val_loss: 0.4416\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.8261 - loss: 0.4573 - val_accuracy: 0.8125 - val_loss: 0.4208\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8349 - loss: 0.4560 - val_accuracy: 0.8216 - val_loss: 0.4280\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8214 - loss: 0.4666 - val_accuracy: 0.8125 - val_loss: 0.4485\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8442 - loss: 0.4061 - val_accuracy: 0.8175 - val_loss: 0.4295\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Training LSTM...\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 747ms/step - accuracy: 0.4998 - loss: 0.8393 - val_accuracy: 0.4829 - val_loss: 0.7136\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 714ms/step - accuracy: 0.5683 - loss: 0.7945 - val_accuracy: 0.6069 - val_loss: 0.6655\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 712ms/step - accuracy: 0.5939 - loss: 0.7898 - val_accuracy: 0.6290 - val_loss: 0.6648\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 709ms/step - accuracy: 0.6352 - loss: 0.7655 - val_accuracy: 0.5131 - val_loss: 0.6876\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 718ms/step - accuracy: 0.6026 - loss: 0.7722 - val_accuracy: 0.6200 - val_loss: 0.6762\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 721ms/step - accuracy: 0.6344 - loss: 0.7634 - val_accuracy: 0.6079 - val_loss: 0.6659\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 157ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 1s/step - accuracy: 0.5004 - loss: 0.8457 - val_accuracy: 0.4738 - val_loss: 0.7175\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 1s/step - accuracy: 0.5734 - loss: 0.8030 - val_accuracy: 0.6069 - val_loss: 0.6630\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 1s/step - accuracy: 0.6177 - loss: 0.7775 - val_accuracy: 0.6220 - val_loss: 0.6586\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 1s/step - accuracy: 0.6298 - loss: 0.7669 - val_accuracy: 0.6331 - val_loss: 0.6416\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 1s/step - accuracy: 0.6267 - loss: 0.7559 - val_accuracy: 0.6562 - val_loss: 0.6155\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 1s/step - accuracy: 0.6627 - loss: 0.7364 - val_accuracy: 0.6492 - val_loss: 0.6322\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 1s/step - accuracy: 0.6652 - loss: 0.7212 - val_accuracy: 0.5776 - val_loss: 0.6554\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 1s/step - accuracy: 0.6960 - loss: 0.6987 - val_accuracy: 0.7268 - val_loss: 0.5689\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 1s/step - accuracy: 0.6963 - loss: 0.6816 - val_accuracy: 0.7137 - val_loss: 0.5638\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 1s/step - accuracy: 0.7370 - loss: 0.6434 - val_accuracy: 0.6935 - val_loss: 0.5852\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 555ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 741ms/step - accuracy: 0.5178 - loss: 0.8325 - val_accuracy: 0.6119 - val_loss: 0.6648\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 714ms/step - accuracy: 0.5921 - loss: 0.7993 - val_accuracy: 0.5716 - val_loss: 0.6734\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 718ms/step - accuracy: 0.6002 - loss: 0.7811 - val_accuracy: 0.6119 - val_loss: 0.6654\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 736ms/step - accuracy: 0.6182 - loss: 0.7661 - val_accuracy: 0.5242 - val_loss: 0.7055\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 162ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 1s/step - accuracy: 0.5076 - loss: 0.8537 - val_accuracy: 0.4698 - val_loss: 0.7305\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 1s/step - accuracy: 0.5137 - loss: 0.8406 - val_accuracy: 0.4698 - val_loss: 0.7132\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 1s/step - accuracy: 0.4953 - loss: 0.8419 - val_accuracy: 0.4698 - val_loss: 0.7114\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 1s/step - accuracy: 0.4924 - loss: 0.8427 - val_accuracy: 0.4698 - val_loss: 0.7276\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 1s/step - accuracy: 0.4941 - loss: 0.8416 - val_accuracy: 0.4698 - val_loss: 0.7458\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 1s/step - accuracy: 0.4924 - loss: 0.8419 - val_accuracy: 0.4698 - val_loss: 0.7457\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 524ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 860ms/step - accuracy: 0.4958 - loss: 0.8512 - val_accuracy: 0.4698 - val_loss: 0.7248\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 825ms/step - accuracy: 0.5202 - loss: 0.8213 - val_accuracy: 0.5565 - val_loss: 0.7136\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 823ms/step - accuracy: 0.5716 - loss: 0.7977 - val_accuracy: 0.5615 - val_loss: 0.7004\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 803ms/step - accuracy: 0.6011 - loss: 0.7837 - val_accuracy: 0.5605 - val_loss: 0.6840\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 799ms/step - accuracy: 0.5966 - loss: 0.7795 - val_accuracy: 0.6139 - val_loss: 0.6571\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 861ms/step - accuracy: 0.6470 - loss: 0.7571 - val_accuracy: 0.6210 - val_loss: 0.6517\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 837ms/step - accuracy: 0.6244 - loss: 0.7658 - val_accuracy: 0.6401 - val_loss: 0.6416\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 849ms/step - accuracy: 0.6639 - loss: 0.7386 - val_accuracy: 0.5585 - val_loss: 0.7074\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 872ms/step - accuracy: 0.6808 - loss: 0.7053 - val_accuracy: 0.6502 - val_loss: 0.6141\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 797ms/step - accuracy: 0.7085 - loss: 0.6823 - val_accuracy: 0.6885 - val_loss: 0.5665\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 180ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 2s/step - accuracy: 0.5095 - loss: 0.8456 - val_accuracy: 0.4940 - val_loss: 0.7082\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 2s/step - accuracy: 0.5372 - loss: 0.8119 - val_accuracy: 0.5343 - val_loss: 0.7169\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 2s/step - accuracy: 0.5991 - loss: 0.7863 - val_accuracy: 0.5625 - val_loss: 0.6858\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 2s/step - accuracy: 0.6228 - loss: 0.7644 - val_accuracy: 0.4688 - val_loss: 0.7256\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 2s/step - accuracy: 0.5816 - loss: 0.7815 - val_accuracy: 0.5333 - val_loss: 0.6982\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 2s/step - accuracy: 0.6287 - loss: 0.7639 - val_accuracy: 0.6190 - val_loss: 0.6633\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 2s/step - accuracy: 0.6256 - loss: 0.7540 - val_accuracy: 0.5897 - val_loss: 0.6738\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 2s/step - accuracy: 0.6614 - loss: 0.7316 - val_accuracy: 0.6784 - val_loss: 0.5946\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 2s/step - accuracy: 0.6748 - loss: 0.7065 - val_accuracy: 0.7369 - val_loss: 0.5597\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 2s/step - accuracy: 0.6929 - loss: 0.6899 - val_accuracy: 0.6401 - val_loss: 0.6378\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 545ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 854ms/step - accuracy: 0.5070 - loss: 0.8522 - val_accuracy: 0.4698 - val_loss: 0.7250\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 798ms/step - accuracy: 0.5012 - loss: 0.8448 - val_accuracy: 0.4698 - val_loss: 0.7612\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 872ms/step - accuracy: 0.4944 - loss: 0.8460 - val_accuracy: 0.4698 - val_loss: 0.7471\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 829ms/step - accuracy: 0.4898 - loss: 0.8475 - val_accuracy: 0.4698 - val_loss: 0.7329\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 164ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 2s/step - accuracy: 0.5215 - loss: 0.8454 - val_accuracy: 0.4738 - val_loss: 0.7117\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 2s/step - accuracy: 0.5643 - loss: 0.7964 - val_accuracy: 0.5282 - val_loss: 0.6997\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 2s/step - accuracy: 0.6009 - loss: 0.7837 - val_accuracy: 0.6139 - val_loss: 0.6528\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 2s/step - accuracy: 0.6069 - loss: 0.7834 - val_accuracy: 0.5917 - val_loss: 0.6739\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 2s/step - accuracy: 0.6201 - loss: 0.7769 - val_accuracy: 0.6190 - val_loss: 0.6451\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 2s/step - accuracy: 0.6239 - loss: 0.7684 - val_accuracy: 0.6341 - val_loss: 0.6481\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 2s/step - accuracy: 0.6224 - loss: 0.7736 - val_accuracy: 0.5927 - val_loss: 0.6783\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 2s/step - accuracy: 0.6159 - loss: 0.7900 - val_accuracy: 0.4698 - val_loss: 0.7258\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 542ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 726ms/step - accuracy: 0.5058 - loss: 0.8738 - val_accuracy: 0.4677 - val_loss: 0.7332\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 728ms/step - accuracy: 0.4924 - loss: 0.8461 - val_accuracy: 0.4698 - val_loss: 0.7138\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 729ms/step - accuracy: 0.5060 - loss: 0.8428 - val_accuracy: 0.4698 - val_loss: 0.7145\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 715ms/step - accuracy: 0.5034 - loss: 0.8414 - val_accuracy: 0.4698 - val_loss: 0.7229\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 752ms/step - accuracy: 0.4930 - loss: 0.8438 - val_accuracy: 0.4698 - val_loss: 0.7380\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 208ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 1s/step - accuracy: 0.5127 - loss: 0.8440 - val_accuracy: 0.5363 - val_loss: 0.7372\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 1s/step - accuracy: 0.5718 - loss: 0.8210 - val_accuracy: 0.5877 - val_loss: 0.6687\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 1s/step - accuracy: 0.6042 - loss: 0.7776 - val_accuracy: 0.6200 - val_loss: 0.6510\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 1s/step - accuracy: 0.6309 - loss: 0.7680 - val_accuracy: 0.6008 - val_loss: 0.6723\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 1s/step - accuracy: 0.6179 - loss: 0.7746 - val_accuracy: 0.5847 - val_loss: 0.6734\n",
            "Epoch 6/20\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Conv1D, GlobalMaxPooling1D, Dropout, Input, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import joblib\n",
        "import json\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Set paths\n",
        "data_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/data.xlsx\"\n",
        "save_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/deep_learning_results6\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_excel(data_path)\n",
        "df.dropna(inplace=True)\n",
        "print(\"Size of DataFrame after dropping null values:\", df.shape)\n",
        "\n",
        "# Function to parse vector strings into numpy arrays\n",
        "def parse_vector(vector_str, expected_dim):\n",
        "    try:\n",
        "        if isinstance(vector_str, str):\n",
        "            vec = np.array([float(i) for i in vector_str.strip(\"[]\").split()], dtype=np.float32)\n",
        "            if vec.shape[0] == expected_dim:\n",
        "                return vec\n",
        "            elif vec.shape[0] > expected_dim:\n",
        "                return vec[:expected_dim]  # Truncate to expected size\n",
        "            else:\n",
        "                return np.pad(vec, (0, expected_dim - vec.shape[0]))  # Pad with zeros\n",
        "    except:\n",
        "        return np.zeros(expected_dim, dtype=np.float32)  # Default to zero vector\n",
        "    return np.zeros(expected_dim, dtype=np.float32)\n",
        "\n",
        "# Define expected dimensions\n",
        "word2vec_dim = 300\n",
        "fasttext_dim = 300\n",
        "sentence_embedding_dim = 300\n",
        "sinbert_dim = 768  # Larger than others\n",
        "\n",
        "# Apply parsing with dimension corrections\n",
        "df['word2vec_vector'] = df['word2vec_vector'].map(lambda x: parse_vector(x, word2vec_dim))\n",
        "df['fasttext_vector'] = df['fasttext_vector'].map(lambda x: parse_vector(x, fasttext_dim))\n",
        "df['sentence_embedding'] = df['sentence_embedding'].map(lambda x: parse_vector(x, sentence_embedding_dim))\n",
        "df['sinbert_vector'] = df['sinbert_vector'].map(lambda x: parse_vector(x, sinbert_dim))  # Keep 768D\n",
        "\n",
        "# Ensure all feature vectors have the same final dimension\n",
        "final_dim = 768  # Choose larger or normalize to 300\n",
        "for feature in ['word2vec_vector', 'fasttext_vector', 'sentence_embedding']:\n",
        "    df[feature] = df[feature].map(lambda x: np.pad(x, (0, final_dim - x.shape[0])) if x.shape[0] < final_dim else x[:final_dim])\n",
        "\n",
        "# Stack feature vectors correctly\n",
        "X = np.stack(df[['word2vec_vector', 'fasttext_vector', 'sentence_embedding', 'sinbert_vector']].apply(lambda row: np.column_stack(row.values), axis=1).values)\n",
        "\n",
        "# Flatten X for MLP: (samples, final_dim * 4)\n",
        "X_flattened = X.reshape(X.shape[0], -1)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'].values)\n",
        "joblib.dump(label_encoder, os.path.join(save_path, 'label_encoder.pkl'))\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train_flattened, X_test_flattened = train_test_split(X_flattened, test_size=0.2, random_state=42)\n",
        "\n",
        "# Function to implement early stopping and class weights\n",
        "def build_mlp(input_shape, dropout_rate, dense_units):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Dense(dense_units, activation='relu'),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(dense_units // 2, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_lstm(input_shape, dropout_rate, lstm_units):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        LSTM(lstm_units, return_sequences=True),\n",
        "        Dropout(dropout_rate),\n",
        "        LSTM(lstm_units // 2),\n",
        "        Flatten(),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_cnn(input_shape, dropout_rate, filters):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Conv1D(filters, kernel_size=3, activation='relu'),\n",
        "        Dropout(dropout_rate),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(filters // 2, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Early stopping callback to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Apply class weights (use if there is class imbalance)\n",
        "class_weights = {0: 1, 1: 1.5}  # Increase weight for the minority class\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"confusion_matrix\": conf_matrix.tolist()\n",
        "    }\n",
        "\n",
        "# Train and evaluate models with hyperparameter tuning and regularization\n",
        "results = {}\n",
        "\n",
        "# Model hyperparameters for tuning\n",
        "params = {\n",
        "    'MLP': {\n",
        "        'epochs': [10, 20],\n",
        "        'batch_size': [16, 32],\n",
        "        'dropout': [0.2, 0.3],\n",
        "        'dense_units': [64, 128]\n",
        "    },\n",
        "    'LSTM': {\n",
        "        'epochs': [10, 20],\n",
        "        'batch_size': [16, 32],\n",
        "        'dropout': [0.2, 0.3],\n",
        "        'lstm_units': [64, 128],\n",
        "    },\n",
        "    'CNN': {\n",
        "        'epochs': [10, 20],\n",
        "        'batch_size': [16, 32],\n",
        "        'dropout': [0.2, 0.3],\n",
        "        'filters': [64, 128],\n",
        "    }\n",
        "}\n",
        "\n",
        "# Train and evaluate each model\n",
        "for name in ['MLP', 'LSTM', 'CNN']:\n",
        "    print(f\"Training {name}...\")\n",
        "\n",
        "    # Hyperparameter grid search (manually tuned here)\n",
        "    for epochs in params[name]['epochs']:\n",
        "        for batch_size in params[name]['batch_size']:\n",
        "            if name == 'MLP':\n",
        "                for dropout in params[name]['dropout']:\n",
        "                    for dense_units in params[name]['dense_units']:\n",
        "                        model_instance = build_mlp((X_train_flattened.shape[1],), dropout, dense_units)\n",
        "                        model_instance.fit(X_train_flattened, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                                           validation_data=(X_test_flattened, y_test), class_weight=class_weights,\n",
        "                                           callbacks=[early_stopping], verbose=1)\n",
        "                        y_pred = (model_instance.predict(X_test_flattened) > 0.5).astype(int)\n",
        "                        results[name] = evaluate_model(y_test, y_pred)\n",
        "            elif name == 'LSTM':\n",
        "                for dropout in params[name]['dropout']:\n",
        "                    for lstm_units in params[name]['lstm_units']:\n",
        "                        model_instance = build_lstm((X_train.shape[1], X_train.shape[2]), dropout, lstm_units)\n",
        "                        model_instance.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                                           validation_data=(X_test, y_test), class_weight=class_weights,\n",
        "                                           callbacks=[early_stopping], verbose=1)\n",
        "                        y_pred = (model_instance.predict(X_test) > 0.5).astype(int)\n",
        "                        results[name] = evaluate_model(y_test, y_pred)\n",
        "            elif name == 'CNN':\n",
        "                for dropout in params[name]['dropout']:\n",
        "                    for filters in params[name]['filters']:\n",
        "                        model_instance = build_cnn((X_train.shape[1], X_train.shape[2]), dropout, filters)\n",
        "                        model_instance.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                                           validation_data=(X_test, y_test), class_weight=class_weights,\n",
        "                                           callbacks=[early_stopping], verbose=1)\n",
        "                        y_pred = (model_instance.predict(X_test) > 0.5).astype(int)\n",
        "                        results[name] = evaluate_model(y_test, y_pred)\n",
        "\n",
        "# Save results to JSON\n",
        "results_path = os.path.join(save_path, \"model_results.json\")\n",
        "with open(results_path, \"w\") as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n",
        "print(\"Experiment completed. Results saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "JLGX2zvYfpL0",
        "outputId": "6c52f816-232c-45a4-c216-3fc7c414509a"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/data.xlsx'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ad14300ab88e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Size of DataFrame after dropping null values:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/data.xlsx'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Conv1D, GlobalMaxPooling1D, Dropout, Input, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import joblib\n",
        "import json\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Set paths\n",
        "data_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/data.xlsx\"\n",
        "save_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/deep_learning_results7\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_excel(data_path)\n",
        "df.dropna(inplace=True)\n",
        "print(\"Size of DataFrame after dropping null values:\", df.shape)\n",
        "\n",
        "# Function to parse vector strings into numpy arrays\n",
        "def parse_vector(vector_str, expected_dim):\n",
        "    try:\n",
        "        if isinstance(vector_str, str):\n",
        "            vec = np.array([float(i) for i in vector_str.strip(\"[]\").split()], dtype=np.float32)\n",
        "            if vec.shape[0] == expected_dim:\n",
        "                return vec\n",
        "            elif vec.shape[0] > expected_dim:\n",
        "                return vec[:expected_dim]  # Truncate to expected size\n",
        "            else:\n",
        "                return np.pad(vec, (0, expected_dim - vec.shape[0]))  # Pad with zeros\n",
        "    except:\n",
        "        return np.zeros(expected_dim, dtype=np.float32)  # Default to zero vector\n",
        "    return np.zeros(expected_dim, dtype=np.float32)\n",
        "\n",
        "# Define expected dimensions\n",
        "word2vec_dim = 300\n",
        "fasttext_dim = 300\n",
        "sentence_embedding_dim = 300\n",
        "sinbert_dim = 768  # Larger than others\n",
        "\n",
        "# Apply parsing with dimension corrections\n",
        "df['word2vec_vector'] = df['word2vec_vector'].map(lambda x: parse_vector(x, word2vec_dim))\n",
        "df['fasttext_vector'] = df['fasttext_vector'].map(lambda x: parse_vector(x, fasttext_dim))\n",
        "df['sentence_embedding'] = df['sentence_embedding'].map(lambda x: parse_vector(x, sentence_embedding_dim))\n",
        "df['sinbert_vector'] = df['sinbert_vector'].map(lambda x: parse_vector(x, sinbert_dim))  # Keep 768D\n",
        "\n",
        "# Ensure all feature vectors have the same final dimension\n",
        "final_dim = 768  # Choose larger or normalize to 300\n",
        "for feature in ['word2vec_vector', 'fasttext_vector', 'sentence_embedding']:\n",
        "    df[feature] = df[feature].map(lambda x: np.pad(x, (0, final_dim - x.shape[0])) if x.shape[0] < final_dim else x[:final_dim])\n",
        "\n",
        "# Stack feature vectors correctly\n",
        "X = np.stack(df[['word2vec_vector', 'fasttext_vector', 'sentence_embedding', 'sinbert_vector']].apply(lambda row: np.column_stack(row.values), axis=1).values)\n",
        "\n",
        "# Flatten X for MLP: (samples, final_dim * 4)\n",
        "X_flattened = X.reshape(X.shape[0], -1)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'].values)\n",
        "joblib.dump(label_encoder, os.path.join(save_path, 'label_encoder.pkl'))\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train_flattened, X_test_flattened = train_test_split(X_flattened, test_size=0.2, random_state=42)\n",
        "\n",
        "# Function to implement early stopping and class weights\n",
        "def build_mlp(input_shape, dropout_rate, dense_units):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Dense(dense_units, activation='relu'),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(dense_units // 2, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_lstm(input_shape, dropout_rate, lstm_units):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        LSTM(lstm_units, return_sequences=True),\n",
        "        Dropout(dropout_rate),\n",
        "        LSTM(lstm_units // 2),\n",
        "        Flatten(),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_cnn(input_shape, dropout_rate, filters):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Conv1D(filters, kernel_size=3, activation='relu'),\n",
        "        Dropout(dropout_rate),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(filters // 2, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Early stopping callback to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Apply class weights (use if there is class imbalance)\n",
        "class_weights = {0: 1, 1: 1.5}  # Increase weight for the minority class\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"confusion_matrix\": conf_matrix.tolist()\n",
        "    }\n",
        "\n",
        "# Train and evaluate models with hyperparameter tuning and regularization\n",
        "results = {}\n",
        "\n",
        "# Model hyperparameters for tuning\n",
        "params = {\n",
        "    'MLP': {\n",
        "        'epochs': [10, 20, 30],\n",
        "        'batch_size': [16, 32],\n",
        "        'dropout': [0.2, 0.3],\n",
        "        'dense_units': [64, 128, 256]\n",
        "    },\n",
        "    'LSTM': {\n",
        "        'epochs': [10, 20, 30],\n",
        "        'batch_size': [16, 32],\n",
        "        'dropout': [0.2, 0.3],\n",
        "        'lstm_units': [64, 128, 256],\n",
        "    },\n",
        "    'CNN': {\n",
        "        'epochs': [10, 20, 30],\n",
        "        'batch_size': [16, 32],\n",
        "        'dropout': [0.2, 0.3],\n",
        "        'filters': [64, 128, 256],\n",
        "    }\n",
        "}\n",
        "\n",
        "# Train and evaluate each model\n",
        "for name in ['MLP', 'LSTM', 'CNN']:\n",
        "    print(f\"Training {name}...\")\n",
        "\n",
        "    # Hyperparameter grid search (manually tuned here)\n",
        "    for epochs in params[name]['epochs']:\n",
        "        for batch_size in params[name]['batch_size']:\n",
        "            if name == 'MLP':\n",
        "                for dropout in params[name]['dropout']:\n",
        "                    for dense_units in params[name]['dense_units']:\n",
        "                        model_instance = build_mlp((X_train_flattened.shape[1],), dropout, dense_units)\n",
        "                        model_instance.fit(X_train_flattened, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                                           validation_data=(X_test_flattened, y_test), class_weight=class_weights,\n",
        "                                           callbacks=[early_stopping], verbose=1)\n",
        "                        y_pred = (model_instance.predict(X_test_flattened) > 0.5).astype(int)\n",
        "                        results[name] = evaluate_model(y_test, y_pred)\n",
        "            elif name == 'LSTM':\n",
        "                for dropout in params[name]['dropout']:\n",
        "                    for lstm_units in params[name]['lstm_units']:\n",
        "                        model_instance = build_lstm((X_train.shape[1], X_train.shape[2]), dropout, lstm_units)\n",
        "                        model_instance.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                                           validation_data=(X_test, y_test), class_weight=class_weights,\n",
        "                                           callbacks=[early_stopping], verbose=1)\n",
        "                        y_pred = (model_instance.predict(X_test) > 0.5).astype(int)\n",
        "                        results[name] = evaluate_model(y_test, y_pred)\n",
        "            elif name == 'CNN':\n",
        "                for dropout in params[name]['dropout']:\n",
        "                    for filters in params[name]['filters']:\n",
        "                        model_instance = build_cnn((X_train.shape[1], X_train.shape[2]), dropout, filters)\n",
        "                        model_instance.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                                           validation_data=(X_test, y_test), class_weight=class_weights,\n",
        "                                           callbacks=[early_stopping], verbose=1)\n",
        "                        y_pred = (model_instance.predict(X_test) > 0.5).astype(int)\n",
        "                        results[name] = evaluate_model(y_test, y_pred)\n",
        "\n",
        "# Save results to JSON\n",
        "results_path = os.path.join(save_path, \"model_results.json\")\n",
        "with open(results_path, \"w\") as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n",
        "print(\"Experiment completed. Results saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ht16_TbMJlms",
        "outputId": "36a40cfa-8d81-411f-ec76-dda3fca47788"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of DataFrame after dropping null values: (4958, 8)\n",
            "Training MLP...\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.7356 - loss: 0.6292 - val_accuracy: 0.8095 - val_loss: 0.4460\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7926 - loss: 0.5303 - val_accuracy: 0.8125 - val_loss: 0.4331\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8231 - loss: 0.4782 - val_accuracy: 0.7954 - val_loss: 0.4599\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8159 - loss: 0.4685 - val_accuracy: 0.8034 - val_loss: 0.4321\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8114 - loss: 0.4688 - val_accuracy: 0.8044 - val_loss: 0.4314\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8309 - loss: 0.4485 - val_accuracy: 0.7067 - val_loss: 0.5760\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8269 - loss: 0.4498 - val_accuracy: 0.7913 - val_loss: 0.4936\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8390 - loss: 0.4367 - val_accuracy: 0.8075 - val_loss: 0.4595\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.7064 - loss: 0.6445 - val_accuracy: 0.7893 - val_loss: 0.4519\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8090 - loss: 0.4933 - val_accuracy: 0.7984 - val_loss: 0.4448\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8165 - loss: 0.4828 - val_accuracy: 0.8054 - val_loss: 0.4455\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8113 - loss: 0.4833 - val_accuracy: 0.7530 - val_loss: 0.5388\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8202 - loss: 0.4615 - val_accuracy: 0.8125 - val_loss: 0.4316\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8355 - loss: 0.4320 - val_accuracy: 0.8065 - val_loss: 0.4369\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8295 - loss: 0.4440 - val_accuracy: 0.7853 - val_loss: 0.4739\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.4167 - val_accuracy: 0.8115 - val_loss: 0.4216\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8524 - loss: 0.4111 - val_accuracy: 0.7984 - val_loss: 0.4605\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8504 - loss: 0.3996 - val_accuracy: 0.7944 - val_loss: 0.4652\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.6966 - loss: 0.6616 - val_accuracy: 0.8034 - val_loss: 0.4538\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8094 - loss: 0.5158 - val_accuracy: 0.7581 - val_loss: 0.4970\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8116 - loss: 0.4982 - val_accuracy: 0.8024 - val_loss: 0.4502\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8064 - loss: 0.4991 - val_accuracy: 0.7661 - val_loss: 0.5005\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8162 - loss: 0.4703 - val_accuracy: 0.8044 - val_loss: 0.4392\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8228 - loss: 0.4642 - val_accuracy: 0.8115 - val_loss: 0.4264\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8306 - loss: 0.4478 - val_accuracy: 0.7641 - val_loss: 0.4880\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8253 - loss: 0.4404 - val_accuracy: 0.8075 - val_loss: 0.4318\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8468 - loss: 0.4209 - val_accuracy: 0.8024 - val_loss: 0.4395\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.7194 - loss: 0.6275 - val_accuracy: 0.7863 - val_loss: 0.4643\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8005 - loss: 0.5106 - val_accuracy: 0.7419 - val_loss: 0.5342\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8118 - loss: 0.5026 - val_accuracy: 0.7782 - val_loss: 0.4842\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8271 - loss: 0.4703 - val_accuracy: 0.8065 - val_loss: 0.4457\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8110 - loss: 0.4809 - val_accuracy: 0.7409 - val_loss: 0.5512\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8274 - loss: 0.4535 - val_accuracy: 0.7812 - val_loss: 0.4913\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8324 - loss: 0.4545 - val_accuracy: 0.8125 - val_loss: 0.4385\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8376 - loss: 0.4382 - val_accuracy: 0.8185 - val_loss: 0.4301\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8270 - loss: 0.4365 - val_accuracy: 0.7802 - val_loss: 0.4984\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8439 - loss: 0.4129 - val_accuracy: 0.7802 - val_loss: 0.4913\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.7212 - loss: 0.6277 - val_accuracy: 0.8004 - val_loss: 0.4445\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8120 - loss: 0.4944 - val_accuracy: 0.7802 - val_loss: 0.4514\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8137 - loss: 0.4875 - val_accuracy: 0.7581 - val_loss: 0.4987\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8209 - loss: 0.4606 - val_accuracy: 0.8165 - val_loss: 0.4224\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8270 - loss: 0.4648 - val_accuracy: 0.7712 - val_loss: 0.4911\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8251 - loss: 0.4579 - val_accuracy: 0.8105 - val_loss: 0.4228\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8318 - loss: 0.4364 - val_accuracy: 0.8185 - val_loss: 0.4189\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8450 - loss: 0.4154 - val_accuracy: 0.7651 - val_loss: 0.4885\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8322 - loss: 0.4332 - val_accuracy: 0.7974 - val_loss: 0.4962\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8416 - loss: 0.4175 - val_accuracy: 0.7984 - val_loss: 0.4646\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.7312 - loss: 0.6285 - val_accuracy: 0.7833 - val_loss: 0.4826\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7973 - loss: 0.5291 - val_accuracy: 0.8105 - val_loss: 0.4348\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8043 - loss: 0.4958 - val_accuracy: 0.8075 - val_loss: 0.4341\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8194 - loss: 0.4609 - val_accuracy: 0.8054 - val_loss: 0.4328\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8359 - loss: 0.4571 - val_accuracy: 0.8024 - val_loss: 0.4381\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8299 - loss: 0.4398 - val_accuracy: 0.8095 - val_loss: 0.4427\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8301 - loss: 0.4366 - val_accuracy: 0.8014 - val_loss: 0.4444\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.6913 - loss: 0.6623 - val_accuracy: 0.7954 - val_loss: 0.4515\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8128 - loss: 0.5180 - val_accuracy: 0.7964 - val_loss: 0.4617\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8087 - loss: 0.4901 - val_accuracy: 0.8004 - val_loss: 0.4321\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8147 - loss: 0.4967 - val_accuracy: 0.8125 - val_loss: 0.4333\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8291 - loss: 0.4564 - val_accuracy: 0.7913 - val_loss: 0.4759\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8297 - loss: 0.4589 - val_accuracy: 0.8044 - val_loss: 0.4292\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8364 - loss: 0.4566 - val_accuracy: 0.8105 - val_loss: 0.4310\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8333 - loss: 0.4356 - val_accuracy: 0.7984 - val_loss: 0.4645\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8418 - loss: 0.4249 - val_accuracy: 0.8125 - val_loss: 0.4328\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.6978 - loss: 0.6528 - val_accuracy: 0.7944 - val_loss: 0.4678\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7990 - loss: 0.5158 - val_accuracy: 0.8155 - val_loss: 0.4385\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8183 - loss: 0.4866 - val_accuracy: 0.8054 - val_loss: 0.4493\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8125 - loss: 0.4970 - val_accuracy: 0.8135 - val_loss: 0.4320\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8224 - loss: 0.4735 - val_accuracy: 0.8085 - val_loss: 0.4499\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8247 - loss: 0.4471 - val_accuracy: 0.8044 - val_loss: 0.4333\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8371 - loss: 0.4297 - val_accuracy: 0.7964 - val_loss: 0.4607\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7153 - loss: 0.6364 - val_accuracy: 0.8044 - val_loss: 0.4387\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8048 - loss: 0.5085 - val_accuracy: 0.7893 - val_loss: 0.4759\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8011 - loss: 0.5059 - val_accuracy: 0.7994 - val_loss: 0.4382\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8306 - loss: 0.4615 - val_accuracy: 0.7933 - val_loss: 0.4572\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8274 - loss: 0.4665 - val_accuracy: 0.8065 - val_loss: 0.4632\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8381 - loss: 0.4356 - val_accuracy: 0.8004 - val_loss: 0.4552\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7369 - loss: 0.6158 - val_accuracy: 0.8024 - val_loss: 0.4441\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7927 - loss: 0.5321 - val_accuracy: 0.8125 - val_loss: 0.4315\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8226 - loss: 0.4860 - val_accuracy: 0.8014 - val_loss: 0.4558\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8173 - loss: 0.4794 - val_accuracy: 0.8145 - val_loss: 0.4325\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8283 - loss: 0.4429 - val_accuracy: 0.8105 - val_loss: 0.4353\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7037 - loss: 0.6528 - val_accuracy: 0.8004 - val_loss: 0.4475\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7847 - loss: 0.5317 - val_accuracy: 0.7964 - val_loss: 0.4542\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8038 - loss: 0.5015 - val_accuracy: 0.8054 - val_loss: 0.4427\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8102 - loss: 0.4948 - val_accuracy: 0.7883 - val_loss: 0.4759\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8151 - loss: 0.4810 - val_accuracy: 0.8105 - val_loss: 0.4343\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8250 - loss: 0.4725 - val_accuracy: 0.7802 - val_loss: 0.4753\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8247 - loss: 0.4639 - val_accuracy: 0.8075 - val_loss: 0.4319\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8412 - loss: 0.4380 - val_accuracy: 0.8024 - val_loss: 0.4535\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.4291 - val_accuracy: 0.8155 - val_loss: 0.4301\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8309 - loss: 0.4483 - val_accuracy: 0.7994 - val_loss: 0.4590\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8479 - loss: 0.4111 - val_accuracy: 0.7913 - val_loss: 0.4676\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8485 - loss: 0.4048 - val_accuracy: 0.8125 - val_loss: 0.4462\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7124 - loss: 0.6275 - val_accuracy: 0.7530 - val_loss: 0.5147\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8004 - loss: 0.5236 - val_accuracy: 0.7621 - val_loss: 0.4967\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8046 - loss: 0.4991 - val_accuracy: 0.7994 - val_loss: 0.4377\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8024 - loss: 0.5025 - val_accuracy: 0.8034 - val_loss: 0.4390\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8161 - loss: 0.4706 - val_accuracy: 0.7903 - val_loss: 0.4682\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8226 - loss: 0.4675 - val_accuracy: 0.7994 - val_loss: 0.4508\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.7040 - loss: 0.6486 - val_accuracy: 0.8034 - val_loss: 0.4377\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8080 - loss: 0.5112 - val_accuracy: 0.8044 - val_loss: 0.4308\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8142 - loss: 0.4911 - val_accuracy: 0.8175 - val_loss: 0.4346\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8329 - loss: 0.4467 - val_accuracy: 0.8095 - val_loss: 0.4216\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8253 - loss: 0.4624 - val_accuracy: 0.7944 - val_loss: 0.4443\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8291 - loss: 0.4381 - val_accuracy: 0.8085 - val_loss: 0.4253\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8432 - loss: 0.4302 - val_accuracy: 0.8125 - val_loss: 0.4273\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7245 - loss: 0.6147 - val_accuracy: 0.7853 - val_loss: 0.4643\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7944 - loss: 0.5124 - val_accuracy: 0.7994 - val_loss: 0.4485\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8169 - loss: 0.4777 - val_accuracy: 0.8024 - val_loss: 0.4403\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8219 - loss: 0.4651 - val_accuracy: 0.8054 - val_loss: 0.4375\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8372 - loss: 0.4481 - val_accuracy: 0.8135 - val_loss: 0.4236\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8408 - loss: 0.4377 - val_accuracy: 0.8054 - val_loss: 0.4369\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8390 - loss: 0.4180 - val_accuracy: 0.7843 - val_loss: 0.4806\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8564 - loss: 0.4215 - val_accuracy: 0.8115 - val_loss: 0.4311\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.6765 - loss: 0.6641 - val_accuracy: 0.7903 - val_loss: 0.4503\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7880 - loss: 0.5360 - val_accuracy: 0.8024 - val_loss: 0.4557\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8070 - loss: 0.4983 - val_accuracy: 0.7893 - val_loss: 0.4654\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8246 - loss: 0.4680 - val_accuracy: 0.7732 - val_loss: 0.4896\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.7037 - loss: 0.6295 - val_accuracy: 0.7954 - val_loss: 0.4497\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7887 - loss: 0.5406 - val_accuracy: 0.8054 - val_loss: 0.4360\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8125 - loss: 0.4996 - val_accuracy: 0.7964 - val_loss: 0.4493\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8212 - loss: 0.4769 - val_accuracy: 0.8054 - val_loss: 0.4292\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8180 - loss: 0.4736 - val_accuracy: 0.8196 - val_loss: 0.4262\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8241 - loss: 0.4550 - val_accuracy: 0.8115 - val_loss: 0.4199\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8315 - loss: 0.4522 - val_accuracy: 0.8125 - val_loss: 0.4350\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8298 - loss: 0.4450 - val_accuracy: 0.8095 - val_loss: 0.4458\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8457 - loss: 0.4191 - val_accuracy: 0.8115 - val_loss: 0.4325\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Training LSTM...\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - accuracy: 0.5318 - loss: 0.8340 - val_accuracy: 0.4698 - val_loss: 0.7245\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 52ms/step - accuracy: 0.5106 - loss: 0.8400 - val_accuracy: 0.4698 - val_loss: 0.7222\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.4944 - loss: 0.8438 - val_accuracy: 0.4698 - val_loss: 0.7241\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 47ms/step - accuracy: 0.5033 - loss: 0.8411 - val_accuracy: 0.4698 - val_loss: 0.7288\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.4965 - loss: 0.8438 - val_accuracy: 0.4698 - val_loss: 0.7136\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - accuracy: 0.5015 - loss: 0.8418 - val_accuracy: 0.4698 - val_loss: 0.7296\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.4993 - loss: 0.8389 - val_accuracy: 0.4698 - val_loss: 0.7037\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 44ms/step - accuracy: 0.5059 - loss: 0.8292 - val_accuracy: 0.5323 - val_loss: 0.6833\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.5465 - loss: 0.8102 - val_accuracy: 0.5484 - val_loss: 0.6839\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 42ms/step - accuracy: 0.5636 - loss: 0.7988 - val_accuracy: 0.4677 - val_loss: 0.7200\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 60ms/step - accuracy: 0.5134 - loss: 0.8445 - val_accuracy: 0.5242 - val_loss: 0.7037\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 53ms/step - accuracy: 0.5430 - loss: 0.8292 - val_accuracy: 0.4698 - val_loss: 0.7131\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.5002 - loss: 0.8292 - val_accuracy: 0.4698 - val_loss: 0.7093\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 52ms/step - accuracy: 0.5023 - loss: 0.8330 - val_accuracy: 0.4698 - val_loss: 0.7157\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 50ms/step - accuracy: 0.5224 - loss: 0.8382 - val_accuracy: 0.6200 - val_loss: 0.6581\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 50ms/step - accuracy: 0.5895 - loss: 0.7951 - val_accuracy: 0.5383 - val_loss: 0.6863\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 50ms/step - accuracy: 0.5971 - loss: 0.7974 - val_accuracy: 0.5958 - val_loss: 0.6643\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 55ms/step - accuracy: 0.6129 - loss: 0.7773 - val_accuracy: 0.6391 - val_loss: 0.6536\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 49ms/step - accuracy: 0.6148 - loss: 0.7699 - val_accuracy: 0.6220 - val_loss: 0.6563\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.6380 - loss: 0.7641 - val_accuracy: 0.4698 - val_loss: 1.0460\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 44ms/step - accuracy: 0.4963 - loss: 0.8566 - val_accuracy: 0.4698 - val_loss: 0.7393\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 54ms/step - accuracy: 0.5033 - loss: 0.8413 - val_accuracy: 0.6069 - val_loss: 0.6692\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 54ms/step - accuracy: 0.6032 - loss: 0.7953 - val_accuracy: 0.6048 - val_loss: 0.6649\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 53ms/step - accuracy: 0.6097 - loss: 0.7797 - val_accuracy: 0.5978 - val_loss: 0.6762\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 53ms/step - accuracy: 0.6307 - loss: 0.7695 - val_accuracy: 0.6300 - val_loss: 0.6483\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 59ms/step - accuracy: 0.6210 - loss: 0.7701 - val_accuracy: 0.6552 - val_loss: 0.6459\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 53ms/step - accuracy: 0.6491 - loss: 0.7490 - val_accuracy: 0.6925 - val_loss: 0.5949\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 54ms/step - accuracy: 0.6867 - loss: 0.7054 - val_accuracy: 0.6764 - val_loss: 0.5934\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 52ms/step - accuracy: 0.7147 - loss: 0.6662 - val_accuracy: 0.7188 - val_loss: 0.5578\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 53ms/step - accuracy: 0.7017 - loss: 0.6811 - val_accuracy: 0.6905 - val_loss: 0.5817\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 52ms/step - accuracy: 0.7079 - loss: 0.6664 - val_accuracy: 0.7268 - val_loss: 0.5473\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.5047 - loss: 0.8421 - val_accuracy: 0.4718 - val_loss: 0.7269\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.5589 - loss: 0.8016 - val_accuracy: 0.5333 - val_loss: 0.7125\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.6065 - loss: 0.7793 - val_accuracy: 0.5060 - val_loss: 0.7132\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.6079 - loss: 0.7763 - val_accuracy: 0.6129 - val_loss: 0.6492\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.6065 - loss: 0.7710 - val_accuracy: 0.6038 - val_loss: 0.6773\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.6193 - loss: 0.7698 - val_accuracy: 0.6139 - val_loss: 0.6618\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.6210 - loss: 0.7687 - val_accuracy: 0.6331 - val_loss: 0.6529\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.4937 - loss: 0.8329 - val_accuracy: 0.5625 - val_loss: 0.6742\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - accuracy: 0.5780 - loss: 0.7960 - val_accuracy: 0.5988 - val_loss: 0.6692\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.6200 - loss: 0.7717 - val_accuracy: 0.5927 - val_loss: 0.6707\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 59ms/step - accuracy: 0.6089 - loss: 0.7780 - val_accuracy: 0.5847 - val_loss: 0.6876\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.6251 - loss: 0.7717 - val_accuracy: 0.5181 - val_loss: 0.7369\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.5082 - loss: 0.8516 - val_accuracy: 0.5504 - val_loss: 0.6892\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 46ms/step - accuracy: 0.5725 - loss: 0.8028 - val_accuracy: 0.5675 - val_loss: 0.6835\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.6070 - loss: 0.7922 - val_accuracy: 0.6119 - val_loss: 0.6647\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 46ms/step - accuracy: 0.6333 - loss: 0.7719 - val_accuracy: 0.5504 - val_loss: 0.6985\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - accuracy: 0.6260 - loss: 0.7608 - val_accuracy: 0.5877 - val_loss: 0.6764\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.6216 - loss: 0.7690 - val_accuracy: 0.6210 - val_loss: 0.6694\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - accuracy: 0.5394 - loss: 0.8351 - val_accuracy: 0.5998 - val_loss: 0.6664\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 56ms/step - accuracy: 0.5767 - loss: 0.7996 - val_accuracy: 0.6058 - val_loss: 0.6632\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.5894 - loss: 0.7925 - val_accuracy: 0.5968 - val_loss: 0.6704\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.6088 - loss: 0.7735 - val_accuracy: 0.5746 - val_loss: 0.6938\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 56ms/step - accuracy: 0.6185 - loss: 0.7605 - val_accuracy: 0.5917 - val_loss: 0.6744\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 0.5040 - loss: 0.8430 - val_accuracy: 0.4950 - val_loss: 0.7013\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 50ms/step - accuracy: 0.5604 - loss: 0.8084 - val_accuracy: 0.5675 - val_loss: 0.6808\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 47ms/step - accuracy: 0.5998 - loss: 0.7834 - val_accuracy: 0.6230 - val_loss: 0.6702\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.6143 - loss: 0.7701 - val_accuracy: 0.6220 - val_loss: 0.6647\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 47ms/step - accuracy: 0.5627 - loss: 0.8355 - val_accuracy: 0.4698 - val_loss: 0.7096\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 50ms/step - accuracy: 0.5126 - loss: 0.8302 - val_accuracy: 0.4698 - val_loss: 0.7146\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 60ms/step - accuracy: 0.4854 - loss: 0.8371 - val_accuracy: 0.4698 - val_loss: 0.7273\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 56ms/step - accuracy: 0.4988 - loss: 0.8395 - val_accuracy: 0.6411 - val_loss: 0.6608\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 54ms/step - accuracy: 0.5890 - loss: 0.8052 - val_accuracy: 0.4960 - val_loss: 0.7299\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 55ms/step - accuracy: 0.5963 - loss: 0.7816 - val_accuracy: 0.5796 - val_loss: 0.6838\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 53ms/step - accuracy: 0.6128 - loss: 0.7758 - val_accuracy: 0.6250 - val_loss: 0.6474\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 54ms/step - accuracy: 0.6199 - loss: 0.7724 - val_accuracy: 0.6401 - val_loss: 0.6453\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 54ms/step - accuracy: 0.6333 - loss: 0.7588 - val_accuracy: 0.6220 - val_loss: 0.6688\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 52ms/step - accuracy: 0.6294 - loss: 0.7502 - val_accuracy: 0.6411 - val_loss: 0.6257\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 52ms/step - accuracy: 0.6215 - loss: 0.7639 - val_accuracy: 0.6573 - val_loss: 0.6248\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 52ms/step - accuracy: 0.6701 - loss: 0.7248 - val_accuracy: 0.6613 - val_loss: 0.6171\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - accuracy: 0.6863 - loss: 0.7076 - val_accuracy: 0.6804 - val_loss: 0.5932\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 53ms/step - accuracy: 0.6982 - loss: 0.6950 - val_accuracy: 0.7208 - val_loss: 0.5647\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 53ms/step - accuracy: 0.7055 - loss: 0.6710 - val_accuracy: 0.7107 - val_loss: 0.5662\n",
            "Epoch 13/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 53ms/step - accuracy: 0.7214 - loss: 0.6554 - val_accuracy: 0.7107 - val_loss: 0.5814\n",
            "Epoch 14/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 55ms/step - accuracy: 0.7125 - loss: 0.6686 - val_accuracy: 0.7087 - val_loss: 0.5694\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 50ms/step - accuracy: 0.4994 - loss: 0.8436 - val_accuracy: 0.5746 - val_loss: 0.6831\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - accuracy: 0.5930 - loss: 0.7857 - val_accuracy: 0.5978 - val_loss: 0.6657\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.6307 - loss: 0.7706 - val_accuracy: 0.4708 - val_loss: 0.7280\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 49ms/step - accuracy: 0.6051 - loss: 0.7739 - val_accuracy: 0.5685 - val_loss: 0.6921\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 50ms/step - accuracy: 0.6206 - loss: 0.7646 - val_accuracy: 0.6190 - val_loss: 0.6568\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 50ms/step - accuracy: 0.6348 - loss: 0.7571 - val_accuracy: 0.6331 - val_loss: 0.6361\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 54ms/step - accuracy: 0.6277 - loss: 0.7642 - val_accuracy: 0.4698 - val_loss: 0.7699\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.6044 - loss: 0.7841 - val_accuracy: 0.6865 - val_loss: 0.5950\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - accuracy: 0.6626 - loss: 0.7130 - val_accuracy: 0.7127 - val_loss: 0.5684\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 50ms/step - accuracy: 0.6901 - loss: 0.7013 - val_accuracy: 0.7208 - val_loss: 0.5491\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 58ms/step - accuracy: 0.7188 - loss: 0.6746 - val_accuracy: 0.6401 - val_loss: 0.6243\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 50ms/step - accuracy: 0.7006 - loss: 0.6784 - val_accuracy: 0.7077 - val_loss: 0.5617\n",
            "Epoch 13/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 50ms/step - accuracy: 0.7113 - loss: 0.6774 - val_accuracy: 0.7087 - val_loss: 0.5399\n",
            "Epoch 14/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - accuracy: 0.7125 - loss: 0.6733 - val_accuracy: 0.7238 - val_loss: 0.5382\n",
            "Epoch 15/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 50ms/step - accuracy: 0.7260 - loss: 0.6438 - val_accuracy: 0.6915 - val_loss: 0.5793\n",
            "Epoch 16/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.7331 - loss: 0.6372 - val_accuracy: 0.7530 - val_loss: 0.5237\n",
            "Epoch 17/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 45ms/step - accuracy: 0.7371 - loss: 0.6365 - val_accuracy: 0.7268 - val_loss: 0.5349\n",
            "Epoch 18/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - accuracy: 0.7343 - loss: 0.6346 - val_accuracy: 0.6704 - val_loss: 0.5868\n",
            "Epoch 19/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 51ms/step - accuracy: 0.7367 - loss: 0.6261 - val_accuracy: 0.7359 - val_loss: 0.5382\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 56ms/step - accuracy: 0.4986 - loss: 0.8491 - val_accuracy: 0.4698 - val_loss: 0.7190\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 55ms/step - accuracy: 0.4942 - loss: 0.8442 - val_accuracy: 0.4698 - val_loss: 0.7463\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 57ms/step - accuracy: 0.4861 - loss: 0.8480 - val_accuracy: 0.4698 - val_loss: 0.7291\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 57ms/step - accuracy: 0.5010 - loss: 0.8419 - val_accuracy: 0.4698 - val_loss: 0.7256\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.5064 - loss: 0.8456 - val_accuracy: 0.4677 - val_loss: 0.7082\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - accuracy: 0.5580 - loss: 0.8046 - val_accuracy: 0.5746 - val_loss: 0.6791\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.6100 - loss: 0.7874 - val_accuracy: 0.5847 - val_loss: 0.6672\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.6142 - loss: 0.7729 - val_accuracy: 0.5998 - val_loss: 0.6801\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - accuracy: 0.5370 - loss: 0.8247 - val_accuracy: 0.5595 - val_loss: 0.6881\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 56ms/step - accuracy: 0.6114 - loss: 0.7798 - val_accuracy: 0.5111 - val_loss: 0.7106\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 60ms/step - accuracy: 0.5022 - loss: 0.8437 - val_accuracy: 0.5504 - val_loss: 0.6838\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 56ms/step - accuracy: 0.5716 - loss: 0.8001 - val_accuracy: 0.6058 - val_loss: 0.6786\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 59ms/step - accuracy: 0.6089 - loss: 0.7762 - val_accuracy: 0.4950 - val_loss: 0.7400\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.5895 - loss: 0.7770 - val_accuracy: 0.5786 - val_loss: 0.6813\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.6286 - loss: 0.7614 - val_accuracy: 0.5968 - val_loss: 0.6741\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.6417 - loss: 0.7692 - val_accuracy: 0.5867 - val_loss: 0.6962\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.6295 - loss: 0.7608 - val_accuracy: 0.6391 - val_loss: 0.6588\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.6255 - loss: 0.7650 - val_accuracy: 0.6573 - val_loss: 0.6362\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.6805 - loss: 0.7149 - val_accuracy: 0.6956 - val_loss: 0.5797\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.6932 - loss: 0.6958 - val_accuracy: 0.6290 - val_loss: 0.6244\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.6835 - loss: 0.6932 - val_accuracy: 0.7319 - val_loss: 0.5288\n",
            "Epoch 12/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.6968 - loss: 0.6874 - val_accuracy: 0.7349 - val_loss: 0.5366\n",
            "Epoch 13/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.7229 - loss: 0.6586 - val_accuracy: 0.7147 - val_loss: 0.5649\n",
            "Epoch 14/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.7354 - loss: 0.6399 - val_accuracy: 0.7137 - val_loss: 0.5582\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.4927 - loss: 0.8463 - val_accuracy: 0.5262 - val_loss: 0.6868\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 55ms/step - accuracy: 0.5730 - loss: 0.7966 - val_accuracy: 0.6179 - val_loss: 0.6600\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.6073 - loss: 0.7847 - val_accuracy: 0.5323 - val_loss: 0.6870\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.5432 - loss: 0.8136 - val_accuracy: 0.6300 - val_loss: 0.6605\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 43ms/step - accuracy: 0.6025 - loss: 0.7940 - val_accuracy: 0.5736 - val_loss: 0.6841\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.5078 - loss: 0.8453 - val_accuracy: 0.6139 - val_loss: 0.6660\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.5782 - loss: 0.8056 - val_accuracy: 0.5786 - val_loss: 0.6816\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.6011 - loss: 0.7911 - val_accuracy: 0.6109 - val_loss: 0.6518\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - accuracy: 0.5950 - loss: 0.7858 - val_accuracy: 0.5242 - val_loss: 0.6928\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.5742 - loss: 0.7882 - val_accuracy: 0.6260 - val_loss: 0.6560\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - accuracy: 0.6170 - loss: 0.7692 - val_accuracy: 0.5383 - val_loss: 0.7264\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
            "Training CNN...\n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.5180 - loss: 0.8258 - val_accuracy: 0.4708 - val_loss: 0.6859\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5511 - loss: 0.7823 - val_accuracy: 0.6381 - val_loss: 0.6484\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6571 - loss: 0.7429 - val_accuracy: 0.6774 - val_loss: 0.6226\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6721 - loss: 0.7206 - val_accuracy: 0.6905 - val_loss: 0.6052\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6910 - loss: 0.7061 - val_accuracy: 0.6855 - val_loss: 0.6061\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6920 - loss: 0.6941 - val_accuracy: 0.7188 - val_loss: 0.5713\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7165 - loss: 0.6781 - val_accuracy: 0.6260 - val_loss: 0.6380\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7085 - loss: 0.6723 - val_accuracy: 0.6925 - val_loss: 0.5868\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7239 - loss: 0.6590 - val_accuracy: 0.7359 - val_loss: 0.5521\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7244 - loss: 0.6490 - val_accuracy: 0.7399 - val_loss: 0.5437\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.5024 - loss: 0.8222 - val_accuracy: 0.5867 - val_loss: 0.6667\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6129 - loss: 0.7532 - val_accuracy: 0.6754 - val_loss: 0.6147\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6815 - loss: 0.7180 - val_accuracy: 0.6593 - val_loss: 0.6160\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6873 - loss: 0.7016 - val_accuracy: 0.7046 - val_loss: 0.5685\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6920 - loss: 0.6894 - val_accuracy: 0.7147 - val_loss: 0.5650\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7139 - loss: 0.6614 - val_accuracy: 0.7117 - val_loss: 0.5542\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7130 - loss: 0.6618 - val_accuracy: 0.6946 - val_loss: 0.5756\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7369 - loss: 0.6214 - val_accuracy: 0.7238 - val_loss: 0.5342\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7258 - loss: 0.6414 - val_accuracy: 0.6935 - val_loss: 0.5663\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7295 - loss: 0.6248 - val_accuracy: 0.7349 - val_loss: 0.5210\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.4997 - loss: 0.8227 - val_accuracy: 0.4698 - val_loss: 0.7004\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5937 - loss: 0.7744 - val_accuracy: 0.6472 - val_loss: 0.6383\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6577 - loss: 0.7449 - val_accuracy: 0.6835 - val_loss: 0.6101\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6779 - loss: 0.7232 - val_accuracy: 0.6986 - val_loss: 0.5903\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7118 - loss: 0.6947 - val_accuracy: 0.7117 - val_loss: 0.5868\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7210 - loss: 0.6741 - val_accuracy: 0.7177 - val_loss: 0.5691\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7124 - loss: 0.6749 - val_accuracy: 0.7258 - val_loss: 0.5599\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7159 - loss: 0.6626 - val_accuracy: 0.7298 - val_loss: 0.5532\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7137 - loss: 0.6589 - val_accuracy: 0.7298 - val_loss: 0.5443\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7342 - loss: 0.6454 - val_accuracy: 0.7248 - val_loss: 0.5405\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.4905 - loss: 0.8263 - val_accuracy: 0.6542 - val_loss: 0.6554\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6132 - loss: 0.7712 - val_accuracy: 0.6714 - val_loss: 0.6293\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6635 - loss: 0.7353 - val_accuracy: 0.6683 - val_loss: 0.6203\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6636 - loss: 0.7193 - val_accuracy: 0.6260 - val_loss: 0.6343\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6924 - loss: 0.6783 - val_accuracy: 0.7288 - val_loss: 0.5665\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7107 - loss: 0.6640 - val_accuracy: 0.7198 - val_loss: 0.5663\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7247 - loss: 0.6482 - val_accuracy: 0.7218 - val_loss: 0.5440\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7215 - loss: 0.6408 - val_accuracy: 0.7218 - val_loss: 0.5582\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7300 - loss: 0.6317 - val_accuracy: 0.7379 - val_loss: 0.5394\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7288 - loss: 0.6289 - val_accuracy: 0.7026 - val_loss: 0.5625\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.5048 - loss: 0.8522 - val_accuracy: 0.4698 - val_loss: 0.6987\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5281 - loss: 0.7958 - val_accuracy: 0.6391 - val_loss: 0.6533\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5979 - loss: 0.7662 - val_accuracy: 0.6542 - val_loss: 0.6388\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6639 - loss: 0.7326 - val_accuracy: 0.6391 - val_loss: 0.6466\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6636 - loss: 0.7300 - val_accuracy: 0.6905 - val_loss: 0.6073\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6834 - loss: 0.7148 - val_accuracy: 0.6925 - val_loss: 0.6037\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7022 - loss: 0.6958 - val_accuracy: 0.7127 - val_loss: 0.5862\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7092 - loss: 0.6794 - val_accuracy: 0.7077 - val_loss: 0.5778\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7141 - loss: 0.6643 - val_accuracy: 0.7117 - val_loss: 0.5688\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7068 - loss: 0.6709 - val_accuracy: 0.7147 - val_loss: 0.5734\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.5020 - loss: 0.8250 - val_accuracy: 0.6562 - val_loss: 0.6564\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5786 - loss: 0.7735 - val_accuracy: 0.6371 - val_loss: 0.6513\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6631 - loss: 0.7394 - val_accuracy: 0.6784 - val_loss: 0.6090\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6867 - loss: 0.7246 - val_accuracy: 0.7067 - val_loss: 0.5886\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6979 - loss: 0.6849 - val_accuracy: 0.7117 - val_loss: 0.5651\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7096 - loss: 0.6832 - val_accuracy: 0.7308 - val_loss: 0.5547\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7400 - loss: 0.6419 - val_accuracy: 0.7117 - val_loss: 0.5579\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7158 - loss: 0.6564 - val_accuracy: 0.7339 - val_loss: 0.5498\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7214 - loss: 0.6413 - val_accuracy: 0.7409 - val_loss: 0.5301\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7431 - loss: 0.6297 - val_accuracy: 0.7067 - val_loss: 0.5610\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.5022 - loss: 0.8229 - val_accuracy: 0.4980 - val_loss: 0.6788\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5580 - loss: 0.7927 - val_accuracy: 0.6583 - val_loss: 0.6429\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6105 - loss: 0.7603 - val_accuracy: 0.6613 - val_loss: 0.6281\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6452 - loss: 0.7579 - val_accuracy: 0.6704 - val_loss: 0.6159\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6784 - loss: 0.7240 - val_accuracy: 0.6815 - val_loss: 0.6178\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6880 - loss: 0.7189 - val_accuracy: 0.6855 - val_loss: 0.5979\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6857 - loss: 0.7081 - val_accuracy: 0.6794 - val_loss: 0.6099\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6709 - loss: 0.6984 - val_accuracy: 0.7117 - val_loss: 0.5894\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7147 - loss: 0.6738 - val_accuracy: 0.7107 - val_loss: 0.5790\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7010 - loss: 0.6724 - val_accuracy: 0.7087 - val_loss: 0.5815\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.5119 - loss: 0.8230 - val_accuracy: 0.6482 - val_loss: 0.6581\n",
            "Epoch 2/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5931 - loss: 0.7871 - val_accuracy: 0.6179 - val_loss: 0.6572\n",
            "Epoch 3/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6389 - loss: 0.7458 - val_accuracy: 0.6663 - val_loss: 0.6273\n",
            "Epoch 4/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6889 - loss: 0.7184 - val_accuracy: 0.6865 - val_loss: 0.6114\n",
            "Epoch 5/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6859 - loss: 0.6997 - val_accuracy: 0.6835 - val_loss: 0.6042\n",
            "Epoch 6/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6927 - loss: 0.6924 - val_accuracy: 0.7147 - val_loss: 0.5697\n",
            "Epoch 7/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7164 - loss: 0.6637 - val_accuracy: 0.7147 - val_loss: 0.5627\n",
            "Epoch 8/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7104 - loss: 0.6739 - val_accuracy: 0.7218 - val_loss: 0.5556\n",
            "Epoch 9/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7231 - loss: 0.6446 - val_accuracy: 0.7258 - val_loss: 0.5569\n",
            "Epoch 10/10\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7351 - loss: 0.6358 - val_accuracy: 0.6663 - val_loss: 0.5952\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.4864 - loss: 0.8322 - val_accuracy: 0.4940 - val_loss: 0.6778\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5717 - loss: 0.7674 - val_accuracy: 0.6774 - val_loss: 0.6256\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6451 - loss: 0.7418 - val_accuracy: 0.6815 - val_loss: 0.6160\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6804 - loss: 0.7177 - val_accuracy: 0.6966 - val_loss: 0.5995\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6934 - loss: 0.6893 - val_accuracy: 0.6804 - val_loss: 0.6048\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7052 - loss: 0.6790 - val_accuracy: 0.7056 - val_loss: 0.5807\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7079 - loss: 0.6828 - val_accuracy: 0.7127 - val_loss: 0.5738\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7090 - loss: 0.6774 - val_accuracy: 0.7198 - val_loss: 0.5652\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7082 - loss: 0.6562 - val_accuracy: 0.7308 - val_loss: 0.5492\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7175 - loss: 0.6463 - val_accuracy: 0.6704 - val_loss: 0.5981\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7241 - loss: 0.6316 - val_accuracy: 0.7308 - val_loss: 0.5370\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7263 - loss: 0.6338 - val_accuracy: 0.7308 - val_loss: 0.5470\n",
            "Epoch 13/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7279 - loss: 0.6326 - val_accuracy: 0.7107 - val_loss: 0.5587\n",
            "Epoch 14/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7354 - loss: 0.6310 - val_accuracy: 0.7288 - val_loss: 0.5486\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.5122 - loss: 0.8223 - val_accuracy: 0.6663 - val_loss: 0.6417\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6307 - loss: 0.7529 - val_accuracy: 0.6815 - val_loss: 0.6060\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6900 - loss: 0.7108 - val_accuracy: 0.6885 - val_loss: 0.6052\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6812 - loss: 0.7096 - val_accuracy: 0.6764 - val_loss: 0.6038\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7005 - loss: 0.6759 - val_accuracy: 0.7016 - val_loss: 0.5665\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7178 - loss: 0.6663 - val_accuracy: 0.7167 - val_loss: 0.5513\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7394 - loss: 0.6266 - val_accuracy: 0.7157 - val_loss: 0.5570\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7153 - loss: 0.6460 - val_accuracy: 0.7329 - val_loss: 0.5359\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7230 - loss: 0.6446 - val_accuracy: 0.7349 - val_loss: 0.5323\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7324 - loss: 0.6163 - val_accuracy: 0.7429 - val_loss: 0.5202\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7408 - loss: 0.6150 - val_accuracy: 0.7167 - val_loss: 0.5611\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7526 - loss: 0.5994 - val_accuracy: 0.7450 - val_loss: 0.5170\n",
            "Epoch 13/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7627 - loss: 0.5838 - val_accuracy: 0.6623 - val_loss: 0.5969\n",
            "Epoch 14/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7564 - loss: 0.5817 - val_accuracy: 0.7177 - val_loss: 0.5563\n",
            "Epoch 15/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7605 - loss: 0.5938 - val_accuracy: 0.7188 - val_loss: 0.5363\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5019 - loss: 0.8296 - val_accuracy: 0.4748 - val_loss: 0.6816\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5706 - loss: 0.7831 - val_accuracy: 0.6542 - val_loss: 0.6424\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6495 - loss: 0.7385 - val_accuracy: 0.6532 - val_loss: 0.6427\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6872 - loss: 0.7203 - val_accuracy: 0.6855 - val_loss: 0.6011\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6601 - loss: 0.7372 - val_accuracy: 0.7067 - val_loss: 0.5945\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6928 - loss: 0.6955 - val_accuracy: 0.7087 - val_loss: 0.5851\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7014 - loss: 0.6956 - val_accuracy: 0.7097 - val_loss: 0.5740\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7111 - loss: 0.6763 - val_accuracy: 0.7087 - val_loss: 0.5739\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7243 - loss: 0.6549 - val_accuracy: 0.7167 - val_loss: 0.5700\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7353 - loss: 0.6385 - val_accuracy: 0.6946 - val_loss: 0.5859\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7260 - loss: 0.6351 - val_accuracy: 0.7006 - val_loss: 0.5772\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7279 - loss: 0.6443 - val_accuracy: 0.7167 - val_loss: 0.5630\n",
            "Epoch 13/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7318 - loss: 0.6440 - val_accuracy: 0.7006 - val_loss: 0.5754\n",
            "Epoch 14/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7205 - loss: 0.6499 - val_accuracy: 0.7329 - val_loss: 0.5400\n",
            "Epoch 15/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7485 - loss: 0.6248 - val_accuracy: 0.7248 - val_loss: 0.5553\n",
            "Epoch 16/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7233 - loss: 0.6293 - val_accuracy: 0.7450 - val_loss: 0.5298\n",
            "Epoch 17/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7378 - loss: 0.6292 - val_accuracy: 0.7429 - val_loss: 0.5321\n",
            "Epoch 18/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7419 - loss: 0.6021 - val_accuracy: 0.7389 - val_loss: 0.5388\n",
            "Epoch 19/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7445 - loss: 0.6034 - val_accuracy: 0.7016 - val_loss: 0.5633\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.4949 - loss: 0.8298 - val_accuracy: 0.5877 - val_loss: 0.6657\n",
            "Epoch 2/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6170 - loss: 0.7621 - val_accuracy: 0.6784 - val_loss: 0.6169\n",
            "Epoch 3/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6705 - loss: 0.7239 - val_accuracy: 0.6058 - val_loss: 0.6554\n",
            "Epoch 4/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6825 - loss: 0.7029 - val_accuracy: 0.6653 - val_loss: 0.6085\n",
            "Epoch 5/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6873 - loss: 0.6889 - val_accuracy: 0.7167 - val_loss: 0.5690\n",
            "Epoch 6/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7241 - loss: 0.6597 - val_accuracy: 0.7238 - val_loss: 0.5530\n",
            "Epoch 7/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7213 - loss: 0.6515 - val_accuracy: 0.6230 - val_loss: 0.6352\n",
            "Epoch 8/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7212 - loss: 0.6365 - val_accuracy: 0.7480 - val_loss: 0.5391\n",
            "Epoch 9/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7206 - loss: 0.6438 - val_accuracy: 0.7440 - val_loss: 0.5315\n",
            "Epoch 10/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7337 - loss: 0.6479 - val_accuracy: 0.7490 - val_loss: 0.5275\n",
            "Epoch 11/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7244 - loss: 0.6382 - val_accuracy: 0.7419 - val_loss: 0.5230\n",
            "Epoch 12/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7484 - loss: 0.6065 - val_accuracy: 0.6905 - val_loss: 0.5713\n",
            "Epoch 13/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7260 - loss: 0.6306 - val_accuracy: 0.7490 - val_loss: 0.5164\n",
            "Epoch 14/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7612 - loss: 0.5913 - val_accuracy: 0.7399 - val_loss: 0.5330\n",
            "Epoch 15/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7527 - loss: 0.6006 - val_accuracy: 0.7238 - val_loss: 0.5452\n",
            "Epoch 16/20\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7538 - loss: 0.6018 - val_accuracy: 0.5736 - val_loss: 0.6891\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.5166 - loss: 0.8255 - val_accuracy: 0.4728 - val_loss: 0.6813\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5137 - loss: 0.7908 - val_accuracy: 0.6411 - val_loss: 0.6493\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6183 - loss: 0.7645 - val_accuracy: 0.6462 - val_loss: 0.6400\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6447 - loss: 0.7508 - val_accuracy: 0.6784 - val_loss: 0.6119\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6939 - loss: 0.7134 - val_accuracy: 0.6573 - val_loss: 0.6234\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6832 - loss: 0.7065 - val_accuracy: 0.6401 - val_loss: 0.6375\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6863 - loss: 0.6963 - val_accuracy: 0.6996 - val_loss: 0.5849\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7157 - loss: 0.6742 - val_accuracy: 0.6825 - val_loss: 0.5984\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7015 - loss: 0.6769 - val_accuracy: 0.6895 - val_loss: 0.5907\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7173 - loss: 0.6634 - val_accuracy: 0.7167 - val_loss: 0.5588\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7159 - loss: 0.6695 - val_accuracy: 0.6724 - val_loss: 0.6027\n",
            "Epoch 12/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7103 - loss: 0.6724 - val_accuracy: 0.7198 - val_loss: 0.5503\n",
            "Epoch 13/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7222 - loss: 0.6486 - val_accuracy: 0.7268 - val_loss: 0.5437\n",
            "Epoch 14/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7249 - loss: 0.6341 - val_accuracy: 0.7248 - val_loss: 0.5427\n",
            "Epoch 15/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7338 - loss: 0.6365 - val_accuracy: 0.7067 - val_loss: 0.5652\n",
            "Epoch 16/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7359 - loss: 0.6306 - val_accuracy: 0.6583 - val_loss: 0.6092\n",
            "Epoch 17/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7101 - loss: 0.6556 - val_accuracy: 0.7218 - val_loss: 0.5436\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.5033 - loss: 0.8213 - val_accuracy: 0.4778 - val_loss: 0.6842\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5621 - loss: 0.7739 - val_accuracy: 0.6613 - val_loss: 0.6323\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6724 - loss: 0.7323 - val_accuracy: 0.6038 - val_loss: 0.6683\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6504 - loss: 0.7300 - val_accuracy: 0.6734 - val_loss: 0.6139\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6956 - loss: 0.6875 - val_accuracy: 0.7006 - val_loss: 0.5802\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6862 - loss: 0.6942 - val_accuracy: 0.7026 - val_loss: 0.5918\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7062 - loss: 0.6720 - val_accuracy: 0.7157 - val_loss: 0.5608\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7230 - loss: 0.6468 - val_accuracy: 0.7167 - val_loss: 0.5548\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7327 - loss: 0.6428 - val_accuracy: 0.7208 - val_loss: 0.5600\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7143 - loss: 0.6544 - val_accuracy: 0.7117 - val_loss: 0.5621\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7323 - loss: 0.6304 - val_accuracy: 0.7349 - val_loss: 0.5421\n",
            "Epoch 12/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7276 - loss: 0.6251 - val_accuracy: 0.7198 - val_loss: 0.5566\n",
            "Epoch 13/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7429 - loss: 0.6080 - val_accuracy: 0.6804 - val_loss: 0.5832\n",
            "Epoch 14/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7375 - loss: 0.6124 - val_accuracy: 0.7440 - val_loss: 0.5275\n",
            "Epoch 15/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7373 - loss: 0.6336 - val_accuracy: 0.7480 - val_loss: 0.5227\n",
            "Epoch 16/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7626 - loss: 0.5945 - val_accuracy: 0.7470 - val_loss: 0.5196\n",
            "Epoch 17/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7441 - loss: 0.6092 - val_accuracy: 0.7419 - val_loss: 0.5217\n",
            "Epoch 18/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7506 - loss: 0.5971 - val_accuracy: 0.7268 - val_loss: 0.5468\n",
            "Epoch 19/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7581 - loss: 0.5895 - val_accuracy: 0.7540 - val_loss: 0.5125\n",
            "Epoch 20/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7757 - loss: 0.5580 - val_accuracy: 0.7520 - val_loss: 0.5078\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.4945 - loss: 0.8329 - val_accuracy: 0.5111 - val_loss: 0.6757\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5240 - loss: 0.7898 - val_accuracy: 0.6774 - val_loss: 0.6403\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6377 - loss: 0.7600 - val_accuracy: 0.6734 - val_loss: 0.6219\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6571 - loss: 0.7352 - val_accuracy: 0.6804 - val_loss: 0.6175\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6754 - loss: 0.7205 - val_accuracy: 0.6804 - val_loss: 0.6115\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6855 - loss: 0.7058 - val_accuracy: 0.6663 - val_loss: 0.6179\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6985 - loss: 0.6867 - val_accuracy: 0.7117 - val_loss: 0.5820\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7063 - loss: 0.6824 - val_accuracy: 0.7046 - val_loss: 0.5932\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7052 - loss: 0.6706 - val_accuracy: 0.6774 - val_loss: 0.5992\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6951 - loss: 0.6823 - val_accuracy: 0.6714 - val_loss: 0.5976\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Epoch 1/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.5100 - loss: 0.8318 - val_accuracy: 0.4768 - val_loss: 0.6804\n",
            "Epoch 2/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5757 - loss: 0.7842 - val_accuracy: 0.6270 - val_loss: 0.6540\n",
            "Epoch 3/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6316 - loss: 0.7453 - val_accuracy: 0.6663 - val_loss: 0.6224\n",
            "Epoch 4/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6797 - loss: 0.7233 - val_accuracy: 0.6522 - val_loss: 0.6292\n",
            "Epoch 5/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6732 - loss: 0.7117 - val_accuracy: 0.6946 - val_loss: 0.5877\n",
            "Epoch 6/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6970 - loss: 0.7029 - val_accuracy: 0.7117 - val_loss: 0.5790\n",
            "Epoch 7/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7112 - loss: 0.6657 - val_accuracy: 0.6946 - val_loss: 0.5848\n",
            "Epoch 8/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7133 - loss: 0.6591 - val_accuracy: 0.7248 - val_loss: 0.5571\n",
            "Epoch 9/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7214 - loss: 0.6539 - val_accuracy: 0.6804 - val_loss: 0.5868\n",
            "Epoch 10/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7258 - loss: 0.6488 - val_accuracy: 0.7218 - val_loss: 0.5560\n",
            "Epoch 11/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7297 - loss: 0.6363 - val_accuracy: 0.7248 - val_loss: 0.5521\n",
            "Epoch 12/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7351 - loss: 0.6297 - val_accuracy: 0.7429 - val_loss: 0.5391\n",
            "Epoch 13/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7515 - loss: 0.6062 - val_accuracy: 0.7177 - val_loss: 0.5561\n",
            "Epoch 14/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7340 - loss: 0.6253 - val_accuracy: 0.7319 - val_loss: 0.5464\n",
            "Epoch 15/20\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7551 - loss: 0.6043 - val_accuracy: 0.7157 - val_loss: 0.5542\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "Experiment completed. Results saved.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Conv1D, GlobalMaxPooling1D, Dropout, Input, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import joblib\n",
        "import json\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Set paths\n",
        "data_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/data.xlsx\"\n",
        "save_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/deep_learning_results8\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_excel(data_path)\n",
        "df.dropna(inplace=True)\n",
        "print(\"Size of DataFrame after dropping null values:\", df.shape)\n",
        "\n",
        "# Function to parse vector strings into numpy arrays\n",
        "def parse_vector(vector_str, expected_dim):\n",
        "    try:\n",
        "        if isinstance(vector_str, str):\n",
        "            vec = np.array([float(i) for i in vector_str.strip(\"[]\").split()], dtype=np.float32)\n",
        "            if vec.shape[0] == expected_dim:\n",
        "                return vec\n",
        "            elif vec.shape[0] > expected_dim:\n",
        "                return vec[:expected_dim]  # Truncate to expected size\n",
        "            else:\n",
        "                return np.pad(vec, (0, expected_dim - vec.shape[0]))  # Pad with zeros\n",
        "    except:\n",
        "        return np.zeros(expected_dim, dtype=np.float32)  # Default to zero vector\n",
        "    return np.zeros(expected_dim, dtype=np.float32)\n",
        "\n",
        "# Define expected dimensions\n",
        "word2vec_dim = 300\n",
        "fasttext_dim = 300\n",
        "sentence_embedding_dim = 300\n",
        "sinbert_dim = 768  # Larger than others\n",
        "\n",
        "# Apply parsing with dimension corrections\n",
        "df['word2vec_vector'] = df['word2vec_vector'].map(lambda x: parse_vector(x, word2vec_dim))\n",
        "df['fasttext_vector'] = df['fasttext_vector'].map(lambda x: parse_vector(x, fasttext_dim))\n",
        "df['sentence_embedding'] = df['sentence_embedding'].map(lambda x: parse_vector(x, sentence_embedding_dim))\n",
        "df['sinbert_vector'] = df['sinbert_vector'].map(lambda x: parse_vector(x, sinbert_dim))  # Keep 768D\n",
        "\n",
        "# Ensure all feature vectors have the same final dimension\n",
        "final_dim = 768  # Choose larger or normalize to 300\n",
        "for feature in ['word2vec_vector', 'fasttext_vector', 'sentence_embedding']:\n",
        "    df[feature] = df[feature].map(lambda x: np.pad(x, (0, final_dim - x.shape[0])) if x.shape[0] < final_dim else x[:final_dim])\n",
        "\n",
        "# Stack feature vectors correctly\n",
        "X = np.stack(df[['word2vec_vector', 'fasttext_vector', 'sentence_embedding', 'sinbert_vector']].apply(lambda row: np.column_stack(row.values), axis=1).values)\n",
        "\n",
        "# Flatten X for MLP: (samples, final_dim * 4)\n",
        "X_flattened = X.reshape(X.shape[0], -1)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'].values)\n",
        "joblib.dump(label_encoder, os.path.join(save_path, 'label_encoder.pkl'))\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train_flattened, X_test_flattened = train_test_split(X_flattened, test_size=0.2, random_state=42)\n",
        "\n",
        "# Function to implement early stopping and class weights\n",
        "def build_mlp(input_shape, dropout_rate, dense_units):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Dense(dense_units, activation='relu'),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(dense_units // 2, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_lstm(input_shape, dropout_rate, lstm_units):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        LSTM(lstm_units, return_sequences=True),\n",
        "        Dropout(dropout_rate),\n",
        "        LSTM(lstm_units // 2),\n",
        "        Flatten(),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_cnn(input_shape, dropout_rate, filters):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Conv1D(filters, kernel_size=3, activation='relu'),\n",
        "        Dropout(dropout_rate),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(filters // 2, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Early stopping callback to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Apply class weights (use if there is class imbalance)\n",
        "class_weights = {0: 1, 1: 1.5}  # Increase weight for the minority class\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"confusion_matrix\": conf_matrix.tolist()\n",
        "    }\n",
        "\n",
        "# Train and evaluate models with hyperparameter tuning and regularization\n",
        "results = {}\n",
        "\n",
        "# Model hyperparameters for tuning\n",
        "params = {\n",
        "    'MLP': {\n",
        "        'epochs': [10, 20],\n",
        "        'batch_size': [16, 32],\n",
        "        'dropout': [0.2, 0.3],\n",
        "        'dense_units': [64, 128]\n",
        "    },\n",
        "    'LSTM': {\n",
        "        'epochs': [10, 20],\n",
        "        'batch_size': [16, 32],\n",
        "        'dropout': [0.2, 0.3],\n",
        "        'lstm_units': [64, 128],\n",
        "    },\n",
        "    'CNN': {\n",
        "        'epochs': [10, 20],\n",
        "        'batch_size': [16, 32],\n",
        "        'dropout': [0.2, 0.3],\n",
        "        'filters': [64, 128],\n",
        "    }\n",
        "}\n",
        "\n",
        "# Train and evaluate each model\n",
        "for name in ['MLP', 'LSTM', 'CNN']:\n",
        "    print(f\"Training {name}...\")\n",
        "\n",
        "    # Hyperparameter grid search (manually tuned here)\n",
        "    for epochs in params[name]['epochs']:\n",
        "        for batch_size in params[name]['batch_size']:\n",
        "            if name == 'MLP':\n",
        "                for dropout in params[name]['dropout']:\n",
        "                    for dense_units in params[name]['dense_units']:\n",
        "                        model_instance = build_mlp((X_train_flattened.shape[1],), dropout, dense_units)\n",
        "                        model_instance.fit(X_train_flattened, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                                           validation_data=(X_test_flattened, y_test), class_weight=class_weights,\n",
        "                                           callbacks=[early_stopping], verbose=1)\n",
        "                        y_pred = (model_instance.predict(X_test_flattened) > 0.5).astype(int)\n",
        "                        results[name] = evaluate_model(y_test, y_pred)\n",
        "            elif name == 'LSTM':\n",
        "                for dropout in params[name]['dropout']:\n",
        "                    for lstm_units in params[name]['lstm_units']:\n",
        "                        model_instance = build_lstm((X_train.shape[1], X_train.shape[2]), dropout, lstm_units)\n",
        "                        model_instance.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                                           validation_data=(X_test, y_test), class_weight=class_weights,\n",
        "                                           callbacks=[early_stopping], verbose=1)\n",
        "                        y_pred = (model_instance.predict(X_test) > 0.5).astype(int)\n",
        "                        results[name] = evaluate_model(y_test, y_pred)\n",
        "            elif name == 'CNN':\n",
        "                for dropout in params[name]['dropout']:\n",
        "                    for filters in params[name]['filters']:\n",
        "                        model_instance = build_cnn((X_train.shape[1], X_train.shape[2]), dropout, filters)\n",
        "                        model_instance.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                                           validation_data=(X_test, y_test), class_weight=class_weights,\n",
        "                                           callbacks=[early_stopping], verbose=1)\n",
        "                        y_pred = (model_instance.predict(X_test) > 0.5).astype(int)\n",
        "                        results[name] = evaluate_model(y_test, y_pred)\n",
        "\n",
        "# Save results to JSON\n",
        "results_path = os.path.join(save_path, \"model_results.json\")\n",
        "with open(results_path, \"w\") as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n",
        "print(\"Experiment completed. Results saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhYNSUoqXdO_",
        "outputId": "de237245-b6f4-4d4e-a0ad-1a64e1d120c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training MLP...\n",
            "Epoch 1/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.7113 - loss: 0.6780 - val_accuracy: 0.7903 - val_loss: 0.5133\n",
            "Epoch 2/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8074 - loss: 0.4249 - val_accuracy: 0.7893 - val_loss: 0.4742\n",
            "Epoch 3/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8084 - loss: 0.4094 - val_accuracy: 0.8004 - val_loss: 0.4402\n",
            "Epoch 4/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8264 - loss: 0.3906 - val_accuracy: 0.8034 - val_loss: 0.4523\n",
            "Epoch 5/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8290 - loss: 0.3728 - val_accuracy: 0.8014 - val_loss: 0.4337\n",
            "Epoch 6/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8374 - loss: 0.3610 - val_accuracy: 0.8115 - val_loss: 0.4437\n",
            "Epoch 7/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8287 - loss: 0.3657 - val_accuracy: 0.8145 - val_loss: 0.4269\n",
            "Epoch 8/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8371 - loss: 0.3494 - val_accuracy: 0.8125 - val_loss: 0.4388\n",
            "Epoch 9/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8561 - loss: 0.3292 - val_accuracy: 0.7974 - val_loss: 0.4602\n",
            "Epoch 10/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8689 - loss: 0.3262 - val_accuracy: 0.8135 - val_loss: 0.4444\n",
            "Epoch 11/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8498 - loss: 0.3285 - val_accuracy: 0.8105 - val_loss: 0.4457\n",
            "Epoch 12/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8684 - loss: 0.3083 - val_accuracy: 0.8135 - val_loss: 0.4281\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training LSTM...\n",
            "Epoch 1/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - accuracy: 0.5600 - loss: 0.6850 - val_accuracy: 0.6048 - val_loss: 0.6646\n",
            "Epoch 2/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 59ms/step - accuracy: 0.6160 - loss: 0.6519 - val_accuracy: 0.6079 - val_loss: 0.6582\n",
            "Epoch 3/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 55ms/step - accuracy: 0.6039 - loss: 0.6560 - val_accuracy: 0.6331 - val_loss: 0.6521\n",
            "Epoch 4/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.6288 - loss: 0.6404 - val_accuracy: 0.6321 - val_loss: 0.6416\n",
            "Epoch 5/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.6442 - loss: 0.6315 - val_accuracy: 0.6290 - val_loss: 0.6400\n",
            "Epoch 6/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.6616 - loss: 0.6243 - val_accuracy: 0.6532 - val_loss: 0.6310\n",
            "Epoch 7/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 78ms/step - accuracy: 0.6331 - loss: 0.6359 - val_accuracy: 0.6200 - val_loss: 0.6575\n",
            "Epoch 8/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.6174 - loss: 0.6527 - val_accuracy: 0.6371 - val_loss: 0.6487\n",
            "Epoch 9/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.6476 - loss: 0.6314 - val_accuracy: 0.6381 - val_loss: 0.6482\n",
            "Epoch 10/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.6502 - loss: 0.6276 - val_accuracy: 0.6462 - val_loss: 0.6325\n",
            "Epoch 11/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 55ms/step - accuracy: 0.6746 - loss: 0.6054 - val_accuracy: 0.6532 - val_loss: 0.6235\n",
            "Epoch 12/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 49ms/step - accuracy: 0.6669 - loss: 0.6117 - val_accuracy: 0.6472 - val_loss: 0.6252\n",
            "Epoch 13/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.6311 - loss: 0.6379 - val_accuracy: 0.6149 - val_loss: 0.6459\n",
            "Epoch 14/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.5011 - loss: 0.7200 - val_accuracy: 0.5302 - val_loss: 0.6914\n",
            "Epoch 15/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - accuracy: 0.4962 - loss: 0.6954 - val_accuracy: 0.4698 - val_loss: 0.6986\n",
            "Epoch 16/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - accuracy: 0.5046 - loss: 0.6968 - val_accuracy: 0.4698 - val_loss: 0.6974\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training CNN...\n",
            "Epoch 1/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.4974 - loss: 0.6925 - val_accuracy: 0.6139 - val_loss: 0.6785\n",
            "Epoch 2/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6233 - loss: 0.6758 - val_accuracy: 0.6704 - val_loss: 0.6469\n",
            "Epoch 3/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6867 - loss: 0.6424 - val_accuracy: 0.6784 - val_loss: 0.6100\n",
            "Epoch 4/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6887 - loss: 0.6080 - val_accuracy: 0.6865 - val_loss: 0.5916\n",
            "Epoch 5/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7209 - loss: 0.5762 - val_accuracy: 0.6946 - val_loss: 0.5799\n",
            "Epoch 6/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7234 - loss: 0.5636 - val_accuracy: 0.7036 - val_loss: 0.5803\n",
            "Epoch 7/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7041 - loss: 0.5731 - val_accuracy: 0.7036 - val_loss: 0.5626\n",
            "Epoch 8/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7340 - loss: 0.5650 - val_accuracy: 0.7097 - val_loss: 0.5599\n",
            "Epoch 9/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7180 - loss: 0.5609 - val_accuracy: 0.7077 - val_loss: 0.5591\n",
            "Epoch 10/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7217 - loss: 0.5589 - val_accuracy: 0.7097 - val_loss: 0.5629\n",
            "Epoch 11/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7292 - loss: 0.5615 - val_accuracy: 0.7097 - val_loss: 0.5682\n",
            "Epoch 12/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7292 - loss: 0.5632 - val_accuracy: 0.7157 - val_loss: 0.5496\n",
            "Epoch 13/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7492 - loss: 0.5322 - val_accuracy: 0.7147 - val_loss: 0.5539\n",
            "Epoch 14/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7315 - loss: 0.5420 - val_accuracy: 0.7117 - val_loss: 0.5589\n",
            "Epoch 15/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7484 - loss: 0.5265 - val_accuracy: 0.7218 - val_loss: 0.5484\n",
            "Epoch 16/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7472 - loss: 0.5276 - val_accuracy: 0.7218 - val_loss: 0.5436\n",
            "Epoch 17/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7336 - loss: 0.5484 - val_accuracy: 0.7208 - val_loss: 0.5424\n",
            "Epoch 18/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7499 - loss: 0.5214 - val_accuracy: 0.7147 - val_loss: 0.5507\n",
            "Epoch 19/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7325 - loss: 0.5317 - val_accuracy: 0.7238 - val_loss: 0.5442\n",
            "Epoch 20/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7479 - loss: 0.5119 - val_accuracy: 0.7228 - val_loss: 0.5361\n",
            "Epoch 21/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7549 - loss: 0.5183 - val_accuracy: 0.7268 - val_loss: 0.5397\n",
            "Epoch 22/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7512 - loss: 0.5162 - val_accuracy: 0.7268 - val_loss: 0.5366\n",
            "Epoch 23/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7605 - loss: 0.4941 - val_accuracy: 0.7298 - val_loss: 0.5334\n",
            "Epoch 24/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7492 - loss: 0.5145 - val_accuracy: 0.7308 - val_loss: 0.5351\n",
            "Epoch 25/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7461 - loss: 0.5241 - val_accuracy: 0.7288 - val_loss: 0.5355\n",
            "Epoch 26/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7628 - loss: 0.4951 - val_accuracy: 0.7329 - val_loss: 0.5336\n",
            "Epoch 27/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7567 - loss: 0.4964 - val_accuracy: 0.7369 - val_loss: 0.5223\n",
            "Epoch 28/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7549 - loss: 0.5100 - val_accuracy: 0.7480 - val_loss: 0.5195\n",
            "Epoch 29/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7705 - loss: 0.4832 - val_accuracy: 0.7500 - val_loss: 0.5153\n",
            "Epoch 30/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7674 - loss: 0.4883 - val_accuracy: 0.7379 - val_loss: 0.5254\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training complete. Models and results saved.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Conv1D, GlobalMaxPooling1D, Dropout, Input, Flatten, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import joblib\n",
        "import json\n",
        "\n",
        "# Set paths\n",
        "data_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/data.xlsx\"\n",
        "save_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/deep_learning_results_optimized1\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_excel(data_path)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Function to parse vector strings into numpy arrays\n",
        "def parse_vector(vector_str, expected_dim):\n",
        "    try:\n",
        "        if isinstance(vector_str, str):\n",
        "            vec = np.array([float(i) for i in vector_str.strip(\"[]\").split()], dtype=np.float32)\n",
        "            return np.pad(vec, (0, max(0, expected_dim - len(vec))))[:expected_dim]\n",
        "    except:\n",
        "        pass\n",
        "    return np.zeros(expected_dim, dtype=np.float32)\n",
        "\n",
        "# Define expected dimensions\n",
        "embedding_dim = 768\n",
        "\n",
        "# Apply parsing to embeddings\n",
        "df['word2vec_vector'] = df['word2vec_vector'].map(lambda x: parse_vector(x, embedding_dim))\n",
        "df['fasttext_vector'] = df['fasttext_vector'].map(lambda x: parse_vector(x, embedding_dim))\n",
        "df['sentence_embedding'] = df['sentence_embedding'].map(lambda x: parse_vector(x, embedding_dim))\n",
        "df['sinbert_vector'] = df['sinbert_vector'].map(lambda x: parse_vector(x, embedding_dim))\n",
        "\n",
        "# Stack feature vectors\n",
        "X = np.stack(df[['word2vec_vector', 'fasttext_vector', 'sentence_embedding', 'sinbert_vector']].apply(lambda row: np.column_stack(row.values), axis=1).values)\n",
        "X_flattened = X.reshape(X.shape[0], -1)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'].values)\n",
        "joblib.dump(label_encoder, os.path.join(save_path, 'label_encoder.pkl'))\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train_flattened, X_test_flattened = train_test_split(X_flattened, test_size=0.2, random_state=42)\n",
        "\n",
        "# Optimized Model Architectures\n",
        "def build_mlp(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Dense(256, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.4),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_lstm(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        LSTM(128, return_sequences=True),\n",
        "        Dropout(0.4),\n",
        "        LSTM(64),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0003), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_cnn(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Conv1D(128, kernel_size=3, activation='relu'),\n",
        "        Dropout(0.4),\n",
        "        Conv1D(64, kernel_size=3, activation='relu'),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0003), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train and save models\n",
        "models = {\n",
        "    'MLP': build_mlp((X_train_flattened.shape[1],)),\n",
        "    'LSTM': build_lstm((X_train.shape[1], X_train.shape[2])),\n",
        "    'CNN': build_cnn((X_train.shape[1], X_train.shape[2]))\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"Training {name}...\")\n",
        "    if name == 'MLP':\n",
        "        model.fit(X_train_flattened, y_train, epochs=30, batch_size=32, validation_data=(X_test_flattened, y_test), callbacks=[early_stopping], verbose=1)\n",
        "        y_pred = (model.predict(X_test_flattened) > 0.5).astype(int)\n",
        "    else:\n",
        "        model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping], verbose=1)\n",
        "        y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "    # Save the trained model\n",
        "    model.save(os.path.join(save_path, f\"{name}_model.h5\"))\n",
        "\n",
        "    # Evaluate model\n",
        "    results[name] = {\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"precision\": precision_score(y_test, y_pred),\n",
        "        \"recall\": recall_score(y_test, y_pred),\n",
        "        \"f1_score\": f1_score(y_test, y_pred),\n",
        "        \"confusion_matrix\": confusion_matrix(y_test, y_pred).tolist()\n",
        "    }\n",
        "\n",
        "# Save evaluation results\n",
        "with open(os.path.join(save_path, \"model_results.json\"), \"w\") as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n",
        "print(\"Training complete. Models and results saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElGoSWsDZoDQ",
        "outputId": "2c9feb72-6408-4c7a-c154-18a6738f4849"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training MLP...\n",
            "Epoch 1/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.7157 - loss: 0.5598 - val_accuracy: 0.7500 - val_loss: 0.5314\n",
            "Epoch 2/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8133 - loss: 0.4172 - val_accuracy: 0.8105 - val_loss: 0.4517\n",
            "Epoch 3/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8017 - loss: 0.4259 - val_accuracy: 0.8115 - val_loss: 0.4395\n",
            "Epoch 4/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8226 - loss: 0.3900 - val_accuracy: 0.7883 - val_loss: 0.4616\n",
            "Epoch 5/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8364 - loss: 0.3683 - val_accuracy: 0.8095 - val_loss: 0.4340\n",
            "Epoch 6/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8381 - loss: 0.3618 - val_accuracy: 0.8185 - val_loss: 0.4256\n",
            "Epoch 7/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8420 - loss: 0.3592 - val_accuracy: 0.7984 - val_loss: 0.4481\n",
            "Epoch 8/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8425 - loss: 0.3411 - val_accuracy: 0.7984 - val_loss: 0.4374\n",
            "Epoch 9/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8478 - loss: 0.3494 - val_accuracy: 0.8115 - val_loss: 0.4464\n",
            "Epoch 10/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8602 - loss: 0.3266 - val_accuracy: 0.8196 - val_loss: 0.4236\n",
            "Epoch 11/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8538 - loss: 0.3304 - val_accuracy: 0.8246 - val_loss: 0.4296\n",
            "Epoch 12/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8720 - loss: 0.3020 - val_accuracy: 0.7944 - val_loss: 0.5002\n",
            "Epoch 13/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8659 - loss: 0.2938 - val_accuracy: 0.8196 - val_loss: 0.4175\n",
            "Epoch 14/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8627 - loss: 0.3045 - val_accuracy: 0.8024 - val_loss: 0.4899\n",
            "Epoch 15/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8722 - loss: 0.2847 - val_accuracy: 0.8135 - val_loss: 0.4521\n",
            "Epoch 16/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8800 - loss: 0.2795 - val_accuracy: 0.8155 - val_loss: 0.4623\n",
            "Epoch 17/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8753 - loss: 0.2783 - val_accuracy: 0.8115 - val_loss: 0.4612\n",
            "Epoch 18/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8974 - loss: 0.2523 - val_accuracy: 0.7903 - val_loss: 0.5022\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training LSTM...\n",
            "Epoch 1/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.5458 - loss: 0.6849 - val_accuracy: 0.5978 - val_loss: 0.6648\n",
            "Epoch 2/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - accuracy: 0.6267 - loss: 0.6518 - val_accuracy: 0.6532 - val_loss: 0.6368\n",
            "Epoch 3/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.6356 - loss: 0.6482 - val_accuracy: 0.6411 - val_loss: 0.6365\n",
            "Epoch 4/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.6567 - loss: 0.6205 - val_accuracy: 0.6058 - val_loss: 0.6893\n",
            "Epoch 5/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 59ms/step - accuracy: 0.5778 - loss: 0.6855 - val_accuracy: 0.5978 - val_loss: 0.6598\n",
            "Epoch 6/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.6345 - loss: 0.6437 - val_accuracy: 0.6562 - val_loss: 0.6223\n",
            "Epoch 7/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 0.6731 - loss: 0.6097 - val_accuracy: 0.6401 - val_loss: 0.6425\n",
            "Epoch 8/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.6441 - loss: 0.6361 - val_accuracy: 0.6482 - val_loss: 0.6265\n",
            "Epoch 9/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.6769 - loss: 0.6034 - val_accuracy: 0.6633 - val_loss: 0.6129\n",
            "Epoch 10/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.6778 - loss: 0.5996 - val_accuracy: 0.6613 - val_loss: 0.6180\n",
            "Epoch 11/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.6179 - loss: 0.6602 - val_accuracy: 0.6502 - val_loss: 0.6373\n",
            "Epoch 12/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.6602 - loss: 0.6274 - val_accuracy: 0.6552 - val_loss: 0.6314\n",
            "Epoch 13/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 59ms/step - accuracy: 0.6562 - loss: 0.6237 - val_accuracy: 0.6583 - val_loss: 0.6248\n",
            "Epoch 14/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.6619 - loss: 0.6154 - val_accuracy: 0.6754 - val_loss: 0.6101\n",
            "Epoch 15/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.6762 - loss: 0.6088 - val_accuracy: 0.6593 - val_loss: 0.6253\n",
            "Epoch 16/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.6748 - loss: 0.6030 - val_accuracy: 0.6250 - val_loss: 0.6483\n",
            "Epoch 17/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.6520 - loss: 0.6281 - val_accuracy: 0.6542 - val_loss: 0.6310\n",
            "Epoch 18/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.6878 - loss: 0.5952 - val_accuracy: 0.6855 - val_loss: 0.5917\n",
            "Epoch 19/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 0.6964 - loss: 0.5891 - val_accuracy: 0.6875 - val_loss: 0.6030\n",
            "Epoch 20/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.6708 - loss: 0.5991 - val_accuracy: 0.6774 - val_loss: 0.5972\n",
            "Epoch 21/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.6959 - loss: 0.5885 - val_accuracy: 0.6976 - val_loss: 0.5829\n",
            "Epoch 22/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.7156 - loss: 0.5558 - val_accuracy: 0.6855 - val_loss: 0.6038\n",
            "Epoch 23/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 56ms/step - accuracy: 0.7061 - loss: 0.5530 - val_accuracy: 0.6875 - val_loss: 0.5656\n",
            "Epoch 24/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.6683 - loss: 0.5835 - val_accuracy: 0.4688 - val_loss: 0.6950\n",
            "Epoch 25/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.4828 - loss: 0.6954 - val_accuracy: 0.5302 - val_loss: 0.6931\n",
            "Epoch 26/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.4947 - loss: 0.6933 - val_accuracy: 0.5302 - val_loss: 0.6921\n",
            "Epoch 27/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.5044 - loss: 0.6933 - val_accuracy: 0.4708 - val_loss: 0.6937\n",
            "Epoch 28/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 55ms/step - accuracy: 0.4905 - loss: 0.6932 - val_accuracy: 0.4688 - val_loss: 0.6937\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training CNN...\n",
            "Epoch 1/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.5131 - loss: 0.6923 - val_accuracy: 0.6462 - val_loss: 0.6791\n",
            "Epoch 2/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6332 - loss: 0.6765 - val_accuracy: 0.6532 - val_loss: 0.6553\n",
            "Epoch 3/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6730 - loss: 0.6456 - val_accuracy: 0.6754 - val_loss: 0.6152\n",
            "Epoch 4/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7051 - loss: 0.6067 - val_accuracy: 0.6774 - val_loss: 0.5900\n",
            "Epoch 5/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7057 - loss: 0.5862 - val_accuracy: 0.6976 - val_loss: 0.5750\n",
            "Epoch 6/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7154 - loss: 0.5735 - val_accuracy: 0.7117 - val_loss: 0.5631\n",
            "Epoch 7/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7272 - loss: 0.5503 - val_accuracy: 0.7067 - val_loss: 0.5628\n",
            "Epoch 8/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7222 - loss: 0.5539 - val_accuracy: 0.7026 - val_loss: 0.5786\n",
            "Epoch 9/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7220 - loss: 0.5516 - val_accuracy: 0.6996 - val_loss: 0.5777\n",
            "Epoch 10/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7412 - loss: 0.5353 - val_accuracy: 0.7188 - val_loss: 0.5476\n",
            "Epoch 11/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7462 - loss: 0.5362 - val_accuracy: 0.7097 - val_loss: 0.5572\n",
            "Epoch 12/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7260 - loss: 0.5396 - val_accuracy: 0.7188 - val_loss: 0.5453\n",
            "Epoch 13/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7248 - loss: 0.5465 - val_accuracy: 0.7177 - val_loss: 0.5416\n",
            "Epoch 14/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7334 - loss: 0.5292 - val_accuracy: 0.7218 - val_loss: 0.5448\n",
            "Epoch 15/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7481 - loss: 0.5118 - val_accuracy: 0.7097 - val_loss: 0.5599\n",
            "Epoch 16/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7549 - loss: 0.5129 - val_accuracy: 0.7278 - val_loss: 0.5349\n",
            "Epoch 17/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7334 - loss: 0.5216 - val_accuracy: 0.7137 - val_loss: 0.5507\n",
            "Epoch 18/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7446 - loss: 0.5174 - val_accuracy: 0.7137 - val_loss: 0.5526\n",
            "Epoch 19/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7545 - loss: 0.5161 - val_accuracy: 0.7258 - val_loss: 0.5356\n",
            "Epoch 20/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7561 - loss: 0.5130 - val_accuracy: 0.7177 - val_loss: 0.5376\n",
            "Epoch 21/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7439 - loss: 0.5122 - val_accuracy: 0.7369 - val_loss: 0.5265\n",
            "Epoch 22/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7556 - loss: 0.5053 - val_accuracy: 0.7268 - val_loss: 0.5458\n",
            "Epoch 23/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7569 - loss: 0.4988 - val_accuracy: 0.7298 - val_loss: 0.5283\n",
            "Epoch 24/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7598 - loss: 0.4975 - val_accuracy: 0.7308 - val_loss: 0.5432\n",
            "Epoch 25/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7544 - loss: 0.5035 - val_accuracy: 0.7288 - val_loss: 0.5242\n",
            "Epoch 26/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7531 - loss: 0.4985 - val_accuracy: 0.7319 - val_loss: 0.5234\n",
            "Epoch 27/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7532 - loss: 0.5056 - val_accuracy: 0.7359 - val_loss: 0.5351\n",
            "Epoch 28/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7762 - loss: 0.4897 - val_accuracy: 0.7329 - val_loss: 0.5134\n",
            "Epoch 29/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7613 - loss: 0.4917 - val_accuracy: 0.7389 - val_loss: 0.5114\n",
            "Epoch 30/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7531 - loss: 0.4915 - val_accuracy: 0.7450 - val_loss: 0.5175\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training complete. Models and results saved.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Conv1D, GlobalMaxPooling1D, Dropout, Input, Flatten, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import joblib\n",
        "import json\n",
        "\n",
        "# Set paths\n",
        "data_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/data.xlsx\"\n",
        "save_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/deep_learning_results_optimized2\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_excel(data_path)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Function to parse vector strings into numpy arrays\n",
        "def parse_vector(vector_str, expected_dim):\n",
        "    try:\n",
        "        if isinstance(vector_str, str):\n",
        "            vec = np.array([float(i) for i in vector_str.strip(\"[]\").split()], dtype=np.float32)\n",
        "            return np.pad(vec, (0, max(0, expected_dim - len(vec))))[:expected_dim]\n",
        "    except:\n",
        "        pass\n",
        "    return np.zeros(expected_dim, dtype=np.float32)\n",
        "\n",
        "# Define expected dimensions\n",
        "embedding_dim = 768\n",
        "\n",
        "# Apply parsing to embeddings\n",
        "df['word2vec_vector'] = df['word2vec_vector'].map(lambda x: parse_vector(x, embedding_dim))\n",
        "df['fasttext_vector'] = df['fasttext_vector'].map(lambda x: parse_vector(x, embedding_dim))\n",
        "df['sentence_embedding'] = df['sentence_embedding'].map(lambda x: parse_vector(x, embedding_dim))\n",
        "df['sinbert_vector'] = df['sinbert_vector'].map(lambda x: parse_vector(x, embedding_dim))\n",
        "\n",
        "# Stack feature vectors\n",
        "X = np.stack(df[['word2vec_vector', 'fasttext_vector', 'sentence_embedding', 'sinbert_vector']].apply(lambda row: np.column_stack(row.values), axis=1).values)\n",
        "X_flattened = X.reshape(X.shape[0], -1)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'].values)\n",
        "joblib.dump(label_encoder, os.path.join(save_path, 'label_encoder.pkl'))\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train_flattened, X_test_flattened = train_test_split(X_flattened, test_size=0.2, random_state=42)\n",
        "\n",
        "# Optimized Model Architectures\n",
        "def build_mlp(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Dense(256, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.4),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_lstm(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        LSTM(128, return_sequences=True),\n",
        "        Dropout(0.4),\n",
        "        LSTM(64),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0003), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_cnn(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Conv1D(128, kernel_size=3, activation='relu'),\n",
        "        Dropout(0.4),\n",
        "        Conv1D(64, kernel_size=3, activation='relu'),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0003), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train and save models\n",
        "models = {\n",
        "    'MLP': build_mlp((X_train_flattened.shape[1],)),\n",
        "    'LSTM': build_lstm((X_train.shape[1], X_train.shape[2])),\n",
        "    'CNN': build_cnn((X_train.shape[1], X_train.shape[2]))\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"Training {name}...\")\n",
        "    if name == 'MLP':\n",
        "        model.fit(X_train_flattened, y_train, epochs=30, batch_size=32, validation_data=(X_test_flattened, y_test), callbacks=[early_stopping], verbose=1)\n",
        "        y_pred = (model.predict(X_test_flattened) > 0.5).astype(int)\n",
        "    else:\n",
        "        model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping], verbose=1)\n",
        "        y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "    # Save the trained model\n",
        "    model.save(os.path.join(save_path, f\"{name}_model.h5\"))\n",
        "\n",
        "    # Evaluate model\n",
        "    results[name] = {\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"precision\": precision_score(y_test, y_pred),\n",
        "        \"recall\": recall_score(y_test, y_pred),\n",
        "        \"f1_score\": f1_score(y_test, y_pred),\n",
        "        \"confusion_matrix\": confusion_matrix(y_test, y_pred).tolist()\n",
        "    }\n",
        "\n",
        "# Save evaluation results\n",
        "with open(os.path.join(save_path, \"model_results.json\"), \"w\") as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n",
        "print(\"Training complete. Models and results saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvBNUxPGgHOo",
        "outputId": "40c62192-5c2e-4643-f2d1-6b33c08c8999"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training MLP Model...\n",
            "Epoch 1/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.7338 - loss: 0.5284 - val_accuracy: 0.8024 - val_loss: 0.4517 - learning_rate: 7.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7940 - loss: 0.4492 - val_accuracy: 0.7782 - val_loss: 0.4937 - learning_rate: 7.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8088 - loss: 0.4289 - val_accuracy: 0.8004 - val_loss: 0.4371 - learning_rate: 7.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.8113 - loss: 0.4144 - val_accuracy: 0.8135 - val_loss: 0.4236 - learning_rate: 7.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8278 - loss: 0.3868 - val_accuracy: 0.8155 - val_loss: 0.4277 - learning_rate: 7.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.8158 - loss: 0.4040 - val_accuracy: 0.8065 - val_loss: 0.4216 - learning_rate: 7.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8328 - loss: 0.3766 - val_accuracy: 0.7843 - val_loss: 0.4786 - learning_rate: 7.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8386 - loss: 0.3693 - val_accuracy: 0.8085 - val_loss: 0.4296 - learning_rate: 7.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m122/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8361 - loss: 0.3848\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8360 - loss: 0.3847 - val_accuracy: 0.8135 - val_loss: 0.4356 - learning_rate: 7.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8398 - loss: 0.3559 - val_accuracy: 0.8105 - val_loss: 0.4341 - learning_rate: 3.5000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.8433 - loss: 0.3548 - val_accuracy: 0.8095 - val_loss: 0.4601 - learning_rate: 3.5000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m122/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8423 - loss: 0.3461\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.8424 - loss: 0.3460 - val_accuracy: 0.8115 - val_loss: 0.4449 - learning_rate: 3.5000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8493 - loss: 0.3405 - val_accuracy: 0.8226 - val_loss: 0.4478 - learning_rate: 1.7500e-04\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\n",
            "MLP Model Evaluation:\n",
            "Accuracy: 0.8065, F1 Score: 0.7852, ROC-AUC: 0.8034\n",
            "\n",
            "Training LSTM Model...\n",
            "Epoch 1/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 3s/step - accuracy: 0.5541 - loss: 0.6797 - val_accuracy: 0.6089 - val_loss: 0.6569 - learning_rate: 4.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 3s/step - accuracy: 0.6266 - loss: 0.6456 - val_accuracy: 0.6270 - val_loss: 0.6456 - learning_rate: 4.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 3s/step - accuracy: 0.6318 - loss: 0.6308 - val_accuracy: 0.6502 - val_loss: 0.6352 - learning_rate: 4.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 3s/step - accuracy: 0.6384 - loss: 0.6219 - val_accuracy: 0.6502 - val_loss: 0.6190 - learning_rate: 4.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 3s/step - accuracy: 0.6726 - loss: 0.6093 - val_accuracy: 0.6583 - val_loss: 0.6097 - learning_rate: 4.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 3s/step - accuracy: 0.6775 - loss: 0.5980 - val_accuracy: 0.6724 - val_loss: 0.5890 - learning_rate: 4.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 3s/step - accuracy: 0.6845 - loss: 0.5857 - val_accuracy: 0.7077 - val_loss: 0.5651 - learning_rate: 4.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 3s/step - accuracy: 0.7041 - loss: 0.5757 - val_accuracy: 0.7026 - val_loss: 0.5660 - learning_rate: 4.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 3s/step - accuracy: 0.7316 - loss: 0.5447 - val_accuracy: 0.7379 - val_loss: 0.5277 - learning_rate: 4.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 3s/step - accuracy: 0.7214 - loss: 0.5596 - val_accuracy: 0.7298 - val_loss: 0.5269 - learning_rate: 4.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m432s\u001b[0m 3s/step - accuracy: 0.7166 - loss: 0.5527 - val_accuracy: 0.7117 - val_loss: 0.5642 - learning_rate: 4.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 3s/step - accuracy: 0.7201 - loss: 0.5520 - val_accuracy: 0.7288 - val_loss: 0.5259 - learning_rate: 4.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m450s\u001b[0m 3s/step - accuracy: 0.7367 - loss: 0.5294 - val_accuracy: 0.7440 - val_loss: 0.5234 - learning_rate: 4.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m418s\u001b[0m 3s/step - accuracy: 0.7630 - loss: 0.5057 - val_accuracy: 0.7228 - val_loss: 0.5459 - learning_rate: 4.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 3s/step - accuracy: 0.7422 - loss: 0.5190 - val_accuracy: 0.7369 - val_loss: 0.5232 - learning_rate: 4.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 3s/step - accuracy: 0.7452 - loss: 0.5166 - val_accuracy: 0.7480 - val_loss: 0.5184 - learning_rate: 4.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 3s/step - accuracy: 0.7418 - loss: 0.5123 - val_accuracy: 0.7490 - val_loss: 0.5124 - learning_rate: 4.0000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m401s\u001b[0m 3s/step - accuracy: 0.7494 - loss: 0.5044 - val_accuracy: 0.7399 - val_loss: 0.5284 - learning_rate: 4.0000e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 3s/step - accuracy: 0.7535 - loss: 0.5074 - val_accuracy: 0.7500 - val_loss: 0.5127 - learning_rate: 4.0000e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m432s\u001b[0m 3s/step - accuracy: 0.7636 - loss: 0.5026 - val_accuracy: 0.7470 - val_loss: 0.5073 - learning_rate: 4.0000e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 3s/step - accuracy: 0.7578 - loss: 0.4912 - val_accuracy: 0.7450 - val_loss: 0.5149 - learning_rate: 4.0000e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 3s/step - accuracy: 0.7526 - loss: 0.5142 - val_accuracy: 0.7157 - val_loss: 0.5444 - learning_rate: 4.0000e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7595 - loss: 0.5026\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00019999999494757503.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m403s\u001b[0m 3s/step - accuracy: 0.7595 - loss: 0.5026 - val_accuracy: 0.7460 - val_loss: 0.5167 - learning_rate: 4.0000e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 3s/step - accuracy: 0.7622 - loss: 0.4950 - val_accuracy: 0.7419 - val_loss: 0.5177 - learning_rate: 2.0000e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m452s\u001b[0m 3s/step - accuracy: 0.7544 - loss: 0.4963 - val_accuracy: 0.7419 - val_loss: 0.5111 - learning_rate: 2.0000e-04\n",
            "Epoch 26/30\n",
            "\u001b[1m 31/124\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:22\u001b[0m 3s/step - accuracy: 0.7944 - loss: 0.4512"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Conv1D, GlobalMaxPooling1D, Dropout, Input, BatchNormalization, LayerNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
        "import joblib\n",
        "import json\n",
        "\n",
        "# Enable mixed precision for speed improvement\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Set paths\n",
        "data_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/data.xlsx\"\n",
        "save_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/deep_learning_results_optimized3\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_excel(data_path).dropna()\n",
        "\n",
        "# Function to parse vector strings into numpy arrays\n",
        "def parse_vector(vector_str, expected_dim=768):\n",
        "    if isinstance(vector_str, str):\n",
        "        try:\n",
        "            vec = np.array([float(i) for i in vector_str.strip(\"[]\").split()], dtype=np.float32)\n",
        "            return np.pad(vec, (0, max(0, expected_dim - len(vec))))[:expected_dim]\n",
        "        except ValueError:\n",
        "            pass\n",
        "    return np.zeros(expected_dim, dtype=np.float32)\n",
        "\n",
        "# Define embedding dimension\n",
        "embedding_dim = 768\n",
        "\n",
        "# Convert embeddings into arrays\n",
        "embedding_features = ['word2vec_vector', 'fasttext_vector', 'sentence_embedding', 'sinbert_vector']\n",
        "for feature in embedding_features:\n",
        "    df[feature] = df[feature].map(lambda x: parse_vector(x, embedding_dim))\n",
        "\n",
        "# Stack feature vectors efficiently\n",
        "X = np.stack(df[embedding_features].apply(lambda row: np.column_stack(row.values), axis=1).values)\n",
        "X_flattened = X.reshape(X.shape[0], -1)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'].values)\n",
        "joblib.dump(label_encoder, os.path.join(save_path, 'label_encoder.pkl'))\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train_flattened, X_test_flattened = train_test_split(X_flattened, test_size=0.2, random_state=42)\n",
        "\n",
        "# Optimized Model Architectures\n",
        "def build_mlp(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Dense(256, activation='relu'),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0007), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_lstm(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        LSTM(128, return_sequences=True),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.3),\n",
        "        LSTM(64),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0004), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_cnn(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Conv1D(128, kernel_size=3, activation='relu'),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Conv1D(64, kernel_size=3, activation='relu'),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0004), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Callbacks for training efficiency\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
        "\n",
        "# Train and save models\n",
        "models = {\n",
        "    'MLP': build_mlp((X_train_flattened.shape[1],)),\n",
        "    'LSTM': build_lstm((X_train.shape[1], X_train.shape[2])),\n",
        "    'CNN': build_cnn((X_train.shape[1], X_train.shape[2]))\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name} Model...\")\n",
        "\n",
        "    if name == 'MLP':\n",
        "        history = model.fit(\n",
        "            X_train_flattened, y_train,\n",
        "            epochs=30, batch_size=32, validation_data=(X_test_flattened, y_test),\n",
        "            callbacks=[early_stopping, reduce_lr], verbose=1\n",
        "        )\n",
        "        y_pred = (model.predict(X_test_flattened) > 0.5).astype(int)\n",
        "    else:\n",
        "        history = model.fit(\n",
        "            X_train, y_train,\n",
        "            epochs=30, batch_size=32, validation_data=(X_test, y_test),\n",
        "            callbacks=[early_stopping, reduce_lr], verbose=1\n",
        "        )\n",
        "        y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "    # Save the trained model using TensorFlow's SavedModel format\n",
        "    model.save(os.path.join(save_path, f\"{name}_model.keras\"))\n",
        "\n",
        "    # Evaluate model performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred).tolist()\n",
        "\n",
        "    results[name] = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"confusion_matrix\": cm\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{name} Model Evaluation:\\nAccuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
        "\n",
        "# Save evaluation results\n",
        "with open(os.path.join(save_path, \"model_results.json\"), \"w\") as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n",
        "# Save results in CSV format for easy analysis\n",
        "pd.DataFrame(results).T.to_csv(os.path.join(save_path, \"model_results.csv\"), index=True)\n",
        "\n",
        "print(\"\\nTraining complete. Models and results saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6ApeA_GXdEl",
        "outputId": "61ceb235-d962-4b64-92a9-ea326d8dd60b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training MLP Model...\n",
            "Epoch 1/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - accuracy: 0.7186 - loss: 0.5595 - val_accuracy: 0.7823 - val_loss: 0.4663 - learning_rate: 7.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.7904 - loss: 0.4532 - val_accuracy: 0.8044 - val_loss: 0.4461 - learning_rate: 7.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.7881 - loss: 0.4422 - val_accuracy: 0.8054 - val_loss: 0.4405 - learning_rate: 7.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.8049 - loss: 0.4197 - val_accuracy: 0.7994 - val_loss: 0.4823 - learning_rate: 7.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.8167 - loss: 0.4096 - val_accuracy: 0.8085 - val_loss: 0.4444 - learning_rate: 7.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8255 - loss: 0.3893 - val_accuracy: 0.8135 - val_loss: 0.4271 - learning_rate: 7.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8292 - loss: 0.3830 - val_accuracy: 0.8085 - val_loss: 0.4376 - learning_rate: 7.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8262 - loss: 0.3751 - val_accuracy: 0.8105 - val_loss: 0.4476 - learning_rate: 7.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.8336 - loss: 0.3688 - val_accuracy: 0.8246 - val_loss: 0.4207 - learning_rate: 7.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.8294 - loss: 0.3775 - val_accuracy: 0.8085 - val_loss: 0.4416 - learning_rate: 7.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8435 - loss: 0.3494 - val_accuracy: 0.8135 - val_loss: 0.4310 - learning_rate: 7.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m122/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8438 - loss: 0.3578\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8437 - loss: 0.3580 - val_accuracy: 0.8125 - val_loss: 0.4356 - learning_rate: 7.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.8423 - loss: 0.3419 - val_accuracy: 0.8196 - val_loss: 0.4466 - learning_rate: 3.5000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.8630 - loss: 0.3149 - val_accuracy: 0.8196 - val_loss: 0.4635 - learning_rate: 3.5000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m123/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8652 - loss: 0.3147\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.8652 - loss: 0.3147 - val_accuracy: 0.8206 - val_loss: 0.4879 - learning_rate: 3.5000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.8690 - loss: 0.2931 - val_accuracy: 0.8246 - val_loss: 0.4578 - learning_rate: 1.7500e-04\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\n",
            "MLP Model Evaluation:\n",
            "Accuracy: 0.8246, F1 Score: 0.8027, ROC-AUC: 0.8209\n",
            "\n",
            "Training LSTM Model...\n",
            "Epoch 1/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 3s/step - accuracy: 0.5464 - loss: 0.6816 - val_accuracy: 0.5907 - val_loss: 0.6710 - learning_rate: 4.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 3s/step - accuracy: 0.6414 - loss: 0.6327 - val_accuracy: 0.6613 - val_loss: 0.6209 - learning_rate: 4.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 3s/step - accuracy: 0.6411 - loss: 0.6274 - val_accuracy: 0.6472 - val_loss: 0.6244 - learning_rate: 4.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 3s/step - accuracy: 0.6762 - loss: 0.6044 - val_accuracy: 0.6704 - val_loss: 0.6008 - learning_rate: 4.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m 45/124\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3:36\u001b[0m 3s/step - accuracy: 0.6899 - loss: 0.5955"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Conv1D, GlobalMaxPooling1D, Dropout, Input, BatchNormalization, LayerNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
        "import joblib\n",
        "import json\n",
        "\n",
        "# Enable mixed precision for speed improvement\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Set paths\n",
        "data_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/data.xlsx\"\n",
        "save_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/deep_learning_results_optimized4\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_excel(data_path).dropna()\n",
        "\n",
        "# Function to parse vector strings into numpy arrays\n",
        "def parse_vector(vector_str, expected_dim=768):\n",
        "    if isinstance(vector_str, str):\n",
        "        try:\n",
        "            vec = np.array([float(i) for i in vector_str.strip(\"[]\").split()], dtype=np.float32)\n",
        "            return np.pad(vec, (0, max(0, expected_dim - len(vec))))[:expected_dim]\n",
        "        except ValueError:\n",
        "            pass\n",
        "    return np.zeros(expected_dim, dtype=np.float32)\n",
        "\n",
        "# Define embedding dimension\n",
        "embedding_dim = 768\n",
        "\n",
        "# Convert embeddings into arrays\n",
        "embedding_features = ['word2vec_vector', 'fasttext_vector', 'sentence_embedding', 'sinbert_vector']\n",
        "for feature in embedding_features:\n",
        "    df[feature] = df[feature].map(lambda x: parse_vector(x, embedding_dim))\n",
        "\n",
        "# Stack feature vectors efficiently\n",
        "X = np.stack(df[embedding_features].apply(lambda row: np.column_stack(row.values), axis=1).values)\n",
        "X_flattened = X.reshape(X.shape[0], -1)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'].values)\n",
        "joblib.dump(label_encoder, os.path.join(save_path, 'label_encoder.pkl'))\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train_flattened, X_test_flattened = train_test_split(X_flattened, test_size=0.2, random_state=42)\n",
        "\n",
        "# Optimized Model Architectures\n",
        "def build_mlp(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Dense(256, activation='relu'),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0007), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_lstm(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        LSTM(128, return_sequences=True),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.3),\n",
        "        LSTM(64),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0004), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_cnn(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Conv1D(128, kernel_size=3, activation='relu'),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Conv1D(64, kernel_size=3, activation='relu'),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0004), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Callbacks for training efficiency\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
        "\n",
        "# Train and save models\n",
        "models = {\n",
        "    'MLP': build_mlp((X_train_flattened.shape[1],)),\n",
        "    'LSTM': build_lstm((X_train.shape[1], X_train.shape[2])),\n",
        "    'CNN': build_cnn((X_train.shape[1], X_train.shape[2]))\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name} Model...\")\n",
        "\n",
        "    if name == 'MLP':\n",
        "        history = model.fit(\n",
        "            X_train_flattened, y_train,\n",
        "            epochs=30, batch_size=32, validation_data=(X_test_flattened, y_test),\n",
        "            callbacks=[early_stopping, reduce_lr], verbose=1\n",
        "        )\n",
        "        y_pred = (model.predict(X_test_flattened) > 0.5).astype(int)\n",
        "    else:\n",
        "        history = model.fit(\n",
        "            X_train, y_train,\n",
        "            epochs=30, batch_size=32, validation_data=(X_test, y_test),\n",
        "            callbacks=[early_stopping, reduce_lr], verbose=1\n",
        "        )\n",
        "        y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "    # Save the trained model using TensorFlow's SavedModel format\n",
        "    model.save(os.path.join(save_path, f\"{name}_model.keras\"))\n",
        "\n",
        "    # Evaluate model performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred).tolist()\n",
        "\n",
        "    results[name] = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"confusion_matrix\": cm\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{name} Model Evaluation:\\nAccuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
        "\n",
        "# Save evaluation results\n",
        "with open(os.path.join(save_path, \"model_results.json\"), \"w\") as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n",
        "# Save results in CSV format for easy analysis\n",
        "pd.DataFrame(results).T.to_csv(os.path.join(save_path, \"model_results.csv\"), index=True)\n",
        "\n",
        "print(\"\\nTraining complete. Models and results saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPqV2faxdTcZ",
        "outputId": "926e206c-c4d1-4fc3-c0c4-010327b6f992"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training MLP Model...\n",
            "Epoch 1/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - accuracy: 0.7322 - loss: 0.5567 - val_accuracy: 0.7661 - val_loss: 0.4933 - learning_rate: 7.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7872 - loss: 0.4532 - val_accuracy: 0.8125 - val_loss: 0.4495 - learning_rate: 7.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7983 - loss: 0.4433 - val_accuracy: 0.8034 - val_loss: 0.4318 - learning_rate: 7.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8041 - loss: 0.4295 - val_accuracy: 0.8095 - val_loss: 0.4306 - learning_rate: 7.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8190 - loss: 0.4127 - val_accuracy: 0.8125 - val_loss: 0.4364 - learning_rate: 7.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8234 - loss: 0.4100 - val_accuracy: 0.7984 - val_loss: 0.4403 - learning_rate: 7.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m118/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8183 - loss: 0.4035\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8182 - loss: 0.4033 - val_accuracy: 0.8004 - val_loss: 0.4338 - learning_rate: 7.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8333 - loss: 0.3736 - val_accuracy: 0.8185 - val_loss: 0.4445 - learning_rate: 3.5000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8283 - loss: 0.3728 - val_accuracy: 0.8135 - val_loss: 0.4327 - learning_rate: 3.5000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m114/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8481 - loss: 0.3430\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8477 - loss: 0.3437 - val_accuracy: 0.7883 - val_loss: 0.4843 - learning_rate: 3.5000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8300 - loss: 0.3694 - val_accuracy: 0.8115 - val_loss: 0.4465 - learning_rate: 1.7500e-04\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "\n",
            "MLP Model Evaluation:\n",
            "Accuracy: 0.8095, F1 Score: 0.7907, ROC-AUC: 0.8070\n",
            "\n",
            "Training LSTM Model...\n",
            "Epoch 1/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 60ms/step - accuracy: 0.5501 - loss: 0.6822 - val_accuracy: 0.6331 - val_loss: 0.6487 - learning_rate: 4.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 49ms/step - accuracy: 0.6327 - loss: 0.6411 - val_accuracy: 0.6240 - val_loss: 0.6396 - learning_rate: 4.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.6466 - loss: 0.6284 - val_accuracy: 0.6502 - val_loss: 0.6271 - learning_rate: 4.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - accuracy: 0.6615 - loss: 0.6251 - val_accuracy: 0.6512 - val_loss: 0.6239 - learning_rate: 4.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.6642 - loss: 0.6124 - val_accuracy: 0.6573 - val_loss: 0.6085 - learning_rate: 4.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.6798 - loss: 0.6066 - val_accuracy: 0.6794 - val_loss: 0.5979 - learning_rate: 4.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.6997 - loss: 0.5818 - val_accuracy: 0.6724 - val_loss: 0.5983 - learning_rate: 4.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.7088 - loss: 0.5622 - val_accuracy: 0.7006 - val_loss: 0.5652 - learning_rate: 4.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.7170 - loss: 0.5485 - val_accuracy: 0.6986 - val_loss: 0.5585 - learning_rate: 4.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 62ms/step - accuracy: 0.7147 - loss: 0.5587 - val_accuracy: 0.7319 - val_loss: 0.5237 - learning_rate: 4.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.7292 - loss: 0.5364 - val_accuracy: 0.7248 - val_loss: 0.5438 - learning_rate: 4.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.7299 - loss: 0.5292 - val_accuracy: 0.7288 - val_loss: 0.5273 - learning_rate: 4.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7373 - loss: 0.5335\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00019999999494757503.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.7372 - loss: 0.5335 - val_accuracy: 0.7137 - val_loss: 0.5575 - learning_rate: 4.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.7384 - loss: 0.5209 - val_accuracy: 0.7208 - val_loss: 0.5264 - learning_rate: 2.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.7417 - loss: 0.5228 - val_accuracy: 0.7440 - val_loss: 0.5212 - learning_rate: 2.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.7433 - loss: 0.5208 - val_accuracy: 0.7268 - val_loss: 0.5345 - learning_rate: 2.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.7488 - loss: 0.5161 - val_accuracy: 0.7288 - val_loss: 0.5245 - learning_rate: 2.0000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7416 - loss: 0.5196\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 49ms/step - accuracy: 0.7416 - loss: 0.5195 - val_accuracy: 0.7409 - val_loss: 0.5252 - learning_rate: 2.0000e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.7550 - loss: 0.5015 - val_accuracy: 0.7480 - val_loss: 0.5209 - learning_rate: 1.0000e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.7537 - loss: 0.5017 - val_accuracy: 0.7510 - val_loss: 0.5252 - learning_rate: 1.0000e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.7610 - loss: 0.5011 - val_accuracy: 0.7480 - val_loss: 0.5193 - learning_rate: 1.0000e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 59ms/step - accuracy: 0.7663 - loss: 0.5006 - val_accuracy: 0.7460 - val_loss: 0.5171 - learning_rate: 1.0000e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.7649 - loss: 0.4902 - val_accuracy: 0.7510 - val_loss: 0.5181 - learning_rate: 1.0000e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.7616 - loss: 0.5019 - val_accuracy: 0.7450 - val_loss: 0.5232 - learning_rate: 1.0000e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m123/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7620 - loss: 0.4894\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.7619 - loss: 0.4896 - val_accuracy: 0.7550 - val_loss: 0.5189 - learning_rate: 1.0000e-04\n",
            "Epoch 26/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.7684 - loss: 0.4860 - val_accuracy: 0.7490 - val_loss: 0.5176 - learning_rate: 5.0000e-05\n",
            "Epoch 27/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - accuracy: 0.7592 - loss: 0.4913 - val_accuracy: 0.7470 - val_loss: 0.5201 - learning_rate: 5.0000e-05\n",
            "Epoch 28/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.7584 - loss: 0.4947 - val_accuracy: 0.7480 - val_loss: 0.5165 - learning_rate: 5.0000e-05\n",
            "Epoch 29/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.7593 - loss: 0.4991 - val_accuracy: 0.7450 - val_loss: 0.5205 - learning_rate: 5.0000e-05\n",
            "Epoch 30/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.7683 - loss: 0.4821 - val_accuracy: 0.7500 - val_loss: 0.5156 - learning_rate: 5.0000e-05\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
            "\n",
            "LSTM Model Evaluation:\n",
            "Accuracy: 0.7500, F1 Score: 0.7019, ROC-AUC: 0.7430\n",
            "\n",
            "Training CNN Model...\n",
            "Epoch 1/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.5415 - loss: 0.7244 - val_accuracy: 0.5252 - val_loss: 0.6704 - learning_rate: 4.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6456 - loss: 0.6441 - val_accuracy: 0.7127 - val_loss: 0.5742 - learning_rate: 4.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6782 - loss: 0.6005 - val_accuracy: 0.6744 - val_loss: 0.6073 - learning_rate: 4.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6941 - loss: 0.5815 - val_accuracy: 0.7228 - val_loss: 0.5338 - learning_rate: 4.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7246 - loss: 0.5527 - val_accuracy: 0.7329 - val_loss: 0.5232 - learning_rate: 4.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7274 - loss: 0.5455 - val_accuracy: 0.7137 - val_loss: 0.5590 - learning_rate: 4.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7396 - loss: 0.5240 - val_accuracy: 0.7409 - val_loss: 0.5128 - learning_rate: 4.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7443 - loss: 0.5101 - val_accuracy: 0.7429 - val_loss: 0.5127 - learning_rate: 4.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7493 - loss: 0.5203 - val_accuracy: 0.7399 - val_loss: 0.5108 - learning_rate: 4.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7538 - loss: 0.4946 - val_accuracy: 0.7611 - val_loss: 0.4977 - learning_rate: 4.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7460 - loss: 0.4990 - val_accuracy: 0.7681 - val_loss: 0.4907 - learning_rate: 4.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7647 - loss: 0.4910 - val_accuracy: 0.7611 - val_loss: 0.4956 - learning_rate: 4.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7656 - loss: 0.4840 - val_accuracy: 0.7621 - val_loss: 0.4836 - learning_rate: 4.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7645 - loss: 0.4828 - val_accuracy: 0.7601 - val_loss: 0.4868 - learning_rate: 4.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7746 - loss: 0.4628 - val_accuracy: 0.7671 - val_loss: 0.4823 - learning_rate: 4.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7701 - loss: 0.4720 - val_accuracy: 0.7591 - val_loss: 0.4832 - learning_rate: 4.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7808 - loss: 0.4596 - val_accuracy: 0.7802 - val_loss: 0.4758 - learning_rate: 4.0000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7788 - loss: 0.4626 - val_accuracy: 0.7772 - val_loss: 0.4766 - learning_rate: 4.0000e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7895 - loss: 0.4630 - val_accuracy: 0.7752 - val_loss: 0.4748 - learning_rate: 4.0000e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7894 - loss: 0.4458 - val_accuracy: 0.7792 - val_loss: 0.4707 - learning_rate: 4.0000e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7855 - loss: 0.4563 - val_accuracy: 0.7641 - val_loss: 0.4852 - learning_rate: 4.0000e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7765 - loss: 0.4576 - val_accuracy: 0.7812 - val_loss: 0.4693 - learning_rate: 4.0000e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7995 - loss: 0.4438 - val_accuracy: 0.7742 - val_loss: 0.4717 - learning_rate: 4.0000e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7828 - loss: 0.4530 - val_accuracy: 0.7833 - val_loss: 0.4693 - learning_rate: 4.0000e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7705 - loss: 0.4637 - val_accuracy: 0.7843 - val_loss: 0.4681 - learning_rate: 4.0000e-04\n",
            "Epoch 26/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7891 - loss: 0.4378 - val_accuracy: 0.7833 - val_loss: 0.4675 - learning_rate: 4.0000e-04\n",
            "Epoch 27/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8012 - loss: 0.4263 - val_accuracy: 0.7752 - val_loss: 0.4760 - learning_rate: 4.0000e-04\n",
            "Epoch 28/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8018 - loss: 0.4253 - val_accuracy: 0.7712 - val_loss: 0.4771 - learning_rate: 4.0000e-04\n",
            "Epoch 29/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7950 - loss: 0.4407 - val_accuracy: 0.7823 - val_loss: 0.4610 - learning_rate: 4.0000e-04\n",
            "Epoch 30/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8216 - loss: 0.4063 - val_accuracy: 0.7560 - val_loss: 0.5121 - learning_rate: 4.0000e-04\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step   \n",
            "\n",
            "CNN Model Evaluation:\n",
            "Accuracy: 0.7823, F1 Score: 0.7584, ROC-AUC: 0.7791\n",
            "\n",
            "Training complete. Models and results saved.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Conv1D, GlobalMaxPooling1D, Dropout, Input, BatchNormalization, LayerNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
        "import joblib\n",
        "import json\n",
        "\n",
        "# Enable mixed precision for speed improvement\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Set paths\n",
        "data_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/data.xlsx\"\n",
        "save_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/deep_learning_results_optimized5\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_excel(data_path).dropna()\n",
        "\n",
        "# Function to parse vector strings into numpy arrays\n",
        "def parse_vector(vector_str, expected_dim=768):\n",
        "    if isinstance(vector_str, str):\n",
        "        try:\n",
        "            vec = np.array([float(i) for i in vector_str.strip(\"[]\").split()], dtype=np.float32)\n",
        "            return np.pad(vec, (0, max(0, expected_dim - len(vec))))[:expected_dim]\n",
        "        except ValueError:\n",
        "            pass\n",
        "    return np.zeros(expected_dim, dtype=np.float32)\n",
        "\n",
        "# Define embedding dimension\n",
        "embedding_dim = 768\n",
        "\n",
        "# Convert embeddings into arrays\n",
        "embedding_features = ['word2vec_vector', 'fasttext_vector', 'sentence_embedding', 'sinbert_vector']\n",
        "for feature in embedding_features:\n",
        "    df[feature] = df[feature].map(lambda x: parse_vector(x, embedding_dim))\n",
        "\n",
        "# Stack feature vectors efficiently\n",
        "X = np.stack(df[embedding_features].apply(lambda row: np.column_stack(row.values), axis=1).values)\n",
        "X_flattened = X.reshape(X.shape[0], -1)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'].values)\n",
        "joblib.dump(label_encoder, os.path.join(save_path, 'label_encoder.pkl'))\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train_flattened, X_test_flattened = train_test_split(X_flattened, test_size=0.2, random_state=42)\n",
        "\n",
        "# Optimized Model Architectures\n",
        "def build_mlp(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Dense(256, activation='relu'),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0007), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_lstm(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        LSTM(128, return_sequences=True),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.3),\n",
        "        LSTM(64),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0004), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_cnn(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Conv1D(128, kernel_size=3, activation='relu'),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Conv1D(64, kernel_size=3, activation='relu'),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0004), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Callbacks for training efficiency\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
        "\n",
        "# Train and save models\n",
        "models = {\n",
        "    'MLP': build_mlp((X_train_flattened.shape[1],)),\n",
        "    'LSTM': build_lstm((X_train.shape[1], X_train.shape[2])),\n",
        "    'CNN': build_cnn((X_train.shape[1], X_train.shape[2]))\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name} Model...\")\n",
        "\n",
        "    if name == 'MLP':\n",
        "        history = model.fit(\n",
        "            X_train_flattened, y_train,\n",
        "            epochs=30, batch_size=32, validation_data=(X_test_flattened, y_test),\n",
        "            callbacks=[early_stopping, reduce_lr], verbose=1\n",
        "        )\n",
        "        y_pred = (model.predict(X_test_flattened) > 0.5).astype(int)\n",
        "    else:\n",
        "        history = model.fit(\n",
        "            X_train, y_train,\n",
        "            epochs=30, batch_size=32, validation_data=(X_test, y_test),\n",
        "            callbacks=[early_stopping, reduce_lr], verbose=1\n",
        "        )\n",
        "        y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "    # Save the trained model using TensorFlow's SavedModel format\n",
        "    model.save(os.path.join(save_path, f\"{name}_model.keras\"))\n",
        "\n",
        "    # Evaluate model performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred).tolist()\n",
        "\n",
        "    results[name] = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"confusion_matrix\": cm\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{name} Model Evaluation:\\nAccuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
        "\n",
        "# Save evaluation results\n",
        "with open(os.path.join(save_path, \"model_results.json\"), \"w\") as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n",
        "# Save results in CSV format for easy analysis\n",
        "pd.DataFrame(results).T.to_csv(os.path.join(save_path, \"model_results.csv\"), index=True)\n",
        "\n",
        "print(\"\\nTraining complete. Models and results saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQMCeNiygZ_v",
        "outputId": "7c831f47-6e84-44b8-80c5-5b3cd50d368a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training MLP Model...\n",
            "Epoch 1/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.7012 - loss: 0.6013 - val_accuracy: 0.6956 - val_loss: 0.5470 - learning_rate: 7.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7943 - loss: 0.4382 - val_accuracy: 0.7692 - val_loss: 0.4774 - learning_rate: 7.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8084 - loss: 0.4337 - val_accuracy: 0.7923 - val_loss: 0.4729 - learning_rate: 7.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8121 - loss: 0.4016 - val_accuracy: 0.8034 - val_loss: 0.4520 - learning_rate: 7.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8256 - loss: 0.3939 - val_accuracy: 0.8165 - val_loss: 0.4385 - learning_rate: 7.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8171 - loss: 0.3980 - val_accuracy: 0.8054 - val_loss: 0.4375 - learning_rate: 7.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8358 - loss: 0.3703 - val_accuracy: 0.7923 - val_loss: 0.4446 - learning_rate: 7.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8207 - loss: 0.3879 - val_accuracy: 0.8196 - val_loss: 0.4256 - learning_rate: 7.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8326 - loss: 0.3860 - val_accuracy: 0.8054 - val_loss: 0.4329 - learning_rate: 7.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8372 - loss: 0.3627 - val_accuracy: 0.7843 - val_loss: 0.5069 - learning_rate: 7.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8260 - loss: 0.3746 - val_accuracy: 0.8196 - val_loss: 0.4253 - learning_rate: 7.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8429 - loss: 0.3524 - val_accuracy: 0.8185 - val_loss: 0.4255 - learning_rate: 7.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8395 - loss: 0.3616 - val_accuracy: 0.7974 - val_loss: 0.4748 - learning_rate: 7.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m119/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.3491\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8439 - loss: 0.3491 - val_accuracy: 0.7994 - val_loss: 0.4528 - learning_rate: 7.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8568 - loss: 0.3252 - val_accuracy: 0.8206 - val_loss: 0.4471 - learning_rate: 3.5000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8667 - loss: 0.3141 - val_accuracy: 0.8185 - val_loss: 0.4429 - learning_rate: 3.5000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m119/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8703 - loss: 0.3081\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8702 - loss: 0.3078 - val_accuracy: 0.8165 - val_loss: 0.4732 - learning_rate: 3.5000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8768 - loss: 0.2762 - val_accuracy: 0.8175 - val_loss: 0.4510 - learning_rate: 1.7500e-04\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "\n",
            "MLP Model Evaluation:\n",
            "Accuracy: 0.8196, F1 Score: 0.7973, ROC-AUC: 0.8159\n",
            "\n",
            "Training LSTM Model...\n",
            "Epoch 1/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.5800 - loss: 0.6718 - val_accuracy: 0.6200 - val_loss: 0.6498 - learning_rate: 4.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.6348 - loss: 0.6387 - val_accuracy: 0.5696 - val_loss: 0.7059 - learning_rate: 4.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - accuracy: 0.6404 - loss: 0.6379 - val_accuracy: 0.6391 - val_loss: 0.6238 - learning_rate: 4.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.6502 - loss: 0.6184 - val_accuracy: 0.6623 - val_loss: 0.6082 - learning_rate: 4.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.6754 - loss: 0.5943 - val_accuracy: 0.6774 - val_loss: 0.5897 - learning_rate: 4.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.7016 - loss: 0.5795 - val_accuracy: 0.6905 - val_loss: 0.5833 - learning_rate: 4.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.7061 - loss: 0.5640 - val_accuracy: 0.7177 - val_loss: 0.5501 - learning_rate: 4.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.6970 - loss: 0.5798 - val_accuracy: 0.7218 - val_loss: 0.5407 - learning_rate: 4.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 0.7052 - loss: 0.5577 - val_accuracy: 0.7026 - val_loss: 0.5621 - learning_rate: 4.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.7201 - loss: 0.5550 - val_accuracy: 0.7278 - val_loss: 0.5351 - learning_rate: 4.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 56ms/step - accuracy: 0.7134 - loss: 0.5515 - val_accuracy: 0.7379 - val_loss: 0.5288 - learning_rate: 4.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.7388 - loss: 0.5309 - val_accuracy: 0.7339 - val_loss: 0.5317 - learning_rate: 4.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.7447 - loss: 0.5236 - val_accuracy: 0.7450 - val_loss: 0.5201 - learning_rate: 4.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 61ms/step - accuracy: 0.7451 - loss: 0.5279 - val_accuracy: 0.7228 - val_loss: 0.5353 - learning_rate: 4.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.7483 - loss: 0.5148 - val_accuracy: 0.7006 - val_loss: 0.5628 - learning_rate: 4.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m123/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7338 - loss: 0.5215\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00019999999494757503.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.7340 - loss: 0.5214 - val_accuracy: 0.7167 - val_loss: 0.5450 - learning_rate: 4.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.7432 - loss: 0.5242 - val_accuracy: 0.7389 - val_loss: 0.5110 - learning_rate: 2.0000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.7524 - loss: 0.5102 - val_accuracy: 0.7369 - val_loss: 0.5246 - learning_rate: 2.0000e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.7507 - loss: 0.4930 - val_accuracy: 0.7268 - val_loss: 0.5361 - learning_rate: 2.0000e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7604 - loss: 0.4967\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 62ms/step - accuracy: 0.7603 - loss: 0.4967 - val_accuracy: 0.7419 - val_loss: 0.5213 - learning_rate: 2.0000e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.7534 - loss: 0.5004 - val_accuracy: 0.7550 - val_loss: 0.5103 - learning_rate: 1.0000e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 61ms/step - accuracy: 0.7637 - loss: 0.4907 - val_accuracy: 0.7359 - val_loss: 0.5209 - learning_rate: 1.0000e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.7745 - loss: 0.4805 - val_accuracy: 0.7470 - val_loss: 0.5139 - learning_rate: 1.0000e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m123/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7625 - loss: 0.4896\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - accuracy: 0.7625 - loss: 0.4896 - val_accuracy: 0.7409 - val_loss: 0.5120 - learning_rate: 1.0000e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.7561 - loss: 0.4909 - val_accuracy: 0.7440 - val_loss: 0.5076 - learning_rate: 5.0000e-05\n",
            "Epoch 26/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.7780 - loss: 0.4689 - val_accuracy: 0.7530 - val_loss: 0.5061 - learning_rate: 5.0000e-05\n",
            "Epoch 27/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.7615 - loss: 0.4894 - val_accuracy: 0.7500 - val_loss: 0.5090 - learning_rate: 5.0000e-05\n",
            "Epoch 28/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 64ms/step - accuracy: 0.7819 - loss: 0.4759 - val_accuracy: 0.7510 - val_loss: 0.5074 - learning_rate: 5.0000e-05\n",
            "Epoch 29/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 53ms/step - accuracy: 0.7691 - loss: 0.4803 - val_accuracy: 0.7500 - val_loss: 0.5041 - learning_rate: 5.0000e-05\n",
            "Epoch 30/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step - accuracy: 0.7784 - loss: 0.4751 - val_accuracy: 0.7490 - val_loss: 0.5059 - learning_rate: 5.0000e-05\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
            "\n",
            "LSTM Model Evaluation:\n",
            "Accuracy: 0.7500, F1 Score: 0.7162, ROC-AUC: 0.7455\n",
            "\n",
            "Training CNN Model...\n",
            "Epoch 1/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.5167 - loss: 0.7191 - val_accuracy: 0.5444 - val_loss: 0.6653 - learning_rate: 4.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6038 - loss: 0.6542 - val_accuracy: 0.7006 - val_loss: 0.5892 - learning_rate: 4.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6618 - loss: 0.6137 - val_accuracy: 0.6472 - val_loss: 0.6567 - learning_rate: 4.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7058 - loss: 0.5795 - val_accuracy: 0.7238 - val_loss: 0.5407 - learning_rate: 4.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7203 - loss: 0.5431 - val_accuracy: 0.7298 - val_loss: 0.5071 - learning_rate: 4.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7448 - loss: 0.5257 - val_accuracy: 0.7440 - val_loss: 0.5006 - learning_rate: 4.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7342 - loss: 0.5315 - val_accuracy: 0.7419 - val_loss: 0.5216 - learning_rate: 4.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7440 - loss: 0.5165 - val_accuracy: 0.7470 - val_loss: 0.5143 - learning_rate: 4.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7502 - loss: 0.5103 - val_accuracy: 0.7470 - val_loss: 0.4974 - learning_rate: 4.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7539 - loss: 0.5104 - val_accuracy: 0.7591 - val_loss: 0.4838 - learning_rate: 4.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7584 - loss: 0.4982 - val_accuracy: 0.7611 - val_loss: 0.4820 - learning_rate: 4.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7628 - loss: 0.4768 - val_accuracy: 0.7611 - val_loss: 0.4758 - learning_rate: 4.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7656 - loss: 0.4792 - val_accuracy: 0.7641 - val_loss: 0.4763 - learning_rate: 4.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7723 - loss: 0.4834 - val_accuracy: 0.7631 - val_loss: 0.4922 - learning_rate: 4.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7678 - loss: 0.4808 - val_accuracy: 0.7802 - val_loss: 0.4694 - learning_rate: 4.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7716 - loss: 0.4676 - val_accuracy: 0.7681 - val_loss: 0.4938 - learning_rate: 4.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7635 - loss: 0.4904 - val_accuracy: 0.7782 - val_loss: 0.4653 - learning_rate: 4.0000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7930 - loss: 0.4576 - val_accuracy: 0.7762 - val_loss: 0.4679 - learning_rate: 4.0000e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7862 - loss: 0.4495 - val_accuracy: 0.7379 - val_loss: 0.5445 - learning_rate: 4.0000e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7702 - loss: 0.4735 - val_accuracy: 0.7863 - val_loss: 0.4616 - learning_rate: 4.0000e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7842 - loss: 0.4539 - val_accuracy: 0.7742 - val_loss: 0.4729 - learning_rate: 4.0000e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7826 - loss: 0.4586 - val_accuracy: 0.7863 - val_loss: 0.4582 - learning_rate: 4.0000e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7740 - loss: 0.4547 - val_accuracy: 0.7692 - val_loss: 0.4717 - learning_rate: 4.0000e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8009 - loss: 0.4372 - val_accuracy: 0.7923 - val_loss: 0.4641 - learning_rate: 4.0000e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m119/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7839 - loss: 0.4521\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00019999999494757503.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7845 - loss: 0.4512 - val_accuracy: 0.7823 - val_loss: 0.4628 - learning_rate: 4.0000e-04\n",
            "Epoch 26/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7983 - loss: 0.4365 - val_accuracy: 0.7752 - val_loss: 0.4654 - learning_rate: 2.0000e-04\n",
            "Epoch 27/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8038 - loss: 0.4320 - val_accuracy: 0.7823 - val_loss: 0.4556 - learning_rate: 2.0000e-04\n",
            "Epoch 28/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8063 - loss: 0.4240 - val_accuracy: 0.7853 - val_loss: 0.4546 - learning_rate: 2.0000e-04\n",
            "Epoch 29/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7974 - loss: 0.4216 - val_accuracy: 0.7762 - val_loss: 0.4675 - learning_rate: 2.0000e-04\n",
            "Epoch 30/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8024 - loss: 0.4288 - val_accuracy: 0.7853 - val_loss: 0.4529 - learning_rate: 2.0000e-04\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\n",
            "CNN Model Evaluation:\n",
            "Accuracy: 0.7853, F1 Score: 0.7609, ROC-AUC: 0.7820\n",
            "\n",
            "Training complete. Models and results saved.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Conv1D, GlobalMaxPooling1D, Dropout, Input, BatchNormalization, LayerNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
        "import joblib\n",
        "import json\n",
        "\n",
        "# Enable mixed precision for speed improvement\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Set paths\n",
        "data_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/data.xlsx\"\n",
        "save_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/deep_learning_results_optimized6\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_excel(data_path).dropna()\n",
        "\n",
        "# Function to parse vector strings into numpy arrays\n",
        "def parse_vector(vector_str, expected_dim=768):\n",
        "    if isinstance(vector_str, str):\n",
        "        try:\n",
        "            vec = np.array([float(i) for i in vector_str.strip(\"[]\").split()], dtype=np.float32)\n",
        "            return np.pad(vec, (0, max(0, expected_dim - len(vec))))[:expected_dim]\n",
        "        except ValueError:\n",
        "            pass\n",
        "    return np.zeros(expected_dim, dtype=np.float32)\n",
        "\n",
        "# Define embedding dimension\n",
        "embedding_dim = 768\n",
        "\n",
        "# Convert embeddings into arrays\n",
        "embedding_features = ['word2vec_vector', 'fasttext_vector', 'sentence_embedding', 'sinbert_vector']\n",
        "for feature in embedding_features:\n",
        "    df[feature] = df[feature].map(lambda x: parse_vector(x, embedding_dim))\n",
        "\n",
        "# Stack feature vectors efficiently\n",
        "X = np.stack(df[embedding_features].apply(lambda row: np.column_stack(row.values), axis=1).values)\n",
        "X_flattened = X.reshape(X.shape[0], -1)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'].values)\n",
        "joblib.dump(label_encoder, os.path.join(save_path, 'label_encoder.pkl'))\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train_flattened, X_test_flattened = train_test_split(X_flattened, test_size=0.2, random_state=42)\n",
        "\n",
        "# Optimized Model Architectures\n",
        "def build_mlp(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Dense(256, activation='relu'),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0007), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_lstm(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        LSTM(128, return_sequences=True),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.3),\n",
        "        LSTM(64),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0004), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_cnn(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Conv1D(128, kernel_size=3, activation='relu'),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Conv1D(64, kernel_size=3, activation='relu'),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0004), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Callbacks for training efficiency\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
        "\n",
        "# Train and save models\n",
        "models = {\n",
        "    'MLP': build_mlp((X_train_flattened.shape[1],)),\n",
        "    'LSTM': build_lstm((X_train.shape[1], X_train.shape[2])),\n",
        "    'CNN': build_cnn((X_train.shape[1], X_train.shape[2]))\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name} Model...\")\n",
        "\n",
        "    if name == 'MLP':\n",
        "        history = model.fit(\n",
        "            X_train_flattened, y_train,\n",
        "            epochs=30, batch_size=32, validation_data=(X_test_flattened, y_test),\n",
        "            callbacks=[early_stopping, reduce_lr], verbose=1\n",
        "        )\n",
        "        y_pred = (model.predict(X_test_flattened) > 0.5).astype(int)\n",
        "    else:\n",
        "        history = model.fit(\n",
        "            X_train, y_train,\n",
        "            epochs=30, batch_size=32, validation_data=(X_test, y_test),\n",
        "            callbacks=[early_stopping, reduce_lr], verbose=1\n",
        "        )\n",
        "        y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "    # Save the trained model using TensorFlow's SavedModel format\n",
        "    model.save(os.path.join(save_path, f\"{name}_model.keras\"))\n",
        "\n",
        "    # Evaluate model performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred).tolist()\n",
        "\n",
        "    results[name] = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"confusion_matrix\": cm\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{name} Model Evaluation:\\nAccuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
        "\n",
        "# Save evaluation results\n",
        "with open(os.path.join(save_path, \"model_results.json\"), \"w\") as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n",
        "# Save results in CSV format for easy analysis\n",
        "pd.DataFrame(results).T.to_csv(os.path.join(save_path, \"model_results.csv\"), index=True)\n",
        "\n",
        "print(\"\\nTraining complete. Models and results saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMmu3ZRei6Gk",
        "outputId": "da5b70ae-8683-4c4b-b556-8348b998e41c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training MLP Model...\n",
            "Epoch 1/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.7046 - loss: 0.5765 - val_accuracy: 0.7651 - val_loss: 0.4845 - learning_rate: 7.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7895 - loss: 0.4631 - val_accuracy: 0.7812 - val_loss: 0.4712 - learning_rate: 7.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8113 - loss: 0.4227 - val_accuracy: 0.7782 - val_loss: 0.5069 - learning_rate: 7.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8086 - loss: 0.4143 - val_accuracy: 0.7954 - val_loss: 0.4489 - learning_rate: 7.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8023 - loss: 0.4238 - val_accuracy: 0.8145 - val_loss: 0.4424 - learning_rate: 7.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8140 - loss: 0.4102 - val_accuracy: 0.8085 - val_loss: 0.4287 - learning_rate: 7.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8205 - loss: 0.3880 - val_accuracy: 0.8085 - val_loss: 0.4544 - learning_rate: 7.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8280 - loss: 0.3903 - val_accuracy: 0.7702 - val_loss: 0.5157 - learning_rate: 7.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m121/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8252 - loss: 0.3848\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8254 - loss: 0.3844 - val_accuracy: 0.7601 - val_loss: 0.5186 - learning_rate: 7.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8349 - loss: 0.3682 - val_accuracy: 0.8165 - val_loss: 0.4177 - learning_rate: 3.5000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8562 - loss: 0.3323 - val_accuracy: 0.8085 - val_loss: 0.4328 - learning_rate: 3.5000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8621 - loss: 0.3269 - val_accuracy: 0.8024 - val_loss: 0.4479 - learning_rate: 3.5000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m115/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8537 - loss: 0.3408\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8538 - loss: 0.3400 - val_accuracy: 0.7802 - val_loss: 0.5334 - learning_rate: 3.5000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8579 - loss: 0.3173 - val_accuracy: 0.8105 - val_loss: 0.4340 - learning_rate: 1.7500e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8739 - loss: 0.3026 - val_accuracy: 0.8044 - val_loss: 0.4688 - learning_rate: 1.7500e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m117/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8806 - loss: 0.2791\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8799 - loss: 0.2804 - val_accuracy: 0.8105 - val_loss: 0.4600 - learning_rate: 1.7500e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8523 - loss: 0.3082 - val_accuracy: 0.8155 - val_loss: 0.4728 - learning_rate: 8.7500e-05\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "\n",
            "MLP Model Evaluation:\n",
            "Accuracy: 0.8165, F1 Score: 0.7908, ROC-AUC: 0.8121\n",
            "\n",
            "Training LSTM Model...\n",
            "Epoch 1/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.5665 - loss: 0.6803 - val_accuracy: 0.6381 - val_loss: 0.6450 - learning_rate: 4.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.6255 - loss: 0.6470 - val_accuracy: 0.6431 - val_loss: 0.6302 - learning_rate: 4.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.6496 - loss: 0.6252 - val_accuracy: 0.6442 - val_loss: 0.6266 - learning_rate: 4.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.6652 - loss: 0.6117 - val_accuracy: 0.6593 - val_loss: 0.6104 - learning_rate: 4.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - accuracy: 0.6646 - loss: 0.6146 - val_accuracy: 0.6562 - val_loss: 0.6151 - learning_rate: 4.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 56ms/step - accuracy: 0.6703 - loss: 0.5974 - val_accuracy: 0.6966 - val_loss: 0.5876 - learning_rate: 4.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.6843 - loss: 0.5932 - val_accuracy: 0.7056 - val_loss: 0.5762 - learning_rate: 4.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.7094 - loss: 0.5688 - val_accuracy: 0.6835 - val_loss: 0.5864 - learning_rate: 4.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 64ms/step - accuracy: 0.7161 - loss: 0.5577 - val_accuracy: 0.7167 - val_loss: 0.5515 - learning_rate: 4.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.7271 - loss: 0.5425 - val_accuracy: 0.7228 - val_loss: 0.5304 - learning_rate: 4.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.7198 - loss: 0.5428 - val_accuracy: 0.7288 - val_loss: 0.5268 - learning_rate: 4.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.7298 - loss: 0.5361 - val_accuracy: 0.7127 - val_loss: 0.5406 - learning_rate: 4.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.7398 - loss: 0.5302 - val_accuracy: 0.7369 - val_loss: 0.5320 - learning_rate: 4.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.7411 - loss: 0.5183 - val_accuracy: 0.7399 - val_loss: 0.5242 - learning_rate: 4.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.7432 - loss: 0.5173 - val_accuracy: 0.7369 - val_loss: 0.5174 - learning_rate: 4.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.7379 - loss: 0.5270 - val_accuracy: 0.7419 - val_loss: 0.5183 - learning_rate: 4.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 68ms/step - accuracy: 0.7536 - loss: 0.5036 - val_accuracy: 0.7450 - val_loss: 0.5248 - learning_rate: 4.0000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7459 - loss: 0.5079\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.00019999999494757503.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 59ms/step - accuracy: 0.7459 - loss: 0.5079 - val_accuracy: 0.7319 - val_loss: 0.5337 - learning_rate: 4.0000e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - accuracy: 0.7497 - loss: 0.4970 - val_accuracy: 0.7389 - val_loss: 0.5258 - learning_rate: 2.0000e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.7670 - loss: 0.4877 - val_accuracy: 0.7429 - val_loss: 0.5225 - learning_rate: 2.0000e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 63ms/step - accuracy: 0.7611 - loss: 0.4940 - val_accuracy: 0.7510 - val_loss: 0.5103 - learning_rate: 2.0000e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.7626 - loss: 0.4879 - val_accuracy: 0.7621 - val_loss: 0.5055 - learning_rate: 2.0000e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.7804 - loss: 0.4690 - val_accuracy: 0.7429 - val_loss: 0.5158 - learning_rate: 2.0000e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.7745 - loss: 0.4793 - val_accuracy: 0.7581 - val_loss: 0.5090 - learning_rate: 2.0000e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - accuracy: 0.7790 - loss: 0.4738 - val_accuracy: 0.7581 - val_loss: 0.5041 - learning_rate: 2.0000e-04\n",
            "Epoch 26/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.7743 - loss: 0.4712 - val_accuracy: 0.7712 - val_loss: 0.5100 - learning_rate: 2.0000e-04\n",
            "Epoch 27/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.7718 - loss: 0.4771 - val_accuracy: 0.7560 - val_loss: 0.5095 - learning_rate: 2.0000e-04\n",
            "Epoch 28/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 65ms/step - accuracy: 0.7760 - loss: 0.4756 - val_accuracy: 0.7591 - val_loss: 0.5013 - learning_rate: 2.0000e-04\n",
            "Epoch 29/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.7694 - loss: 0.4722 - val_accuracy: 0.7631 - val_loss: 0.5038 - learning_rate: 2.0000e-04\n",
            "Epoch 30/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.7723 - loss: 0.4669 - val_accuracy: 0.7641 - val_loss: 0.5075 - learning_rate: 2.0000e-04\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
            "\n",
            "LSTM Model Evaluation:\n",
            "Accuracy: 0.7591, F1 Score: 0.7256, ROC-AUC: 0.7545\n",
            "\n",
            "Training CNN Model...\n",
            "Epoch 1/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.5302 - loss: 0.7392 - val_accuracy: 0.6734 - val_loss: 0.6342 - learning_rate: 4.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6251 - loss: 0.6451 - val_accuracy: 0.6109 - val_loss: 0.6457 - learning_rate: 4.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6892 - loss: 0.6013 - val_accuracy: 0.6875 - val_loss: 0.5842 - learning_rate: 4.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7154 - loss: 0.5645 - val_accuracy: 0.6905 - val_loss: 0.5900 - learning_rate: 4.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7201 - loss: 0.5487 - val_accuracy: 0.7056 - val_loss: 0.5598 - learning_rate: 4.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7399 - loss: 0.5303 - val_accuracy: 0.7339 - val_loss: 0.5156 - learning_rate: 4.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7387 - loss: 0.5096 - val_accuracy: 0.7349 - val_loss: 0.5089 - learning_rate: 4.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7592 - loss: 0.5031 - val_accuracy: 0.7490 - val_loss: 0.4989 - learning_rate: 4.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7652 - loss: 0.4914 - val_accuracy: 0.7510 - val_loss: 0.4971 - learning_rate: 4.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7497 - loss: 0.5065 - val_accuracy: 0.7450 - val_loss: 0.5094 - learning_rate: 4.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7639 - loss: 0.4887 - val_accuracy: 0.7440 - val_loss: 0.5167 - learning_rate: 4.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7655 - loss: 0.4891 - val_accuracy: 0.7591 - val_loss: 0.4892 - learning_rate: 4.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7745 - loss: 0.4845 - val_accuracy: 0.7571 - val_loss: 0.4909 - learning_rate: 4.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7659 - loss: 0.4843 - val_accuracy: 0.7681 - val_loss: 0.4871 - learning_rate: 4.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7620 - loss: 0.4822 - val_accuracy: 0.7601 - val_loss: 0.4895 - learning_rate: 4.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7746 - loss: 0.4743 - val_accuracy: 0.7692 - val_loss: 0.4885 - learning_rate: 4.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7810 - loss: 0.4649 - val_accuracy: 0.7692 - val_loss: 0.4801 - learning_rate: 4.0000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7948 - loss: 0.4539 - val_accuracy: 0.7510 - val_loss: 0.5054 - learning_rate: 4.0000e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7817 - loss: 0.4700 - val_accuracy: 0.7702 - val_loss: 0.4804 - learning_rate: 4.0000e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m117/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7811 - loss: 0.4519\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.00019999999494757503.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7809 - loss: 0.4526 - val_accuracy: 0.7601 - val_loss: 0.4960 - learning_rate: 4.0000e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7862 - loss: 0.4444 - val_accuracy: 0.7681 - val_loss: 0.4680 - learning_rate: 2.0000e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7874 - loss: 0.4487 - val_accuracy: 0.7702 - val_loss: 0.4821 - learning_rate: 2.0000e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7883 - loss: 0.4454 - val_accuracy: 0.7833 - val_loss: 0.4754 - learning_rate: 2.0000e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m121/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7986 - loss: 0.4370\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7985 - loss: 0.4372 - val_accuracy: 0.7722 - val_loss: 0.4681 - learning_rate: 2.0000e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7930 - loss: 0.4430 - val_accuracy: 0.7742 - val_loss: 0.4646 - learning_rate: 1.0000e-04\n",
            "Epoch 26/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8007 - loss: 0.4277 - val_accuracy: 0.7762 - val_loss: 0.4681 - learning_rate: 1.0000e-04\n",
            "Epoch 27/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8081 - loss: 0.4259 - val_accuracy: 0.7772 - val_loss: 0.4689 - learning_rate: 1.0000e-04\n",
            "Epoch 28/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7970 - loss: 0.4350 - val_accuracy: 0.7742 - val_loss: 0.4636 - learning_rate: 1.0000e-04\n",
            "Epoch 29/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7998 - loss: 0.4244 - val_accuracy: 0.7732 - val_loss: 0.4672 - learning_rate: 1.0000e-04\n",
            "Epoch 30/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7900 - loss: 0.4499 - val_accuracy: 0.7732 - val_loss: 0.4790 - learning_rate: 1.0000e-04\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "\n",
            "CNN Model Evaluation:\n",
            "Accuracy: 0.7742, F1 Score: 0.7395, ROC-AUC: 0.7690\n",
            "\n",
            "Training complete. Models and results saved.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Conv1D, GlobalMaxPooling1D, Dropout, Input, BatchNormalization, LayerNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
        "import joblib\n",
        "import json\n",
        "\n",
        "# Enable mixed precision for speed improvement\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Set paths\n",
        "data_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/data.xlsx\"\n",
        "save_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/deep_learning_results_optimized7\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_excel(data_path).dropna()\n",
        "\n",
        "# Function to parse vector strings into numpy arrays\n",
        "def parse_vector(vector_str, expected_dim=768):\n",
        "    if isinstance(vector_str, str):\n",
        "        try:\n",
        "            vec = np.array([float(i) for i in vector_str.strip(\"[]\").split()], dtype=np.float32)\n",
        "            return np.pad(vec, (0, max(0, expected_dim - len(vec))))[:expected_dim]\n",
        "        except ValueError:\n",
        "            pass\n",
        "    return np.zeros(expected_dim, dtype=np.float32)\n",
        "\n",
        "# Define embedding dimension\n",
        "embedding_dim = 768\n",
        "\n",
        "# Convert embeddings into arrays\n",
        "embedding_features = ['word2vec_vector', 'fasttext_vector', 'sentence_embedding', 'sinbert_vector']\n",
        "for feature in embedding_features:\n",
        "    df[feature] = df[feature].map(lambda x: parse_vector(x, embedding_dim))\n",
        "\n",
        "# Stack feature vectors efficiently\n",
        "X = np.stack(df[embedding_features].apply(lambda row: np.column_stack(row.values), axis=1).values)\n",
        "X_flattened = X.reshape(X.shape[0], -1)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'].values)\n",
        "joblib.dump(label_encoder, os.path.join(save_path, 'label_encoder.pkl'))\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train_flattened, X_test_flattened = train_test_split(X_flattened, test_size=0.2, random_state=42)\n",
        "\n",
        "# Optimized Model Architectures\n",
        "def build_mlp(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Dense(256, activation='relu'),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0007), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_lstm(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        LSTM(128, return_sequences=True),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.3),\n",
        "        LSTM(64),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0004), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_cnn(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Conv1D(128, kernel_size=3, activation='relu'),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Conv1D(64, kernel_size=3, activation='relu'),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0004), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Callbacks for training efficiency\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
        "\n",
        "# Train and save models\n",
        "models = {\n",
        "    'MLP': build_mlp((X_train_flattened.shape[1],)),\n",
        "    'LSTM': build_lstm((X_train.shape[1], X_train.shape[2])),\n",
        "    'CNN': build_cnn((X_train.shape[1], X_train.shape[2]))\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name} Model...\")\n",
        "\n",
        "    if name == 'MLP':\n",
        "        history = model.fit(\n",
        "            X_train_flattened, y_train,\n",
        "            epochs=30, batch_size=32, validation_data=(X_test_flattened, y_test),\n",
        "            callbacks=[early_stopping, reduce_lr], verbose=1\n",
        "        )\n",
        "        y_pred = (model.predict(X_test_flattened) > 0.5).astype(int)\n",
        "    else:\n",
        "        history = model.fit(\n",
        "            X_train, y_train,\n",
        "            epochs=30, batch_size=32, validation_data=(X_test, y_test),\n",
        "            callbacks=[early_stopping, reduce_lr], verbose=1\n",
        "        )\n",
        "        y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "    # Save the trained model using TensorFlow's SavedModel format\n",
        "    model.save(os.path.join(save_path, f\"{name}_model.keras\"))\n",
        "\n",
        "    # Evaluate model performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred).tolist()\n",
        "\n",
        "    results[name] = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"confusion_matrix\": cm\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{name} Model Evaluation:\\nAccuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
        "\n",
        "# Save evaluation results\n",
        "with open(os.path.join(save_path, \"model_results.json\"), \"w\") as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n",
        "# Save results in CSV format for easy analysis\n",
        "pd.DataFrame(results).T.to_csv(os.path.join(save_path, \"model_results.csv\"), index=True)\n",
        "\n",
        "print(\"\\nTraining complete. Models and results saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B79M7F2_nMIm",
        "outputId": "ccedd8df-1586-4163-be26-1461ebc3c2f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training MLP Model...\n",
            "Epoch 1/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.7106 - loss: 0.5703 - val_accuracy: 0.7944 - val_loss: 0.4403 - learning_rate: 7.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7766 - loss: 0.4765 - val_accuracy: 0.8044 - val_loss: 0.4356 - learning_rate: 7.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8086 - loss: 0.4265 - val_accuracy: 0.7994 - val_loss: 0.4359 - learning_rate: 7.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8142 - loss: 0.4120 - val_accuracy: 0.8065 - val_loss: 0.4413 - learning_rate: 7.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8156 - loss: 0.3978 - val_accuracy: 0.8115 - val_loss: 0.4344 - learning_rate: 7.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8232 - loss: 0.3964 - val_accuracy: 0.8014 - val_loss: 0.4455 - learning_rate: 7.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8139 - loss: 0.3991 - val_accuracy: 0.7702 - val_loss: 0.5164 - learning_rate: 7.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m115/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8345 - loss: 0.3622\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8337 - loss: 0.3638 - val_accuracy: 0.8065 - val_loss: 0.4476 - learning_rate: 7.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8283 - loss: 0.3743 - val_accuracy: 0.8226 - val_loss: 0.4284 - learning_rate: 3.5000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8492 - loss: 0.3485 - val_accuracy: 0.8145 - val_loss: 0.4232 - learning_rate: 3.5000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8524 - loss: 0.3369 - val_accuracy: 0.8075 - val_loss: 0.4533 - learning_rate: 3.5000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8437 - loss: 0.3490 - val_accuracy: 0.8155 - val_loss: 0.4441 - learning_rate: 3.5000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m108/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8517 - loss: 0.3404\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8519 - loss: 0.3399 - val_accuracy: 0.8165 - val_loss: 0.4315 - learning_rate: 3.5000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8565 - loss: 0.3273 - val_accuracy: 0.8095 - val_loss: 0.4385 - learning_rate: 1.7500e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8708 - loss: 0.3049 - val_accuracy: 0.8155 - val_loss: 0.4296 - learning_rate: 1.7500e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m116/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8823 - loss: 0.2878\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8815 - loss: 0.2886 - val_accuracy: 0.8105 - val_loss: 0.4498 - learning_rate: 1.7500e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8779 - loss: 0.2807 - val_accuracy: 0.8075 - val_loss: 0.4526 - learning_rate: 8.7500e-05\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "\n",
            "MLP Model Evaluation:\n",
            "Accuracy: 0.8145, F1 Score: 0.7890, ROC-AUC: 0.8102\n",
            "\n",
            "Training LSTM Model...\n",
            "Epoch 1/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 65ms/step - accuracy: 0.5688 - loss: 0.6813 - val_accuracy: 0.6341 - val_loss: 0.6428 - learning_rate: 4.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 98ms/step - accuracy: 0.6399 - loss: 0.6345 - val_accuracy: 0.6109 - val_loss: 0.6557 - learning_rate: 4.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 91ms/step - accuracy: 0.6385 - loss: 0.6332 - val_accuracy: 0.6573 - val_loss: 0.6212 - learning_rate: 4.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 51ms/step - accuracy: 0.6476 - loss: 0.6284 - val_accuracy: 0.6502 - val_loss: 0.6134 - learning_rate: 4.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.6667 - loss: 0.6047 - val_accuracy: 0.6794 - val_loss: 0.5880 - learning_rate: 4.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.6850 - loss: 0.5932 - val_accuracy: 0.6956 - val_loss: 0.5630 - learning_rate: 4.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - accuracy: 0.7071 - loss: 0.5677 - val_accuracy: 0.7067 - val_loss: 0.5634 - learning_rate: 4.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.7133 - loss: 0.5621 - val_accuracy: 0.7097 - val_loss: 0.5522 - learning_rate: 4.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - accuracy: 0.7241 - loss: 0.5469 - val_accuracy: 0.7218 - val_loss: 0.5380 - learning_rate: 4.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 56ms/step - accuracy: 0.7288 - loss: 0.5419 - val_accuracy: 0.7349 - val_loss: 0.5404 - learning_rate: 4.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.7232 - loss: 0.5489 - val_accuracy: 0.7278 - val_loss: 0.5313 - learning_rate: 4.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.7369 - loss: 0.5336 - val_accuracy: 0.7218 - val_loss: 0.5334 - learning_rate: 4.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.7434 - loss: 0.5165 - val_accuracy: 0.7339 - val_loss: 0.5247 - learning_rate: 4.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 55ms/step - accuracy: 0.7482 - loss: 0.5158 - val_accuracy: 0.7369 - val_loss: 0.5223 - learning_rate: 4.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.7407 - loss: 0.5195 - val_accuracy: 0.7319 - val_loss: 0.5361 - learning_rate: 4.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.7354 - loss: 0.5255 - val_accuracy: 0.7258 - val_loss: 0.5253 - learning_rate: 4.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 60ms/step - accuracy: 0.7390 - loss: 0.5233 - val_accuracy: 0.7450 - val_loss: 0.5198 - learning_rate: 4.0000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 64ms/step - accuracy: 0.7559 - loss: 0.5026 - val_accuracy: 0.7409 - val_loss: 0.5147 - learning_rate: 4.0000e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - accuracy: 0.7507 - loss: 0.5107 - val_accuracy: 0.7268 - val_loss: 0.5219 - learning_rate: 4.0000e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.7553 - loss: 0.5071 - val_accuracy: 0.7339 - val_loss: 0.5221 - learning_rate: 4.0000e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7484 - loss: 0.5090\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.00019999999494757503.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.7485 - loss: 0.5090 - val_accuracy: 0.7389 - val_loss: 0.5242 - learning_rate: 4.0000e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 62ms/step - accuracy: 0.7614 - loss: 0.4918 - val_accuracy: 0.7450 - val_loss: 0.5143 - learning_rate: 2.0000e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 56ms/step - accuracy: 0.7614 - loss: 0.4893 - val_accuracy: 0.7560 - val_loss: 0.5122 - learning_rate: 2.0000e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 59ms/step - accuracy: 0.7613 - loss: 0.4929 - val_accuracy: 0.7450 - val_loss: 0.5163 - learning_rate: 2.0000e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 56ms/step - accuracy: 0.7631 - loss: 0.4862 - val_accuracy: 0.7520 - val_loss: 0.5178 - learning_rate: 2.0000e-04\n",
            "Epoch 26/30\n",
            "\u001b[1m123/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7683 - loss: 0.4850\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.7682 - loss: 0.4850 - val_accuracy: 0.7490 - val_loss: 0.5168 - learning_rate: 2.0000e-04\n",
            "Epoch 27/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - accuracy: 0.7746 - loss: 0.4755 - val_accuracy: 0.7389 - val_loss: 0.5148 - learning_rate: 1.0000e-04\n",
            "Epoch 28/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.7662 - loss: 0.4852 - val_accuracy: 0.7490 - val_loss: 0.5121 - learning_rate: 1.0000e-04\n",
            "Epoch 29/30\n",
            "\u001b[1m123/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7706 - loss: 0.4734\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.7706 - loss: 0.4734 - val_accuracy: 0.7329 - val_loss: 0.5255 - learning_rate: 1.0000e-04\n",
            "Epoch 30/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.7909 - loss: 0.4584 - val_accuracy: 0.7460 - val_loss: 0.5090 - learning_rate: 5.0000e-05\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
            "\n",
            "LSTM Model Evaluation:\n",
            "Accuracy: 0.7460, F1 Score: 0.7014, ROC-AUC: 0.7396\n",
            "\n",
            "Training CNN Model...\n",
            "Epoch 1/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.5333 - loss: 0.7775 - val_accuracy: 0.5766 - val_loss: 0.6569 - learning_rate: 4.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6247 - loss: 0.6476 - val_accuracy: 0.6603 - val_loss: 0.6068 - learning_rate: 4.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6766 - loss: 0.6019 - val_accuracy: 0.7127 - val_loss: 0.5608 - learning_rate: 4.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6968 - loss: 0.5922 - val_accuracy: 0.7097 - val_loss: 0.5469 - learning_rate: 4.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7313 - loss: 0.5488 - val_accuracy: 0.7107 - val_loss: 0.5498 - learning_rate: 4.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7389 - loss: 0.5218 - val_accuracy: 0.7228 - val_loss: 0.5360 - learning_rate: 4.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7429 - loss: 0.5241 - val_accuracy: 0.7228 - val_loss: 0.5276 - learning_rate: 4.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7233 - loss: 0.5540 - val_accuracy: 0.7490 - val_loss: 0.5018 - learning_rate: 4.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7419 - loss: 0.5149 - val_accuracy: 0.7530 - val_loss: 0.4909 - learning_rate: 4.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7718 - loss: 0.4904 - val_accuracy: 0.7621 - val_loss: 0.4957 - learning_rate: 4.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7680 - loss: 0.4849 - val_accuracy: 0.7641 - val_loss: 0.4869 - learning_rate: 4.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7587 - loss: 0.4973 - val_accuracy: 0.7722 - val_loss: 0.4802 - learning_rate: 4.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7505 - loss: 0.4868 - val_accuracy: 0.7631 - val_loss: 0.4828 - learning_rate: 4.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7767 - loss: 0.4749 - val_accuracy: 0.7742 - val_loss: 0.4786 - learning_rate: 4.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7761 - loss: 0.4806 - val_accuracy: 0.7712 - val_loss: 0.4732 - learning_rate: 4.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7928 - loss: 0.4463 - val_accuracy: 0.7692 - val_loss: 0.4670 - learning_rate: 4.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7807 - loss: 0.4681 - val_accuracy: 0.7742 - val_loss: 0.4796 - learning_rate: 4.0000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7628 - loss: 0.4816 - val_accuracy: 0.7833 - val_loss: 0.4658 - learning_rate: 4.0000e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7855 - loss: 0.4437 - val_accuracy: 0.7681 - val_loss: 0.4664 - learning_rate: 4.0000e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8074 - loss: 0.4408 - val_accuracy: 0.7823 - val_loss: 0.4599 - learning_rate: 4.0000e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7885 - loss: 0.4404 - val_accuracy: 0.7843 - val_loss: 0.4587 - learning_rate: 4.0000e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8012 - loss: 0.4383 - val_accuracy: 0.7883 - val_loss: 0.4570 - learning_rate: 4.0000e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7895 - loss: 0.4518 - val_accuracy: 0.7762 - val_loss: 0.4769 - learning_rate: 4.0000e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7917 - loss: 0.4453 - val_accuracy: 0.7450 - val_loss: 0.5258 - learning_rate: 4.0000e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m120/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7793 - loss: 0.4555\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00019999999494757503.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7799 - loss: 0.4550 - val_accuracy: 0.7752 - val_loss: 0.4591 - learning_rate: 4.0000e-04\n",
            "Epoch 26/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8024 - loss: 0.4254 - val_accuracy: 0.7722 - val_loss: 0.4599 - learning_rate: 2.0000e-04\n",
            "Epoch 27/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7880 - loss: 0.4289 - val_accuracy: 0.7722 - val_loss: 0.4632 - learning_rate: 2.0000e-04\n",
            "Epoch 28/30\n",
            "\u001b[1m120/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7889 - loss: 0.4462\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7891 - loss: 0.4457 - val_accuracy: 0.7671 - val_loss: 0.4848 - learning_rate: 2.0000e-04\n",
            "Epoch 29/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8187 - loss: 0.4053 - val_accuracy: 0.7772 - val_loss: 0.4539 - learning_rate: 1.0000e-04\n",
            "Epoch 30/30\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8048 - loss: 0.4177 - val_accuracy: 0.7722 - val_loss: 0.4620 - learning_rate: 1.0000e-04\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
            "\n",
            "CNN Model Evaluation:\n",
            "Accuracy: 0.7772, F1 Score: 0.7445, ROC-AUC: 0.7723\n",
            "\n",
            "Training complete. Models and results saved.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Conv1D, GlobalMaxPooling1D, Dropout, Input, BatchNormalization, LayerNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
        "import joblib\n",
        "import json\n",
        "\n",
        "# Enable mixed precision for speed improvement\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Set paths\n",
        "data_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/data.xlsx\"\n",
        "save_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/deep_learning_results_optimized8\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_excel(data_path).dropna()\n",
        "\n",
        "# Function to parse vector strings into numpy arrays\n",
        "def parse_vector(vector_str, expected_dim=768):\n",
        "    if isinstance(vector_str, str):\n",
        "        try:\n",
        "            vec = np.array([float(i) for i in vector_str.strip(\"[]\").split()], dtype=np.float32)\n",
        "            return np.pad(vec, (0, max(0, expected_dim - len(vec))))[:expected_dim]\n",
        "        except ValueError:\n",
        "            pass\n",
        "    return np.zeros(expected_dim, dtype=np.float32)\n",
        "\n",
        "# Define embedding dimension\n",
        "embedding_dim = 768\n",
        "\n",
        "# Convert embeddings into arrays\n",
        "embedding_features = ['word2vec_vector', 'fasttext_vector', 'sentence_embedding', 'sinbert_vector']\n",
        "for feature in embedding_features:\n",
        "    df[feature] = df[feature].map(lambda x: parse_vector(x, embedding_dim))\n",
        "\n",
        "# Stack feature vectors efficiently\n",
        "X = np.stack(df[embedding_features].apply(lambda row: np.column_stack(row.values), axis=1).values)\n",
        "X_flattened = X.reshape(X.shape[0], -1)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'].values)\n",
        "joblib.dump(label_encoder, os.path.join(save_path, 'label_encoder.pkl'))\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train_flattened, X_test_flattened = train_test_split(X_flattened, test_size=0.2, random_state=42)\n",
        "\n",
        "# Optimized Model Architectures\n",
        "def build_mlp(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Dense(256, activation='relu'),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0007), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_lstm(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        LSTM(128, return_sequences=True),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.3),\n",
        "        LSTM(64),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0004), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_cnn(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Conv1D(128, kernel_size=3, activation='relu'),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Conv1D(64, kernel_size=3, activation='relu'),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0004), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Callbacks for training efficiency\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
        "\n",
        "# Train and save models\n",
        "models = {\n",
        "    'MLP': build_mlp((X_train_flattened.shape[1],)),\n",
        "    'LSTM': build_lstm((X_train.shape[1], X_train.shape[2])),\n",
        "    'CNN': build_cnn((X_train.shape[1], X_train.shape[2]))\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name} Model...\")\n",
        "\n",
        "    if name == 'MLP':\n",
        "        history = model.fit(\n",
        "            X_train_flattened, y_train,\n",
        "            epochs=30, batch_size=32, validation_data=(X_test_flattened, y_test),\n",
        "            callbacks=[early_stopping, reduce_lr], verbose=1\n",
        "        )\n",
        "        y_pred = (model.predict(X_test_flattened) > 0.5).astype(int)\n",
        "    else:\n",
        "        history = model.fit(\n",
        "            X_train, y_train,\n",
        "            epochs=30, batch_size=32, validation_data=(X_test, y_test),\n",
        "            callbacks=[early_stopping, reduce_lr], verbose=1\n",
        "        )\n",
        "        y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "    # Save the trained model using TensorFlow's SavedModel format\n",
        "    model.save(os.path.join(save_path, f\"{name}_model.keras\"))\n",
        "\n",
        "    # Evaluate model performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred).tolist()\n",
        "\n",
        "    results[name] = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"confusion_matrix\": cm\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{name} Model Evaluation:\\nAccuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
        "\n",
        "# Save evaluation results\n",
        "with open(os.path.join(save_path, \"model_results.json\"), \"w\") as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n",
        "# Save results in CSV format for easy analysis\n",
        "pd.DataFrame(results).T.to_csv(os.path.join(save_path, \"model_results.csv\"), index=True)\n",
        "\n",
        "print(\"\\nTraining complete. Models and results saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgoLRbVbJlYb",
        "outputId": "85f48305-8a43-47cf-c164-1b96f46e50ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training MLP Model...\n",
            "Epoch 1/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - accuracy: 0.6428 - loss: 0.6485 - val_accuracy: 0.7792 - val_loss: 0.4660 - learning_rate: 5.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7657 - loss: 0.4895 - val_accuracy: 0.8105 - val_loss: 0.4495 - learning_rate: 5.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7908 - loss: 0.4554 - val_accuracy: 0.8044 - val_loss: 0.4394 - learning_rate: 5.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7827 - loss: 0.4656 - val_accuracy: 0.8044 - val_loss: 0.4382 - learning_rate: 5.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8013 - loss: 0.4206 - val_accuracy: 0.8075 - val_loss: 0.4447 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8056 - loss: 0.4319 - val_accuracy: 0.8065 - val_loss: 0.4333 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7976 - loss: 0.4374 - val_accuracy: 0.8125 - val_loss: 0.4383 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8152 - loss: 0.4152 - val_accuracy: 0.8135 - val_loss: 0.4259 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8330 - loss: 0.3955 - val_accuracy: 0.8024 - val_loss: 0.4395 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8117 - loss: 0.4042 - val_accuracy: 0.8095 - val_loss: 0.4272 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m123/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8351 - loss: 0.3782\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8349 - loss: 0.3783 - val_accuracy: 0.8135 - val_loss: 0.4372 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8368 - loss: 0.3719 - val_accuracy: 0.8115 - val_loss: 0.4219 - learning_rate: 2.5000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8144 - loss: 0.3954 - val_accuracy: 0.8165 - val_loss: 0.4338 - learning_rate: 2.5000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8371 - loss: 0.3749 - val_accuracy: 0.8175 - val_loss: 0.4286 - learning_rate: 2.5000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m119/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8414 - loss: 0.3572\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8412 - loss: 0.3575 - val_accuracy: 0.8155 - val_loss: 0.4322 - learning_rate: 2.5000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8348 - loss: 0.3726 - val_accuracy: 0.8145 - val_loss: 0.4354 - learning_rate: 1.2500e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8517 - loss: 0.3440 - val_accuracy: 0.8155 - val_loss: 0.4417 - learning_rate: 1.2500e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m114/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8466 - loss: 0.3447\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8472 - loss: 0.3440 - val_accuracy: 0.8135 - val_loss: 0.4594 - learning_rate: 1.2500e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8468 - loss: 0.3324 - val_accuracy: 0.8165 - val_loss: 0.4298 - learning_rate: 6.2500e-05\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "\n",
            "MLP Model Evaluation:\n",
            "Accuracy: 0.8115, F1 Score: 0.7911, ROC-AUC: 0.8085\n",
            "\n",
            "Training LSTM Model...\n",
            "Epoch 1/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 96ms/step - accuracy: 0.5484 - loss: 0.6904 - val_accuracy: 0.6119 - val_loss: 0.6547 - learning_rate: 3.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.6028 - loss: 0.6501 - val_accuracy: 0.6240 - val_loss: 0.6571 - learning_rate: 3.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - accuracy: 0.6366 - loss: 0.6423 - val_accuracy: 0.6522 - val_loss: 0.6549 - learning_rate: 3.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.6258 - loss: 0.6406 - val_accuracy: 0.6250 - val_loss: 0.6419 - learning_rate: 3.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 90ms/step - accuracy: 0.6356 - loss: 0.6383 - val_accuracy: 0.6169 - val_loss: 0.6442 - learning_rate: 3.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 90ms/step - accuracy: 0.6566 - loss: 0.6250 - val_accuracy: 0.6351 - val_loss: 0.6404 - learning_rate: 3.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 93ms/step - accuracy: 0.6444 - loss: 0.6296 - val_accuracy: 0.6310 - val_loss: 0.6341 - learning_rate: 3.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 86ms/step - accuracy: 0.6690 - loss: 0.6132 - val_accuracy: 0.6361 - val_loss: 0.6395 - learning_rate: 3.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 89ms/step - accuracy: 0.6567 - loss: 0.6222 - val_accuracy: 0.6512 - val_loss: 0.6242 - learning_rate: 3.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 93ms/step - accuracy: 0.6805 - loss: 0.6014 - val_accuracy: 0.6552 - val_loss: 0.6198 - learning_rate: 3.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 91ms/step - accuracy: 0.6569 - loss: 0.6099 - val_accuracy: 0.6633 - val_loss: 0.6054 - learning_rate: 3.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.6678 - loss: 0.6063 - val_accuracy: 0.6673 - val_loss: 0.6063 - learning_rate: 3.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 89ms/step - accuracy: 0.6832 - loss: 0.5991 - val_accuracy: 0.6905 - val_loss: 0.5964 - learning_rate: 3.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 88ms/step - accuracy: 0.7034 - loss: 0.5704 - val_accuracy: 0.6815 - val_loss: 0.5969 - learning_rate: 3.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 88ms/step - accuracy: 0.7106 - loss: 0.5694 - val_accuracy: 0.7016 - val_loss: 0.5779 - learning_rate: 3.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 88ms/step - accuracy: 0.6947 - loss: 0.5752 - val_accuracy: 0.6996 - val_loss: 0.5739 - learning_rate: 3.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 87ms/step - accuracy: 0.7162 - loss: 0.5536 - val_accuracy: 0.6925 - val_loss: 0.5824 - learning_rate: 3.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.7201 - loss: 0.5475 - val_accuracy: 0.7208 - val_loss: 0.5426 - learning_rate: 3.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 82ms/step - accuracy: 0.7337 - loss: 0.5368 - val_accuracy: 0.7127 - val_loss: 0.5626 - learning_rate: 3.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 88ms/step - accuracy: 0.7322 - loss: 0.5438 - val_accuracy: 0.7208 - val_loss: 0.5479 - learning_rate: 3.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.7323 - loss: 0.5370 - val_accuracy: 0.7349 - val_loss: 0.5269 - learning_rate: 3.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 84ms/step - accuracy: 0.7456 - loss: 0.5180 - val_accuracy: 0.7359 - val_loss: 0.5300 - learning_rate: 3.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - accuracy: 0.7403 - loss: 0.5285 - val_accuracy: 0.7248 - val_loss: 0.5434 - learning_rate: 3.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7423 - loss: 0.5174\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 93ms/step - accuracy: 0.7423 - loss: 0.5174 - val_accuracy: 0.7258 - val_loss: 0.5308 - learning_rate: 3.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 83ms/step - accuracy: 0.7491 - loss: 0.5074 - val_accuracy: 0.7460 - val_loss: 0.5136 - learning_rate: 1.5000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 87ms/step - accuracy: 0.7662 - loss: 0.4916 - val_accuracy: 0.7480 - val_loss: 0.5203 - learning_rate: 1.5000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 89ms/step - accuracy: 0.7662 - loss: 0.4908 - val_accuracy: 0.7530 - val_loss: 0.5163 - learning_rate: 1.5000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 89ms/step - accuracy: 0.7735 - loss: 0.4741 - val_accuracy: 0.7460 - val_loss: 0.5044 - learning_rate: 1.5000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 97ms/step - accuracy: 0.7699 - loss: 0.4811 - val_accuracy: 0.7571 - val_loss: 0.5113 - learning_rate: 1.5000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 86ms/step - accuracy: 0.7407 - loss: 0.5109 - val_accuracy: 0.7510 - val_loss: 0.5122 - learning_rate: 1.5000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7671 - loss: 0.4796\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 92ms/step - accuracy: 0.7672 - loss: 0.4796 - val_accuracy: 0.7722 - val_loss: 0.5153 - learning_rate: 1.5000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 88ms/step - accuracy: 0.7661 - loss: 0.4737 - val_accuracy: 0.7621 - val_loss: 0.5045 - learning_rate: 7.5000e-05\n",
            "Epoch 33/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 90ms/step - accuracy: 0.7696 - loss: 0.4737 - val_accuracy: 0.7550 - val_loss: 0.5060 - learning_rate: 7.5000e-05\n",
            "Epoch 34/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7862 - loss: 0.4622\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 3.7500001781154424e-05.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.7861 - loss: 0.4622 - val_accuracy: 0.7641 - val_loss: 0.5086 - learning_rate: 7.5000e-05\n",
            "Epoch 35/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 90ms/step - accuracy: 0.7767 - loss: 0.4651 - val_accuracy: 0.7631 - val_loss: 0.5082 - learning_rate: 3.7500e-05\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
            "\n",
            "LSTM Model Evaluation:\n",
            "Accuracy: 0.7460, F1 Score: 0.7123, ROC-AUC: 0.7416\n",
            "\n",
            "Training CNN Model...\n",
            "Epoch 1/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 71ms/step - accuracy: 0.5110 - loss: 0.9743 - val_accuracy: 0.5605 - val_loss: 0.6868 - learning_rate: 3.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.4986 - loss: 0.7205 - val_accuracy: 0.4677 - val_loss: 0.6931 - learning_rate: 3.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5092 - loss: 0.7035 - val_accuracy: 0.6431 - val_loss: 0.6652 - learning_rate: 3.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5470 - loss: 0.6871 - val_accuracy: 0.5373 - val_loss: 0.6791 - learning_rate: 3.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5859 - loss: 0.6749 - val_accuracy: 0.5736 - val_loss: 0.6643 - learning_rate: 3.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6098 - loss: 0.6584 - val_accuracy: 0.6058 - val_loss: 0.6633 - learning_rate: 3.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6719 - loss: 0.6095 - val_accuracy: 0.6431 - val_loss: 0.6590 - learning_rate: 3.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7053 - loss: 0.5671 - val_accuracy: 0.7177 - val_loss: 0.5549 - learning_rate: 3.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7042 - loss: 0.5603 - val_accuracy: 0.7137 - val_loss: 0.5763 - learning_rate: 3.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7491 - loss: 0.5169 - val_accuracy: 0.7671 - val_loss: 0.4827 - learning_rate: 3.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7424 - loss: 0.5242 - val_accuracy: 0.7661 - val_loss: 0.4936 - learning_rate: 3.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7470 - loss: 0.5095 - val_accuracy: 0.7601 - val_loss: 0.4837 - learning_rate: 3.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7599 - loss: 0.4975 - val_accuracy: 0.7560 - val_loss: 0.4809 - learning_rate: 3.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7560 - loss: 0.4946 - val_accuracy: 0.7611 - val_loss: 0.4771 - learning_rate: 3.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7677 - loss: 0.4886 - val_accuracy: 0.7429 - val_loss: 0.5217 - learning_rate: 3.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7673 - loss: 0.4758 - val_accuracy: 0.7823 - val_loss: 0.4590 - learning_rate: 3.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7689 - loss: 0.4848 - val_accuracy: 0.7470 - val_loss: 0.5075 - learning_rate: 3.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7718 - loss: 0.4773 - val_accuracy: 0.7802 - val_loss: 0.4631 - learning_rate: 3.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m120/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7838 - loss: 0.4628\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7837 - loss: 0.4630 - val_accuracy: 0.7742 - val_loss: 0.4614 - learning_rate: 3.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7881 - loss: 0.4623 - val_accuracy: 0.7681 - val_loss: 0.4831 - learning_rate: 1.5000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7876 - loss: 0.4539 - val_accuracy: 0.7772 - val_loss: 0.4524 - learning_rate: 1.5000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7950 - loss: 0.4482 - val_accuracy: 0.7853 - val_loss: 0.4548 - learning_rate: 1.5000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7887 - loss: 0.4479 - val_accuracy: 0.7651 - val_loss: 0.4863 - learning_rate: 1.5000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m120/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7922 - loss: 0.4503\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7921 - loss: 0.4504 - val_accuracy: 0.7782 - val_loss: 0.4595 - learning_rate: 1.5000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7914 - loss: 0.4471 - val_accuracy: 0.7792 - val_loss: 0.4567 - learning_rate: 7.5000e-05\n",
            "Epoch 26/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7876 - loss: 0.4597 - val_accuracy: 0.7833 - val_loss: 0.4497 - learning_rate: 7.5000e-05\n",
            "Epoch 27/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7982 - loss: 0.4403 - val_accuracy: 0.7722 - val_loss: 0.4580 - learning_rate: 7.5000e-05\n",
            "Epoch 28/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7966 - loss: 0.4375 - val_accuracy: 0.7661 - val_loss: 0.4741 - learning_rate: 7.5000e-05\n",
            "Epoch 29/50\n",
            "\u001b[1m119/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7770 - loss: 0.4592\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 3.7500001781154424e-05.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7776 - loss: 0.4583 - val_accuracy: 0.7752 - val_loss: 0.4664 - learning_rate: 7.5000e-05\n",
            "Epoch 30/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7913 - loss: 0.4362 - val_accuracy: 0.7863 - val_loss: 0.4557 - learning_rate: 3.7500e-05\n",
            "Epoch 31/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8028 - loss: 0.4233 - val_accuracy: 0.7792 - val_loss: 0.4598 - learning_rate: 3.7500e-05\n",
            "Epoch 32/50\n",
            "\u001b[1m119/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7943 - loss: 0.4371\n",
            "Epoch 32: ReduceLROnPlateau reducing learning rate to 1.8750000890577212e-05.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7943 - loss: 0.4372 - val_accuracy: 0.7792 - val_loss: 0.4620 - learning_rate: 3.7500e-05\n",
            "Epoch 33/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7889 - loss: 0.4484 - val_accuracy: 0.7843 - val_loss: 0.4578 - learning_rate: 1.8750e-05\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "\n",
            "CNN Model Evaluation:\n",
            "Accuracy: 0.7833, F1 Score: 0.7468, ROC-AUC: 0.7774\n",
            "\n",
            "Training complete. Models and results saved.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Conv1D, GlobalMaxPooling1D, Dropout, Input, BatchNormalization, LayerNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
        "import joblib\n",
        "import json\n",
        "\n",
        "# Enable mixed precision for speed improvement\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Set paths\n",
        "data_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/data.xlsx\"\n",
        "save_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/deep_learning_results_optimized9\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_excel(data_path).dropna()\n",
        "\n",
        "# Function to parse vector strings into numpy arrays\n",
        "def parse_vector(vector_str, expected_dim=768):\n",
        "    if isinstance(vector_str, str):\n",
        "        try:\n",
        "            vec = np.array([float(i) for i in vector_str.strip(\"[]\").split()], dtype=np.float32)\n",
        "            return np.pad(vec, (0, max(0, expected_dim - len(vec))))[:expected_dim]\n",
        "        except ValueError:\n",
        "            pass\n",
        "    return np.zeros(expected_dim, dtype=np.float32)\n",
        "\n",
        "# Define embedding dimension\n",
        "embedding_dim = 768\n",
        "\n",
        "# Convert embeddings into arrays\n",
        "embedding_features = ['word2vec_vector', 'fasttext_vector', 'sentence_embedding', 'sinbert_vector']\n",
        "for feature in embedding_features:\n",
        "    df[feature] = df[feature].map(lambda x: parse_vector(x, embedding_dim))\n",
        "\n",
        "# Stack feature vectors efficiently\n",
        "X = np.stack(df[embedding_features].apply(lambda row: np.column_stack(row.values), axis=1).values)\n",
        "X_flattened = X.reshape(X.shape[0], -1)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'].values)\n",
        "joblib.dump(label_encoder, os.path.join(save_path, 'label_encoder.pkl'))\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train_flattened, X_test_flattened = train_test_split(X_flattened, test_size=0.2, random_state=42)\n",
        "\n",
        "# Optimized Model Architectures\n",
        "def build_mlp(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Dense(512, activation='relu'),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.4),\n",
        "        Dense(256, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_lstm(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        LSTM(256, return_sequences=True),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.4),\n",
        "        LSTM(128, return_sequences=True),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.3),\n",
        "        LSTM(64),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0003), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_cnn(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Conv1D(256, kernel_size=5, activation='relu'),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.4),\n",
        "        Conv1D(128, kernel_size=3, activation='relu'),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Conv1D(64, kernel_size=3, activation='relu'),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0003), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Callbacks for training efficiency\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
        "\n",
        "# Train and save models\n",
        "models = {\n",
        "    'MLP': build_mlp((X_train_flattened.shape[1],)),\n",
        "    'LSTM': build_lstm((X_train.shape[1], X_train.shape[2])),\n",
        "    'CNN': build_cnn((X_train.shape[1], X_train.shape[2]))\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name} Model...\")\n",
        "\n",
        "    if name == 'MLP':\n",
        "        history = model.fit(\n",
        "            X_train_flattened, y_train,\n",
        "            epochs=50, batch_size=32, validation_data=(X_test_flattened, y_test),\n",
        "            callbacks=[early_stopping, reduce_lr], verbose=1\n",
        "        )\n",
        "        y_pred = (model.predict(X_test_flattened) > 0.5).astype(int)\n",
        "    else:\n",
        "        history = model.fit(\n",
        "            X_train, y_train,\n",
        "            epochs=50, batch_size=32, validation_data=(X_test, y_test),\n",
        "            callbacks=[early_stopping, reduce_lr], verbose=1\n",
        "        )\n",
        "        y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "    # Save the trained model using TensorFlow's SavedModel format\n",
        "    model.save(os.path.join(save_path, f\"{name}_model.keras\"))\n",
        "\n",
        "    # Evaluate model performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred).tolist()\n",
        "\n",
        "    results[name] = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"confusion_matrix\": cm\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{name} Model Evaluation:\\nAccuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
        "\n",
        "# Save evaluation results\n",
        "with open(os.path.join(save_path, \"model_results.json\"), \"w\") as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n",
        "# Save results in CSV format for easy analysis\n",
        "pd.DataFrame(results).T.to_csv(os.path.join(save_path, \"model_results.csv\"), index=True)\n",
        "\n",
        "print(\"\\nTraining complete. Models and results saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MVzPk5CvF04",
        "outputId": "6ce1bbb9-4fd7-4843-eeb8-fd43f37cf570"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training MLP Model...\n",
            "Epoch 1/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 0.6797 - loss: 0.6035 - val_accuracy: 0.7923 - val_loss: 0.4534 - learning_rate: 5.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7893 - loss: 0.4600 - val_accuracy: 0.8085 - val_loss: 0.4476 - learning_rate: 5.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7785 - loss: 0.4547 - val_accuracy: 0.8004 - val_loss: 0.4367 - learning_rate: 5.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7904 - loss: 0.4384 - val_accuracy: 0.7913 - val_loss: 0.4401 - learning_rate: 5.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7905 - loss: 0.4469 - val_accuracy: 0.8075 - val_loss: 0.4368 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m119/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7944 - loss: 0.4440\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7948 - loss: 0.4435 - val_accuracy: 0.7954 - val_loss: 0.4568 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8035 - loss: 0.4172 - val_accuracy: 0.7883 - val_loss: 0.4535 - learning_rate: 2.5000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8163 - loss: 0.3937 - val_accuracy: 0.8044 - val_loss: 0.4338 - learning_rate: 2.5000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8202 - loss: 0.3903 - val_accuracy: 0.8115 - val_loss: 0.4309 - learning_rate: 2.5000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8225 - loss: 0.3865 - val_accuracy: 0.7883 - val_loss: 0.4451 - learning_rate: 2.5000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8277 - loss: 0.3843 - val_accuracy: 0.8165 - val_loss: 0.4266 - learning_rate: 2.5000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8136 - loss: 0.4035 - val_accuracy: 0.8115 - val_loss: 0.4218 - learning_rate: 2.5000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8392 - loss: 0.3612 - val_accuracy: 0.8135 - val_loss: 0.4437 - learning_rate: 2.5000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8445 - loss: 0.3568 - val_accuracy: 0.7964 - val_loss: 0.4413 - learning_rate: 2.5000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8346 - loss: 0.3736\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8346 - loss: 0.3736 - val_accuracy: 0.8155 - val_loss: 0.4492 - learning_rate: 2.5000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8455 - loss: 0.3526 - val_accuracy: 0.8165 - val_loss: 0.4287 - learning_rate: 1.2500e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8496 - loss: 0.3503 - val_accuracy: 0.8175 - val_loss: 0.4242 - learning_rate: 1.2500e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m111/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8289 - loss: 0.3561\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8304 - loss: 0.3553 - val_accuracy: 0.8155 - val_loss: 0.4258 - learning_rate: 1.2500e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8513 - loss: 0.3316 - val_accuracy: 0.8165 - val_loss: 0.4283 - learning_rate: 6.2500e-05\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step   \n",
            "\n",
            "MLP Model Evaluation:\n",
            "Accuracy: 0.8115, F1 Score: 0.7873, ROC-AUC: 0.8076\n",
            "\n",
            "Training LSTM Model...\n",
            "Epoch 1/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 90ms/step - accuracy: 0.5540 - loss: 0.6814 - val_accuracy: 0.6230 - val_loss: 0.6494 - learning_rate: 3.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 90ms/step - accuracy: 0.6024 - loss: 0.6505 - val_accuracy: 0.6119 - val_loss: 0.6613 - learning_rate: 3.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 88ms/step - accuracy: 0.6435 - loss: 0.6316 - val_accuracy: 0.6310 - val_loss: 0.6490 - learning_rate: 3.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 89ms/step - accuracy: 0.6198 - loss: 0.6456 - val_accuracy: 0.6069 - val_loss: 0.6758 - learning_rate: 3.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 93ms/step - accuracy: 0.6358 - loss: 0.6337 - val_accuracy: 0.6270 - val_loss: 0.6435 - learning_rate: 3.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 91ms/step - accuracy: 0.6642 - loss: 0.6130 - val_accuracy: 0.6442 - val_loss: 0.6330 - learning_rate: 3.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 89ms/step - accuracy: 0.6590 - loss: 0.6228 - val_accuracy: 0.6381 - val_loss: 0.6377 - learning_rate: 3.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 85ms/step - accuracy: 0.6637 - loss: 0.6143 - val_accuracy: 0.6280 - val_loss: 0.6463 - learning_rate: 3.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.6585 - loss: 0.6130 - val_accuracy: 0.6290 - val_loss: 0.6328 - learning_rate: 3.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 89ms/step - accuracy: 0.6749 - loss: 0.6027 - val_accuracy: 0.6663 - val_loss: 0.6064 - learning_rate: 3.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 88ms/step - accuracy: 0.6681 - loss: 0.6053 - val_accuracy: 0.6744 - val_loss: 0.6070 - learning_rate: 3.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 89ms/step - accuracy: 0.6946 - loss: 0.5999 - val_accuracy: 0.6875 - val_loss: 0.5906 - learning_rate: 3.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 91ms/step - accuracy: 0.7138 - loss: 0.5724 - val_accuracy: 0.6855 - val_loss: 0.5813 - learning_rate: 3.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 85ms/step - accuracy: 0.7139 - loss: 0.5730 - val_accuracy: 0.7056 - val_loss: 0.5725 - learning_rate: 3.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 93ms/step - accuracy: 0.7069 - loss: 0.5780 - val_accuracy: 0.6976 - val_loss: 0.5766 - learning_rate: 3.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 84ms/step - accuracy: 0.7183 - loss: 0.5633 - val_accuracy: 0.6996 - val_loss: 0.5746 - learning_rate: 3.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 89ms/step - accuracy: 0.7177 - loss: 0.5647 - val_accuracy: 0.7056 - val_loss: 0.5606 - learning_rate: 3.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.7364 - loss: 0.5376 - val_accuracy: 0.7268 - val_loss: 0.5380 - learning_rate: 3.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 84ms/step - accuracy: 0.7258 - loss: 0.5483 - val_accuracy: 0.7379 - val_loss: 0.5330 - learning_rate: 3.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 89ms/step - accuracy: 0.7321 - loss: 0.5372 - val_accuracy: 0.7208 - val_loss: 0.5464 - learning_rate: 3.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 90ms/step - accuracy: 0.7357 - loss: 0.5302 - val_accuracy: 0.7319 - val_loss: 0.5271 - learning_rate: 3.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.7527 - loss: 0.5111 - val_accuracy: 0.7238 - val_loss: 0.5414 - learning_rate: 3.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 89ms/step - accuracy: 0.7473 - loss: 0.5146 - val_accuracy: 0.7631 - val_loss: 0.5131 - learning_rate: 3.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 91ms/step - accuracy: 0.7589 - loss: 0.5086 - val_accuracy: 0.7440 - val_loss: 0.5312 - learning_rate: 3.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 93ms/step - accuracy: 0.7589 - loss: 0.5115 - val_accuracy: 0.7379 - val_loss: 0.5351 - learning_rate: 3.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7690 - loss: 0.4899\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 89ms/step - accuracy: 0.7689 - loss: 0.4900 - val_accuracy: 0.7379 - val_loss: 0.5262 - learning_rate: 3.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 85ms/step - accuracy: 0.7643 - loss: 0.4855 - val_accuracy: 0.7591 - val_loss: 0.5074 - learning_rate: 1.5000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 93ms/step - accuracy: 0.7678 - loss: 0.4806 - val_accuracy: 0.7510 - val_loss: 0.5184 - learning_rate: 1.5000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - accuracy: 0.7823 - loss: 0.4771 - val_accuracy: 0.7571 - val_loss: 0.5103 - learning_rate: 1.5000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7759 - loss: 0.4746\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 87ms/step - accuracy: 0.7759 - loss: 0.4746 - val_accuracy: 0.7490 - val_loss: 0.5161 - learning_rate: 1.5000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 92ms/step - accuracy: 0.7752 - loss: 0.4675 - val_accuracy: 0.7460 - val_loss: 0.5236 - learning_rate: 7.5000e-05\n",
            "Epoch 32/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 89ms/step - accuracy: 0.7791 - loss: 0.4519 - val_accuracy: 0.7480 - val_loss: 0.5079 - learning_rate: 7.5000e-05\n",
            "Epoch 33/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 92ms/step - accuracy: 0.7918 - loss: 0.4453 - val_accuracy: 0.7510 - val_loss: 0.5058 - learning_rate: 7.5000e-05\n",
            "Epoch 34/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 94ms/step - accuracy: 0.7920 - loss: 0.4504 - val_accuracy: 0.7530 - val_loss: 0.5040 - learning_rate: 7.5000e-05\n",
            "Epoch 35/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 87ms/step - accuracy: 0.7811 - loss: 0.4528 - val_accuracy: 0.7651 - val_loss: 0.5106 - learning_rate: 7.5000e-05\n",
            "Epoch 36/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 91ms/step - accuracy: 0.7867 - loss: 0.4489 - val_accuracy: 0.7450 - val_loss: 0.5275 - learning_rate: 7.5000e-05\n",
            "Epoch 37/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7945 - loss: 0.4435\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 3.7500001781154424e-05.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 87ms/step - accuracy: 0.7944 - loss: 0.4435 - val_accuracy: 0.7379 - val_loss: 0.5273 - learning_rate: 7.5000e-05\n",
            "Epoch 38/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.7955 - loss: 0.4379 - val_accuracy: 0.7571 - val_loss: 0.5100 - learning_rate: 3.7500e-05\n",
            "Epoch 39/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 93ms/step - accuracy: 0.7903 - loss: 0.4343 - val_accuracy: 0.7460 - val_loss: 0.5195 - learning_rate: 3.7500e-05\n",
            "Epoch 40/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7846 - loss: 0.4566\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 1.8750000890577212e-05.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 87ms/step - accuracy: 0.7847 - loss: 0.4565 - val_accuracy: 0.7540 - val_loss: 0.5179 - learning_rate: 3.7500e-05\n",
            "Epoch 41/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 90ms/step - accuracy: 0.7805 - loss: 0.4566 - val_accuracy: 0.7571 - val_loss: 0.5157 - learning_rate: 1.8750e-05\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
            "\n",
            "LSTM Model Evaluation:\n",
            "Accuracy: 0.7530, F1 Score: 0.7154, ROC-AUC: 0.7478\n",
            "\n",
            "Training CNN Model...\n",
            "Epoch 1/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - accuracy: 0.4911 - loss: 0.8824 - val_accuracy: 0.5302 - val_loss: 0.6999 - learning_rate: 3.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.5110 - loss: 0.7230 - val_accuracy: 0.6028 - val_loss: 0.6747 - learning_rate: 3.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5530 - loss: 0.6889 - val_accuracy: 0.5605 - val_loss: 0.6577 - learning_rate: 3.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5934 - loss: 0.6704 - val_accuracy: 0.5575 - val_loss: 0.6800 - learning_rate: 3.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6620 - loss: 0.6074 - val_accuracy: 0.6774 - val_loss: 0.5889 - learning_rate: 3.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7023 - loss: 0.5651 - val_accuracy: 0.7278 - val_loss: 0.5415 - learning_rate: 3.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7121 - loss: 0.5576 - val_accuracy: 0.7127 - val_loss: 0.5446 - learning_rate: 3.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7297 - loss: 0.5433 - val_accuracy: 0.6855 - val_loss: 0.5887 - learning_rate: 3.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7481 - loss: 0.5303 - val_accuracy: 0.7258 - val_loss: 0.5326 - learning_rate: 3.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7454 - loss: 0.5213 - val_accuracy: 0.7036 - val_loss: 0.5656 - learning_rate: 3.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7559 - loss: 0.5208 - val_accuracy: 0.7167 - val_loss: 0.5512 - learning_rate: 3.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7436 - loss: 0.5163 - val_accuracy: 0.7500 - val_loss: 0.4987 - learning_rate: 3.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7540 - loss: 0.5044 - val_accuracy: 0.7046 - val_loss: 0.5755 - learning_rate: 3.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7642 - loss: 0.5003 - val_accuracy: 0.7440 - val_loss: 0.5128 - learning_rate: 3.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7550 - loss: 0.4981\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7550 - loss: 0.4981 - val_accuracy: 0.7359 - val_loss: 0.5365 - learning_rate: 3.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7789 - loss: 0.4738 - val_accuracy: 0.7520 - val_loss: 0.5042 - learning_rate: 1.5000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7720 - loss: 0.4817 - val_accuracy: 0.7399 - val_loss: 0.5203 - learning_rate: 1.5000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m118/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7729 - loss: 0.4793\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7728 - loss: 0.4794 - val_accuracy: 0.7490 - val_loss: 0.5103 - learning_rate: 1.5000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7664 - loss: 0.4818 - val_accuracy: 0.7177 - val_loss: 0.5713 - learning_rate: 7.5000e-05\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\n",
            "CNN Model Evaluation:\n",
            "Accuracy: 0.7500, F1 Score: 0.6908, ROC-AUC: 0.7411\n",
            "\n",
            "Training complete. Models and results saved.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Conv1D, GlobalMaxPooling1D, Dropout, Input, BatchNormalization, LayerNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
        "import joblib\n",
        "import json\n",
        "\n",
        "# Enable mixed precision for speed improvement\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Set paths\n",
        "data_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/data.xlsx\"\n",
        "save_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/deep_learning_results_optimized10\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_excel(data_path).dropna()\n",
        "\n",
        "# Function to parse vector strings into numpy arrays\n",
        "def parse_vector(vector_str, expected_dim=768):\n",
        "    if isinstance(vector_str, str):\n",
        "        try:\n",
        "            vec = np.array([float(i) for i in vector_str.strip(\"[]\").split()], dtype=np.float32)\n",
        "            return np.pad(vec, (0, max(0, expected_dim - len(vec))))[:expected_dim]\n",
        "        except ValueError:\n",
        "            pass\n",
        "    return np.zeros(expected_dim, dtype=np.float32)\n",
        "\n",
        "# Define embedding dimension\n",
        "embedding_dim = 768\n",
        "\n",
        "# Convert embeddings into arrays\n",
        "embedding_features = ['word2vec_vector', 'fasttext_vector', 'sentence_embedding', 'sinbert_vector']\n",
        "for feature in embedding_features:\n",
        "    df[feature] = df[feature].map(lambda x: parse_vector(x, embedding_dim))\n",
        "\n",
        "# Stack feature vectors efficiently\n",
        "X = np.stack(df[embedding_features].apply(lambda row: np.column_stack(row.values), axis=1).values)\n",
        "X_flattened = X.reshape(X.shape[0], -1)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'].values)\n",
        "joblib.dump(label_encoder, os.path.join(save_path, 'label_encoder.pkl'))\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train_flattened, X_test_flattened = train_test_split(X_flattened, test_size=0.2, random_state=42)\n",
        "\n",
        "# Optimized Model Architectures\n",
        "def build_mlp(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Dense(512, activation='relu'),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.4),\n",
        "        Dense(256, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_lstm(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        LSTM(256, return_sequences=True),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.4),\n",
        "        LSTM(128, return_sequences=True),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.3),\n",
        "        LSTM(64),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0003), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_cnn(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Conv1D(256, kernel_size=5, activation='relu'),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.4),\n",
        "        Conv1D(128, kernel_size=3, activation='relu'),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Conv1D(64, kernel_size=3, activation='relu'),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0003), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Callbacks for training efficiency\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
        "\n",
        "# Train and save models\n",
        "models = {\n",
        "    'MLP': build_mlp((X_train_flattened.shape[1],)),\n",
        "    'LSTM': build_lstm((X_train.shape[1], X_train.shape[2])),\n",
        "    'CNN': build_cnn((X_train.shape[1], X_train.shape[2]))\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name} Model...\")\n",
        "\n",
        "    if name == 'MLP':\n",
        "        history = model.fit(\n",
        "            X_train_flattened, y_train,\n",
        "            epochs=50, batch_size=32, validation_data=(X_test_flattened, y_test),\n",
        "            callbacks=[early_stopping, reduce_lr], verbose=1\n",
        "        )\n",
        "        y_pred = (model.predict(X_test_flattened) > 0.5).astype(int)\n",
        "    else:\n",
        "        history = model.fit(\n",
        "            X_train, y_train,\n",
        "            epochs=50, batch_size=32, validation_data=(X_test, y_test),\n",
        "            callbacks=[early_stopping, reduce_lr], verbose=1\n",
        "        )\n",
        "        y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "    # Save the trained model using TensorFlow's SavedModel format\n",
        "    model.save(os.path.join(save_path, f\"{name}_model.keras\"))\n",
        "\n",
        "    # Evaluate model performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred).tolist()\n",
        "\n",
        "    results[name] = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"confusion_matrix\": cm\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{name} Model Evaluation:\\nAccuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
        "\n",
        "# Save evaluation results\n",
        "with open(os.path.join(save_path, \"model_results.json\"), \"w\") as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n",
        "# Save results in CSV format for easy analysis\n",
        "pd.DataFrame(results).T.to_csv(os.path.join(save_path, \"model_results.csv\"), index=True)\n",
        "\n",
        "print(\"\\nTraining complete. Models and results saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "08kC28clzaUs",
        "outputId": "b647ea11-7eda-4a1f-bffd-da06ff30eadb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training MLP Model...\n",
            "Epoch 1/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.5425 - loss: 0.7640 - val_accuracy: 0.6522 - val_loss: 0.6212 - learning_rate: 5.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.6003 - loss: 0.6709 - val_accuracy: 0.6643 - val_loss: 0.6205 - learning_rate: 5.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.6207 - loss: 0.6490 - val_accuracy: 0.6774 - val_loss: 0.6117 - learning_rate: 5.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.6176 - loss: 0.6442 - val_accuracy: 0.6905 - val_loss: 0.6067 - learning_rate: 5.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.6379 - loss: 0.6172 - val_accuracy: 0.6825 - val_loss: 0.5992 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.6285 - loss: 0.6197 - val_accuracy: 0.6724 - val_loss: 0.6031 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.6297 - loss: 0.6251 - val_accuracy: 0.6835 - val_loss: 0.5993 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.6277 - loss: 0.6168 - val_accuracy: 0.6815 - val_loss: 0.5880 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.6532 - loss: 0.6108 - val_accuracy: 0.6532 - val_loss: 0.6124 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.6300 - loss: 0.6193 - val_accuracy: 0.6855 - val_loss: 0.5925 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.6695 - loss: 0.5965 - val_accuracy: 0.6976 - val_loss: 0.5854 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.6696 - loss: 0.5948 - val_accuracy: 0.6976 - val_loss: 0.5864 - learning_rate: 5.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.6543 - loss: 0.6007 - val_accuracy: 0.6956 - val_loss: 0.5813 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.6821 - loss: 0.5728 - val_accuracy: 0.6794 - val_loss: 0.5942 - learning_rate: 5.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.6776 - loss: 0.5962 - val_accuracy: 0.6865 - val_loss: 0.5883 - learning_rate: 5.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m122/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6602 - loss: 0.5997\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6604 - loss: 0.5995 - val_accuracy: 0.6966 - val_loss: 0.5830 - learning_rate: 5.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.6793 - loss: 0.5861 - val_accuracy: 0.7036 - val_loss: 0.5797 - learning_rate: 2.5000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.6640 - loss: 0.5954 - val_accuracy: 0.6905 - val_loss: 0.5803 - learning_rate: 2.5000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.6899 - loss: 0.5752 - val_accuracy: 0.7067 - val_loss: 0.5636 - learning_rate: 2.5000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.6913 - loss: 0.5796 - val_accuracy: 0.7137 - val_loss: 0.5604 - learning_rate: 2.5000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.6949 - loss: 0.5669 - val_accuracy: 0.7208 - val_loss: 0.5647 - learning_rate: 2.5000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7089 - loss: 0.5551 - val_accuracy: 0.7026 - val_loss: 0.5708 - learning_rate: 2.5000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.7006 - loss: 0.5667 - val_accuracy: 0.7319 - val_loss: 0.5487 - learning_rate: 2.5000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7122 - loss: 0.5416 - val_accuracy: 0.7258 - val_loss: 0.5500 - learning_rate: 2.5000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7072 - loss: 0.5563 - val_accuracy: 0.6159 - val_loss: 0.6057 - learning_rate: 2.5000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.7082 - loss: 0.5575 - val_accuracy: 0.7329 - val_loss: 0.5452 - learning_rate: 2.5000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.7165 - loss: 0.5550 - val_accuracy: 0.7359 - val_loss: 0.5472 - learning_rate: 2.5000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.7103 - loss: 0.5514 - val_accuracy: 0.7369 - val_loss: 0.5428 - learning_rate: 2.5000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7120 - loss: 0.5559 - val_accuracy: 0.6845 - val_loss: 0.5784 - learning_rate: 2.5000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7144 - loss: 0.5563 - val_accuracy: 0.7198 - val_loss: 0.5458 - learning_rate: 2.5000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m121/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7304 - loss: 0.5363\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7302 - loss: 0.5365 - val_accuracy: 0.7046 - val_loss: 0.5547 - learning_rate: 2.5000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.7232 - loss: 0.5416 - val_accuracy: 0.6966 - val_loss: 0.5618 - learning_rate: 1.2500e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.7185 - loss: 0.5384 - val_accuracy: 0.7238 - val_loss: 0.5442 - learning_rate: 1.2500e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7341 - loss: 0.5340 - val_accuracy: 0.7500 - val_loss: 0.5301 - learning_rate: 1.2500e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.7333 - loss: 0.5381 - val_accuracy: 0.7218 - val_loss: 0.5436 - learning_rate: 1.2500e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7332 - loss: 0.5312 - val_accuracy: 0.7339 - val_loss: 0.5341 - learning_rate: 1.2500e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7295 - loss: 0.5270 - val_accuracy: 0.7419 - val_loss: 0.5272 - learning_rate: 1.2500e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.7274 - loss: 0.5410 - val_accuracy: 0.7329 - val_loss: 0.5351 - learning_rate: 1.2500e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.7385 - loss: 0.5256 - val_accuracy: 0.7480 - val_loss: 0.5248 - learning_rate: 1.2500e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7478 - loss: 0.5300 - val_accuracy: 0.7349 - val_loss: 0.5341 - learning_rate: 1.2500e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.7196 - loss: 0.5269 - val_accuracy: 0.7329 - val_loss: 0.5360 - learning_rate: 1.2500e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m122/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7464 - loss: 0.5200\n",
            "Epoch 42: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.7462 - loss: 0.5202 - val_accuracy: 0.7258 - val_loss: 0.5404 - learning_rate: 1.2500e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.7357 - loss: 0.5236 - val_accuracy: 0.7389 - val_loss: 0.5297 - learning_rate: 6.2500e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7340 - loss: 0.5213 - val_accuracy: 0.7460 - val_loss: 0.5246 - learning_rate: 6.2500e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7488 - loss: 0.5200 - val_accuracy: 0.7288 - val_loss: 0.5324 - learning_rate: 6.2500e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7460 - loss: 0.5189 - val_accuracy: 0.7480 - val_loss: 0.5263 - learning_rate: 6.2500e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.7453 - loss: 0.5250 - val_accuracy: 0.7500 - val_loss: 0.5215 - learning_rate: 6.2500e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.7513 - loss: 0.5234 - val_accuracy: 0.7319 - val_loss: 0.5295 - learning_rate: 6.2500e-05\n",
            "Epoch 49/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.7534 - loss: 0.5179 - val_accuracy: 0.7319 - val_loss: 0.5315 - learning_rate: 6.2500e-05\n",
            "Epoch 50/50\n",
            "\u001b[1m122/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7463 - loss: 0.5165\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.7461 - loss: 0.5166 - val_accuracy: 0.7510 - val_loss: 0.5221 - learning_rate: 6.2500e-05\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\n",
            "MLP Model Evaluation:\n",
            "Accuracy: 0.7500, F1 Score: 0.7213, ROC-AUC: 0.7465\n",
            "\n",
            "Training LSTM Model...\n",
            "Epoch 1/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1260s\u001b[0m 10s/step - accuracy: 0.4959 - loss: 0.6931 - val_accuracy: 0.4698 - val_loss: 0.6932 - learning_rate: 3.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1300s\u001b[0m 10s/step - accuracy: 0.5055 - loss: 0.6931 - val_accuracy: 0.4698 - val_loss: 0.6932 - learning_rate: 3.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1273s\u001b[0m 10s/step - accuracy: 0.5049 - loss: 0.6931 - val_accuracy: 0.4698 - val_loss: 0.6932 - learning_rate: 3.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.4938 - loss: 0.6932\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1275s\u001b[0m 10s/step - accuracy: 0.4938 - loss: 0.6932 - val_accuracy: 0.4698 - val_loss: 0.6932 - learning_rate: 3.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1291s\u001b[0m 10s/step - accuracy: 0.4850 - loss: 0.6932 - val_accuracy: 0.5302 - val_loss: 0.6931 - learning_rate: 1.5000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1273s\u001b[0m 10s/step - accuracy: 0.4915 - loss: 0.6931 - val_accuracy: 0.4698 - val_loss: 0.6932 - learning_rate: 1.5000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.4947 - loss: 0.6932\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1300s\u001b[0m 10s/step - accuracy: 0.4948 - loss: 0.6932 - val_accuracy: 0.5302 - val_loss: 0.6931 - learning_rate: 1.5000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1236s\u001b[0m 10s/step - accuracy: 0.4996 - loss: 0.6931 - val_accuracy: 0.5302 - val_loss: 0.6931 - learning_rate: 7.5000e-05\n",
            "Epoch 9/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1280s\u001b[0m 10s/step - accuracy: 0.5046 - loss: 0.6931 - val_accuracy: 0.5302 - val_loss: 0.6931 - learning_rate: 7.5000e-05\n",
            "Epoch 10/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.5052 - loss: 0.6931\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 3.7500001781154424e-05.\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1278s\u001b[0m 10s/step - accuracy: 0.5051 - loss: 0.6931 - val_accuracy: 0.5302 - val_loss: 0.6931 - learning_rate: 7.5000e-05\n",
            "Epoch 11/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1219s\u001b[0m 10s/step - accuracy: 0.5030 - loss: 0.6931 - val_accuracy: 0.5302 - val_loss: 0.6931 - learning_rate: 3.7500e-05\n",
            "Epoch 12/50\n",
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1179s\u001b[0m 9s/step - accuracy: 0.5060 - loss: 0.6931 - val_accuracy: 0.5302 - val_loss: 0.6931 - learning_rate: 3.7500e-05\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 3s/step\n",
            "\n",
            "LSTM Model Evaluation:\n",
            "Accuracy: 0.5302, F1 Score: 0.0000, ROC-AUC: 0.5000\n",
            "\n",
            "Training CNN Model...\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4218s\u001b[0m 34s/step - accuracy: 0.5133 - loss: 0.9741 - val_accuracy: 0.4950 - val_loss: 0.6928 - learning_rate: 3.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m108/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m9:07\u001b[0m 34s/step - accuracy: 0.4948 - loss: 0.7148"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Conv1D, GlobalMaxPooling1D, Dropout, Input, BatchNormalization, LayerNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
        "import joblib\n",
        "import json\n",
        "\n",
        "# Enable mixed precision for speed improvement\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Set paths\n",
        "data_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/data.xlsx\"\n",
        "save_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/deep_learning_results_optimized11\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_excel(data_path).dropna()\n",
        "\n",
        "# Function to parse vector strings into numpy arrays\n",
        "def parse_vector(vector_str, expected_dim=768):\n",
        "    if isinstance(vector_str, str):\n",
        "        try:\n",
        "            vec = np.array([float(i) for i in vector_str.strip(\"[]\").split()], dtype=np.float32)\n",
        "            return np.pad(vec, (0, max(0, expected_dim - len(vec))))[:expected_dim]\n",
        "        except ValueError:\n",
        "            pass\n",
        "    return np.zeros(expected_dim, dtype=np.float32)\n",
        "\n",
        "# Define embedding dimension\n",
        "embedding_dim = 768\n",
        "\n",
        "# Convert embeddings into arrays\n",
        "embedding_features = ['word2vec_vector']\n",
        "for feature in embedding_features:\n",
        "    df[feature] = df[feature].map(lambda x: parse_vector(x, embedding_dim))\n",
        "\n",
        "# Stack feature vectors efficiently\n",
        "X = np.stack(df[embedding_features].apply(lambda row: np.column_stack(row.values), axis=1).values)\n",
        "X_flattened = X.reshape(X.shape[0], -1)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'].values)\n",
        "joblib.dump(label_encoder, os.path.join(save_path, 'label_encoder.pkl'))\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train_flattened, X_test_flattened = train_test_split(X_flattened, test_size=0.2, random_state=42)\n",
        "\n",
        "# Optimized Model Architectures\n",
        "def build_mlp(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Dense(512, activation='relu'),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.4),\n",
        "        Dense(256, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_lstm(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        LSTM(256, return_sequences=True),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.4),\n",
        "        LSTM(128, return_sequences=True),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.3),\n",
        "        LSTM(64),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0003), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_cnn(input_shape):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Conv1D(256, kernel_size=5, activation='relu'),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.4),\n",
        "        Conv1D(128, kernel_size=3, activation='relu'),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Conv1D(64, kernel_size=3, activation='relu'),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0003), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Callbacks for training efficiency\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
        "\n",
        "# Train and save models\n",
        "models = {\n",
        "    'MLP': build_mlp((X_train_flattened.shape[1],)),\n",
        "    'LSTM': build_lstm((X_train.shape[1], X_train.shape[2])),\n",
        "    'CNN': build_cnn((X_train.shape[1], X_train.shape[2]))\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name} Model...\")\n",
        "\n",
        "    if name == 'MLP':\n",
        "        history = model.fit(\n",
        "            X_train_flattened, y_train,\n",
        "            epochs=50, batch_size=32, validation_data=(X_test_flattened, y_test),\n",
        "            callbacks=[early_stopping, reduce_lr], verbose=1\n",
        "        )\n",
        "        y_pred = (model.predict(X_test_flattened) > 0.5).astype(int)\n",
        "    else:\n",
        "        history = model.fit(\n",
        "            X_train, y_train,\n",
        "            epochs=50, batch_size=32, validation_data=(X_test, y_test),\n",
        "            callbacks=[early_stopping, reduce_lr], verbose=1\n",
        "        )\n",
        "        y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "    # Save the trained model using TensorFlow's SavedModel format\n",
        "    model.save(os.path.join(save_path, f\"{name}_model.keras\"))\n",
        "\n",
        "    # Evaluate model performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred).tolist()\n",
        "\n",
        "    results[name] = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"confusion_matrix\": cm\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{name} Model Evaluation:\\nAccuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
        "\n",
        "# Save evaluation results\n",
        "with open(os.path.join(save_path, \"model_results.json\"), \"w\") as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n",
        "# Save results in CSV format for easy analysis\n",
        "pd.DataFrame(results).T.to_csv(os.path.join(save_path, \"model_results.csv\"), index=True)\n",
        "\n",
        "print(\"\\nTraining complete. Models and results saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJixOf-ZUqjk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZB4mlAbnaYt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_D5fWcGDJlOr"
      },
      "outputs": [],
      "source": [
        "refer above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "jx-CvdvVGzhD",
        "outputId": "168ea72c-ef58-4a44-874f-fbc54b75d039"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of DataFrame after dropping null values: (4958, 8)\n",
            "Epoch 1/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 4s/step - accuracy: 0.5513 - loss: 0.6755 - val_accuracy: 0.6169 - val_loss: 0.6525\n",
            "Epoch 2/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m484s\u001b[0m 4s/step - accuracy: 0.6078 - loss: 0.6474 - val_accuracy: 0.6485 - val_loss: 0.6340\n",
            "Epoch 3/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m532s\u001b[0m 4s/step - accuracy: 0.6272 - loss: 0.6312 - val_accuracy: 0.6855 - val_loss: 0.5911\n",
            "Epoch 4/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 4s/step - accuracy: 0.6927 - loss: 0.5822 - val_accuracy: 0.6902 - val_loss: 0.5934\n",
            "Epoch 5/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m499s\u001b[0m 4s/step - accuracy: 0.6813 - loss: 0.5828 - val_accuracy: 0.6250 - val_loss: 0.6502\n",
            "Epoch 6/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m504s\u001b[0m 4s/step - accuracy: 0.6886 - loss: 0.5821 - val_accuracy: 0.7527 - val_loss: 0.5187\n",
            "Epoch 7/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m468s\u001b[0m 4s/step - accuracy: 0.6929 - loss: 0.5689 - val_accuracy: 0.7487 - val_loss: 0.5280\n",
            "Epoch 8/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m473s\u001b[0m 4s/step - accuracy: 0.7385 - loss: 0.5346 - val_accuracy: 0.7554 - val_loss: 0.5274\n",
            "Epoch 9/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m501s\u001b[0m 4s/step - accuracy: 0.7271 - loss: 0.5368 - val_accuracy: 0.7493 - val_loss: 0.5124\n",
            "Epoch 10/10\n",
            "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 4s/step - accuracy: 0.7444 - loss: 0.5214 - val_accuracy: 0.7594 - val_loss: 0.5042\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-66838f15022e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;31m# Train BiLSTM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0mbilstm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_bilstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m bilstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test),\n\u001b[0m\u001b[1;32m     89\u001b[0m                  callbacks=[early_stopping], verbose=1)\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Dropout, Input, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import joblib\n",
        "import json\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Set paths\n",
        "data_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/data.xlsx\"\n",
        "save_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/deep_learning_results4\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_excel(data_path)\n",
        "df.dropna(inplace=True)\n",
        "print(\"Size of DataFrame after dropping null values:\", df.shape)\n",
        "\n",
        "# Function to parse vector strings into numpy arrays\n",
        "def parse_vector(vector_str, expected_dim):\n",
        "    try:\n",
        "        if isinstance(vector_str, str):\n",
        "            vec = np.array([float(i) for i in vector_str.strip(\"[]\").split()], dtype=np.float32)\n",
        "            if vec.shape[0] == expected_dim:\n",
        "                return vec\n",
        "            elif vec.shape[0] > expected_dim:\n",
        "                return vec[:expected_dim]  # Truncate to expected size\n",
        "            else:\n",
        "                return np.pad(vec, (0, expected_dim - vec.shape[0]))  # Pad with zeros\n",
        "    except:\n",
        "        return np.zeros(expected_dim, dtype=np.float32)  # Default to zero vector\n",
        "    return np.zeros(expected_dim, dtype=np.float32)\n",
        "\n",
        "# Define expected dimensions\n",
        "word2vec_dim = 300\n",
        "fasttext_dim = 300\n",
        "sentence_embedding_dim = 300\n",
        "sinbert_dim = 768  # Larger than others\n",
        "\n",
        "# Apply parsing with dimension corrections\n",
        "df['word2vec_vector'] = df['word2vec_vector'].map(lambda x: parse_vector(x, word2vec_dim))\n",
        "df['fasttext_vector'] = df['fasttext_vector'].map(lambda x: parse_vector(x, fasttext_dim))\n",
        "df['sentence_embedding'] = df['sentence_embedding'].map(lambda x: parse_vector(x, sentence_embedding_dim))\n",
        "df['sinbert_vector'] = df['sinbert_vector'].map(lambda x: parse_vector(x, sinbert_dim))  # Keep 768D\n",
        "\n",
        "# Ensure all feature vectors have the same final dimension\n",
        "final_dim = 768  # Normalize to 768\n",
        "for feature in ['word2vec_vector', 'fasttext_vector', 'sentence_embedding']:\n",
        "    df[feature] = df[feature].map(lambda x: np.pad(x, (0, final_dim - x.shape[0])) if x.shape[0] < final_dim else x[:final_dim])\n",
        "\n",
        "# Stack feature vectors correctly\n",
        "X = np.stack(df[['word2vec_vector', 'fasttext_vector', 'sentence_embedding', 'sinbert_vector']].apply(lambda row: np.column_stack(row.values), axis=1).values)\n",
        "\n",
        "# Reshape X for BiLSTM (samples, time_steps, features)\n",
        "X = X.reshape(X.shape[0], X.shape[1], X.shape[2])\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'].values)\n",
        "joblib.dump(label_encoder, os.path.join(save_path, 'label_encoder.pkl'))\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define BiLSTM Model\n",
        "def build_bilstm(input_shape, lstm_units=128, dropout_rate=0.3):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Bidirectional(LSTM(lstm_units, return_sequences=True)),\n",
        "        Dropout(dropout_rate),\n",
        "        Bidirectional(LSTM(lstm_units // 2)),\n",
        "        Flatten(),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train BiLSTM model\n",
        "bilstm_model = build_bilstm((X_train.shape[1], X_train.shape[2]))\n",
        "bilstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test),\n",
        "                 callbacks=[early_stopping], verbose=1)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = (bilstm_model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "# Define evaluation function\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"confusion_matrix\": conf_matrix.tolist()\n",
        "    }\n",
        "\n",
        "# Save results\n",
        "results = evaluate_model(y_test, y_pred)\n",
        "results_path = os.path.join(save_path, \"bilstm_results.json\")\n",
        "with open(results_path, \"w\") as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n",
        "# Save model\n",
        "bilstm_model.save(os.path.join(save_path, \"bilstm_model.h5\"))\n",
        "\n",
        "print(\"Experiment completed. Results saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krxDFix8Hnyk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Conv1D, GlobalMaxPooling1D, Dropout, Input, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import joblib\n",
        "import json\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Set paths\n",
        "data_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/data.xlsx\"\n",
        "save_path = \"/content/drive/MyDrive/data_set_emotion/Other_Emotion_Models/tested_models/deep_learning_results2\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_excel(data_path)\n",
        "df.dropna(inplace=True)\n",
        "print(\"Size of DataFrame after dropping null values:\", df.shape)\n",
        "\n",
        "# Function to parse vector strings into numpy arrays\n",
        "def parse_vector(vector_str, expected_dim):\n",
        "    try:\n",
        "        if isinstance(vector_str, str):\n",
        "            vec = np.array([float(i) for i in vector_str.strip(\"[]\").split()], dtype=np.float32)\n",
        "            if vec.shape[0] == expected_dim:\n",
        "                return vec\n",
        "            elif vec.shape[0] > expected_dim:\n",
        "                return vec[:expected_dim]  # Truncate to expected size\n",
        "            else:\n",
        "                return np.pad(vec, (0, expected_dim - vec.shape[0]))  # Pad with zeros\n",
        "    except:\n",
        "        return np.zeros(expected_dim, dtype=np.float32)  # Default to zero vector\n",
        "    return np.zeros(expected_dim, dtype=np.float32)\n",
        "\n",
        "# Define expected dimensions\n",
        "word2vec_dim = 300\n",
        "fasttext_dim = 300\n",
        "sentence_embedding_dim = 300\n",
        "sinbert_dim = 768  # Larger than others\n",
        "\n",
        "# Apply parsing with dimension corrections\n",
        "df['word2vec_vector'] = df['word2vec_vector'].map(lambda x: parse_vector(x, word2vec_dim))\n",
        "df['fasttext_vector'] = df['fasttext_vector'].map(lambda x: parse_vector(x, fasttext_dim))\n",
        "df['sentence_embedding'] = df['sentence_embedding'].map(lambda x: parse_vector(x, sentence_embedding_dim))\n",
        "df['sinbert_vector'] = df['sinbert_vector'].map(lambda x: parse_vector(x, sinbert_dim))  # Keep 768D\n",
        "\n",
        "# Ensure all feature vectors have the same final dimension\n",
        "final_dim = 768  # Choose larger or normalize to 300\n",
        "for feature in ['word2vec_vector', 'fasttext_vector', 'sentence_embedding']:\n",
        "    df[feature] = df[feature].map(lambda x: np.pad(x, (0, final_dim - x.shape[0])) if x.shape[0] < final_dim else x[:final_dim])\n",
        "\n",
        "# Stack feature vectors correctly\n",
        "X = np.stack(df[['word2vec_vector', 'fasttext_vector', 'sentence_embedding', 'sinbert_vector']].apply(lambda row: np.column_stack(row.values), axis=1).values)\n",
        "\n",
        "# Flatten X for MLP: (samples, final_dim * 4)\n",
        "X_flattened = X.reshape(X.shape[0], -1)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'].values)\n",
        "joblib.dump(label_encoder, os.path.join(save_path, 'label_encoder.pkl'))\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train_flattened, X_test_flattened = train_test_split(X_flattened, test_size=0.2, random_state=42)\n",
        "\n",
        "# Function to implement early stopping and class weights\n",
        "def build_mlp(input_shape, dropout_rate=0.2, dense_units=128):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Dense(dense_units, activation='relu'),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(dense_units // 2, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_lstm(input_shape, dropout_rate=0.2, lstm_units=64):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        LSTM(lstm_units, return_sequences=True),\n",
        "        Dropout(dropout_rate),\n",
        "        LSTM(lstm_units // 2),\n",
        "        Flatten(),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_cnn(input_shape, dropout_rate=0.2, filters=64):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "        Conv1D(filters, kernel_size=3, activation='relu'),\n",
        "        Dropout(dropout_rate),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(filters // 2, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Early stopping callback to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Apply class weights (use if there is class imbalance)\n",
        "class_weights = {0: 1, 1: 1.5}  # Increase weight for the minority class\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1_score\": f1,\n",
        "        \"confusion_matrix\": conf_matrix.tolist()\n",
        "    }\n",
        "\n",
        "# Train and evaluate models with hyperparameter tuning and regularization\n",
        "results = {}\n",
        "\n",
        "# Model hyperparameters for tuning\n",
        "params = {\n",
        "    'MLP': {\n",
        "        'epochs': [10, 20],\n",
        "        'batch_size': [16, 32],\n",
        "        'dropout': [0.2, 0.3],\n",
        "        'dense_units': [64, 128]\n",
        "    },\n",
        "    'LSTM': {\n",
        "        'epochs': [10, 20],\n",
        "        'batch_size': [16, 32],\n",
        "        'dropout': [0.2, 0.3],\n",
        "        'lstm_units': [64, 128],\n",
        "    },\n",
        "    'CNN': {\n",
        "        'epochs': [10, 20],\n",
        "        'batch_size': [16, 32],\n",
        "        'dropout': [0.2, 0.3],\n",
        "        'filters': [64, 128],\n",
        "    }\n",
        "}\n",
        "\n",
        "# Train and evaluate each model\n",
        "for name in ['MLP', 'LSTM', 'CNN']:\n",
        "    print(f\"Training {name}...\")\n",
        "\n",
        "    # Hyperparameter grid search (manually tuned here)\n",
        "    for epochs in params[name]['epochs']:\n",
        "        for batch_size in params[name]['batch_size']:\n",
        "            if name == 'MLP':\n",
        "                for dropout in params[name]['dropout']:\n",
        "                    for dense_units in params[name]['dense_units']:\n",
        "                        model_instance = build_mlp((X_train_flattened.shape[1],), dropout, dense_units)\n",
        "                        model_instance.fit(X_train_flattened, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                                           validation_data=(X_test_flattened, y_test), class_weight=class_weights,\n",
        "                                           callbacks=[early_stopping], verbose=1)\n",
        "                        y_pred = (model_instance.predict(X_test_flattened) > 0.5).astype(int)\n",
        "                        results[name] = evaluate_model(y_test, y_pred)\n",
        "            elif name == 'LSTM':\n",
        "                for dropout in params[name]['dropout']:\n",
        "                    for lstm_units in params[name]['lstm_units']:\n",
        "                        model_instance = build_lstm((X_train.shape[1], X_train.shape[2]), dropout, lstm_units)\n",
        "                        model_instance.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                                           validation_data=(X_test, y_test), class_weight=class_weights,\n",
        "                                           callbacks=[early_stopping], verbose=1)\n",
        "                        y_pred = (model_instance.predict(X_test) > 0.5).astype(int)\n",
        "                        results[name] = evaluate_model(y_test, y_pred)\n",
        "            elif name == 'CNN':\n",
        "                for dropout in params[name]['dropout']:\n",
        "                    for filters in params[name]['filters']:\n",
        "                        model_instance = build_cnn((X_train.shape[1], X_train.shape[2]), dropout, filters)\n",
        "                        model_instance.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "                                           validation_data=(X_test, y_test), class_weight=class_weights,\n",
        "                                           callbacks=[early_stopping], verbose=1)\n",
        "                        y_pred = (model_instance.predict(X_test) > 0.5).astype(int)\n",
        "                        results[name] = evaluate_model(y_test, y_pred)\n",
        "\n",
        "# Save results to JSON\n",
        "results_path = os.path.join(save_path, \"model_results.json\")\n",
        "with open(results_path, \"w\") as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n",
        "print(\"Experiment completed. Results saved.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}